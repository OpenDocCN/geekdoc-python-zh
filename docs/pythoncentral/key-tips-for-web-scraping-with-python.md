# 使用 Python 进行 Web 抓取的关键技巧

> 原文：<https://www.pythoncentral.io/key-tips-for-web-scraping-with-python/>

[![python](img/f4861fed5fa7b9db72dfbbb1bc15b832.png)](https://www.pythoncentral.io/wp-content/uploads/2022/09/shahadat-rahman-BfrQnKBulYQ-unsplash-scaled.jpg)

Python 是一种流行的高级通用编程语言，用于创建各种工具和解决方案，包括 web scrapers。事实上，Python 是有经验的开发者和学习者第四喜欢的语言。这种流行源于许多因素，例如语言的简单性(就易用性而言)、可伸缩性和大量预写代码库(库)，这里仅举几例。

虽然 Python 被认为是易于使用和学习的，主要是因为它的语法和语义，但是您可以利用一些技巧来进一步简化这个过程。因此，本文将重点介绍使用 Python 进行 web 抓取的基本技巧。

## 什么是网页抓取？

Web 抓取，也称为 web 数据提取或 web 采集，是指从网站手动或自动收集数据的过程。值得指出的是，术语“网络搜集”的使用通常是指数据收集的自动化形式。自动网络数据提取是通过被称为网络抓取器的机器人来完成的。这些机器人处理一切事情，从向网站发送 HTTP 或 HTTPS 请求，解析数据(将其转换为结构化格式)到将其存储在文件中以供下载。

## Web 抓取中的 Python

鉴于机器人的便利性，你可能想知道如何访问网页抓取器。如果你没有技术/编程背景，你会很高兴听到你可以购买或订阅现成的 web scraper。由一家主要关注此类机器人的公司创建和维护的现成 web 抓取工具提供了便利性和高级功能，这些功能只能来自开发人员的协作团队。

也就是说，如果你有广泛的技术背景，并且愿意投入一些时间和资源，你可以考虑使用 Python 从头开始创建一个 web scraper。如果这个选项对您有吸引力，值得指出的是，您可以从使用 Python 进行 web 抓取的几个关键技巧中获益。

## 使用 Python 进行网页抓取的技巧

在进行网络搜集时，您可以利用以下重要提示:

1.  利用 Python 网络抓取库
2.  避免常见的陷阱(反机器人/反刮擦技术)
3.  阅读 robots.txt
4.  设置超时参数
5.  检查错误代码
6.  评估网站是否有公共 API
7.  使用多重处理包来提高网页抓取速度

### 1.Python Web 抓取库

有许多 Python web 抓取库。其中包括:

*   Python 请求库:它包含预先编写的代码，使您能够发出 HTTP/HTTPS 请求。[点击此处了解更多信息](https://oxylabs.io/blog/python-requests)
*   美丽的汤:这是一个解析库
*   lxml:这是一个解析库
*   Scrapy:这是一个 Python 框架，处理结构化数据的请求、解析和保存
*   Selenium:它旨在呈现 JavaScript 代码，并与其他库一起使用

使用 Python 库进行 web 抓取消除了从头创建一切的需要。例如，Python 请求库提供了一个包含许多 HTTP 方法的模板，包括 GET、POST、PATCH、PUT 和 DELETE。

### 2.避免常见的陷阱

现代网站采用[防刮技术](https://latesthackingnews.com/2020/07/17/main-challenges-in-web-scraping/)来保护存储在服务器上的数据。这些技术包括蜜罐陷阱、IP 拦截、验证码难题、登录和登录要求、标题等等。您可以使用无头浏览器、旋转代理、反检测浏览器或读取 Robots.txt 文件(将在下面讨论)来避免这些缺陷。

### 3.读取 robots.txt 文件

robots.txt 文件包含规定机器人不应访问的网页的说明。遵守这些准则可以防止 IP 阻塞。

### 4.设置超时参数

Python 请求库旨在发出请求，并且将无限期地等待响应，即使在服务器不可用的情况下也是如此。因此，建议设置超时参数。

### 5.检查错误代码

建议经常检查 web 服务器返回的状态代码以识别错误。这有助于确定您的请求是否超时或被阻止。此外，您的 Python 代码应该指出，如果 scraper 遇到错误代码，应该打印出什么内容。

### 6.检查公共 API

一些网站利用应用程序编程接口(API ),通过它您可以轻松方便地访问公开可用的数据。这样的公共 API 消除了创建刮刀的需要。

### 7.多重处理包

一个[多重处理包](https://www.javatpoint.com/python-multiprocessing)使系统能够并行处理多个请求，从而加快网页抓取过程。当您处理大量网页时，这很方便。

## 结论

Python 是一种通用的编程语言，可以用来创建 web 抓取器。如果你想创建一个网页抓取器，这篇文章中强调的技巧可以增加你成功的机会。这些技巧包括检查错误代码和公共 API 的可用性、使用多处理器包、设置超时参数等等。