# ç”¨ Python æ ‡å‡†åŒ–æœºå™¨å­¦ä¹ æ•°æ®çš„ä¸¤ç§ç®€å•æ–¹æ³•

> åŸæ–‡ï¼š<https://www.askpython.com/python/examples/standardize-data-in-python>

å˜¿ï¼Œè¯»è€…ä»¬ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨åœ¨ Python ä¸­æ ‡å‡†åŒ–æ•°æ®çš„ **2 é¡¹é‡è¦æŠ€æœ¯ã€‚æ‰€ä»¥ï¼Œè®©æˆ‘ä»¬å¼€å§‹å§ï¼ï¼**

* * *

## ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦åœ¨ Python ä¸­æ ‡å‡†åŒ–æ•°æ®ï¼Ÿ

åœ¨æ·±å…¥ç ”ç©¶æ ‡å‡†åŒ–çš„æ¦‚å¿µä¹‹å‰ï¼Œäº†è§£æ ‡å‡†åŒ–çš„å¿…è¦æ€§æ˜¯éå¸¸é‡è¦çš„ã€‚

æ‰€ä»¥ï¼Œä½ çœ‹ï¼Œæˆ‘ä»¬ç”¨æ¥ä¸ºä¸€ä¸ªç‰¹å®šçš„é—®é¢˜é™ˆè¿°å»ºç«‹æ¨¡å‹çš„æ•°æ®é›†é€šå¸¸æ˜¯ä»å„ç§æ¥æºå»ºç«‹çš„ã€‚å› æ­¤ï¼Œå¯ä»¥å‡è®¾æ•°æ®é›†åŒ…å«ä¸åŒå°ºåº¦çš„å˜é‡/ç‰¹å¾ã€‚

ä¸ºäº†è®©æˆ‘ä»¬çš„æœºå™¨å­¦ä¹ æˆ–æ·±åº¦å­¦ä¹ æ¨¡å‹èƒ½å¤Ÿå¾ˆå¥½åœ°å·¥ä½œï¼Œæ•°æ®åœ¨ç‰¹å¾æ–¹é¢å…·æœ‰ç›¸åŒçš„è§„æ¨¡æ˜¯éå¸¸å¿…è¦çš„ï¼Œä»¥é¿å…ç»“æœä¸­çš„åå·®ã€‚

å› æ­¤ï¼Œ**ç‰¹å¾ç¼©æ”¾**è¢«è®¤ä¸ºæ˜¯å»ºæ¨¡å‰çš„é‡è¦æ­¥éª¤ã€‚

ç‰¹å¾ç¼©æ”¾å¯å¤§è‡´åˆ†ä¸ºä»¥ä¸‹å‡ ç±»:

*   [å½’ä¸€åŒ–](https://www.askpython.com/python/examples/normalize-data-in-python)
*   æ ‡å‡†åŒ–

**æ ‡å‡†åŒ–**ç”¨äº`normally distributed`çš„æ•°æ®å€¼ã€‚æ­¤å¤–ï¼Œé€šè¿‡åº”ç”¨æ ‡å‡†åŒ–ï¼Œæˆ‘ä»¬å€¾å‘äºä½¿æ•°æ®é›†çš„å¹³å‡å€¼ä¸º 0ï¼Œæ ‡å‡†å·®ç­‰äº 1ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œé€šè¿‡æ ‡å‡†åŒ–è¿™äº›å€¼ï¼Œæˆ‘ä»¬å¾—åˆ°äº†æ•°æ®åˆ†å¸ƒçš„ä»¥ä¸‹ç»Ÿè®¡æ•°æ®

*   **å¹³å‡å€¼= 0**
*   **æ ‡å‡†å·®= 1**

![Standardization 1](img/4728652f7adec554da85daf18e935c74.png)

**Standardization**

å› æ­¤ï¼Œé€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ•°æ®é›†å˜å¾—ä¸è¨€è‡ªæ˜å¹¶ä¸”æ˜“äºåˆ†æï¼Œå› ä¸º**å¹³å‡å€¼ä¸‹é™åˆ° 0** ï¼Œå¹¶ä¸”å®ƒç¢°å·§å…·æœ‰**å•ä½æ–¹å·®**ã€‚

* * *

## åœ¨ Python ä¸­æ ‡å‡†åŒ–æ•°æ®çš„æ–¹æ³•

ç°åœ¨ï¼Œè®©æˆ‘ä»¬åœ¨ä¸‹ä¸€èŠ‚é‡ç‚¹å…³æ³¨å®ç°æ ‡å‡†åŒ–çš„å„ç§æ–¹æ³•ã€‚

### 1.ä½¿ç”¨é¢„å¤„ç†. scale()å‡½æ•°

`preprocessing.scale(data) function`å¯ç”¨äºå°†æ•°æ®å€¼æ ‡å‡†åŒ–ä¸ºå¹³å‡å€¼ç­‰äºé›¶ä¸”æ ‡å‡†å·®ä¸º 1 çš„å€¼ã€‚

è¿™é‡Œï¼Œæˆ‘ä»¬å·²ç»ä½¿ç”¨ä¸‹é¢çš„ä»£ç è¡Œå°† **[è™¹è†œæ•°æ®é›†](https://archive.ics.uci.edu/ml/datasets/iris)** åŠ è½½åˆ°ç¯å¢ƒä¸­:

```py
from sklearn.datasets import load_iris

```

æ­¤å¤–ï¼Œæˆ‘ä»¬å·²ç»å°† iris æ•°æ®é›†ä¿å­˜åˆ°å¦‚ä¸‹åˆ›å»ºçš„æ•°æ®å¯¹è±¡ä¸­ã€‚

```py
from sklearn import preprocessing
data = load_iris()

# separate the independent and dependent variables
X_data = data.data
target = data.target

# standardization of dependent variables
standard = preprocessing.scale(X_data)
print(standard)

```

åœ¨åˆ†ç¦»å› å˜é‡å’Œå“åº”/ç›®æ ‡å˜é‡åï¼Œæˆ‘ä»¬å°†`preprocessing.scale() function`åº”ç”¨äºå› å˜é‡ä»¥æ ‡å‡†åŒ–æ•°æ®ã€‚

**è¾“å‡º:**

![Standardization Output](img/7fe118ac82fc62f72286b25b09125ec0.png)

**Standardization-Output**

* * *

### 2.ä½¿ç”¨ StandardScaler()å‡½æ•°

Python `sklearn library`ä¸ºæˆ‘ä»¬æä¾›äº†`StandardScaler() function`æ¥å¯¹æ•°æ®é›†æ‰§è¡Œæ ‡å‡†åŒ–ã€‚

åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å†æ¬¡åˆ©ç”¨è™¹è†œæ•°æ®é›†ã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª StandardScaler()å¯¹è±¡ï¼Œç„¶ååº”ç”¨`fit_transform() function`å¯¹æ•°æ®é›†åº”ç”¨æ ‡å‡†åŒ–ã€‚

```py
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler

data = load_iris()
scale= StandardScaler()

# separate the independent and dependent variables
X_data = data.data
target = data.target

# standardization of dependent variables
scaled_data = scale.fit_transform(X_data) 
print(scaled_data)

```

**è¾“å‡º**:

![Standardization Output 1](img/803951e0387fffb8e9f686fcc02113ca.png)

**Standardization-Output**

* * *

## ç»“è®º

åˆ°æ­¤ï¼Œæˆ‘ä»¬å°±ç»“æŸäº†è¿™ä¸ªè¯é¢˜ã€‚å¦‚æœä½ é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œæ¬¢è¿åœ¨ä¸‹é¢è¯„è®ºã€‚

åœ¨é‚£ä¹‹å‰ï¼Œè¯·ç»§ç»­å…³æ³¨å¹¶å¿«ä¹å­¦ä¹ ï¼ï¼ğŸ™‚