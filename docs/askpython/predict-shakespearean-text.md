# ä½¿ç”¨ Keras TensorFlow é¢„æµ‹èå£«æ¯”äºšæ–‡æœ¬

> åŸæ–‡ï¼š<https://www.askpython.com/python/examples/predict-shakespearean-text>

å˜¿ä¼™è®¡ä»¬ï¼åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†äº†è§£å¦‚ä½•ä½¿ç”¨ Python ä¸­çš„ Keras TensorFlow API åˆ›å»ºé€’å½’ç¥ç»ç½‘ç»œæ¨¡å‹æ¥é¢„æµ‹èå£«æ¯”äºšæ–‡æœ¬ã€‚

***ä¹Ÿè¯»ä½œ:[è‚¡ä»·é¢„æµ‹ä½¿ç”¨ Python](https://www.askpython.com/python/examples/stock-price-prediction-python)***

ä¸ºäº†äº§ç”Ÿæ–°çš„æ–‡æœ¬ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å®šåˆ¶çš„ RNN æ¨¡å‹æ¥è®­ç»ƒ GitHub èå£«æ¯”äºšæ–‡æœ¬æ•°æ®é›† ã€‚

* * *

## **ç¬¬ä¸€æ­¥:å¯¼å…¥åº“**

æˆ‘ä»¬åˆ©ç”¨äº†ä¸€äº›æœ€æµè¡Œçš„æ·±åº¦å­¦ä¹ åº“ã€‚Sweetviz æ˜¯ä¸€ä¸ªæ–°çš„è½¯ä»¶åŒ…ï¼Œå¯è‡ªåŠ¨è¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æï¼Œå°¤å…¶æœ‰åˆ©äºåˆ†ææˆ‘ä»¬çš„è®­ç»ƒæ•°æ®é›†ã€‚

```py
pip install sweetviz
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
import sweetviz as sw
import seaborn as sns
sns.set()

```

## **ç¬¬äºŒæ­¥:åŠ è½½æ•°æ®é›†**

```py
shakespeare_url='https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'
filepath=keras.utils.get_file('shakespeare.txt',shakespeare_url)
with open(filepath) as f:
    shakespeare_text=f.read()

```

```py
Downloading data from https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt
1122304/1115394 [==============================] - 0s 0us/step
1130496/1115394 [==============================] - 0s 0us/step

```

æ—¢ç„¶æˆ‘ä»¬å·²ç»å°†æ•°æ®é›†ä¸‹è½½åˆ° Python ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬éœ€è¦åœ¨åˆ©ç”¨å®ƒè¿›è¡Œè®­ç»ƒä¹‹å‰å¯¹å…¶è¿›è¡Œé¢„å¤„ç†ã€‚

## **ç¬¬ä¸‰æ­¥:é¢„å¤„ç†æ•°æ®é›†**

æ ‡è®°åŒ–æ˜¯å°†å†—é•¿çš„æ–‡æœ¬å­—ç¬¦ä¸²åˆ†æˆè¾ƒå°éƒ¨åˆ†æˆ–æ ‡è®°çš„è¿‡ç¨‹ã€‚è¾ƒå¤§çš„æ–‡æœ¬å—å¯ä»¥è¢«æ ‡è®°æˆå¥å­ï¼Œç„¶åå˜æˆå•è¯ã€‚

é¢„å¤„ç†è¿˜åŒ…æ‹¬ä»ç”Ÿæˆçš„æ ‡è®°ä¸­åˆ é™¤æ ‡ç‚¹ç¬¦å·ã€‚

```py
tokenizer=keras.preprocessing.text.Tokenizer(char_level=True)
tokenizer.fit_on_texts(shakespeare_text)

max_id=len(tokenizer.word_index)
dataset_size=tokenizer.document_count
[encoded]=np.array(tokenizer.texts_to_sequences([shakespeare_text]))-1

```

## **æ­¥éª¤ 4:å‡†å¤‡æ•°æ®é›†**

æˆ‘ä»¬å°†ä½¿ç”¨`tf.data.Dataset`,å®ƒé€šå¸¸å¯¹å¤§é‡çš„å…ƒç´ æœ‰ç”¨ï¼Œæ¯”å¦‚å¤§é‡çš„æ–‡æœ¬æ•°æ®ã€‚

`Dataset.repeat()`éå†æ•°æ®é›†å¹¶é‡å¤æ•°æ®é›†æŒ‡å®šçš„æ¬¡æ•°ã€‚`window()`å°±åƒä¸€ä¸ªæ»‘åŠ¨çª—å£ï¼Œæ¯æ¬¡æ»‘åŠ¨æŒ‡å®šæ•°é‡çš„çª—å£ï¼Œè¿›è¡Œåå¤è¿­ä»£ã€‚

```py
train_size=dataset_size*90//100
dataset=tf.data.Dataset.from_tensor_slices(encoded[:train_size])

n_steps=100
window_length=n_steps+1
dataset=dataset.repeat().window(window_length,shift=1,drop_remainder=True)

dataset=dataset.flat_map(lambda window: window.batch(window_length))

batch_size=32
dataset=dataset.shuffle(10000).batch(batch_size)
dataset=dataset.map(lambda windows: (windows[:,:-1],windows[:,1:]))
dataset=dataset.map(lambda X_batch,Y_batch: (tf.one_hot(X_batch,depth=max_id),Y_batch))
dataset=dataset.prefetch(1)

```

## **ç¬¬äº”æ­¥:å»ºç«‹æ¨¡å‹**

æ¨¡å‹æ„å»ºéå¸¸ç®€å•ã€‚æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªé¡ºåºæ¨¡å‹ï¼Œå¹¶å‘è¯¥æ¨¡å‹æ·»åŠ å…·æœ‰æŸäº›ç‰¹å¾çš„å±‚ã€‚

```py
model=keras.models.Sequential()
model.add(keras.layers.GRU(128,return_sequences=True,input_shape=[None,max_id]))
model.add(keras.layers.GRU(128,return_sequences=True))
model.add(keras.layers.TimeDistributed(keras.layers.Dense(max_id,activation='softmax')))

```

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ç¼–è¯‘æ¨¡å‹å¹¶åœ¨æ•°æ®é›†ä¸Šæ‹Ÿåˆæ¨¡å‹ã€‚æˆ‘ä»¬å°†ä½¿ç”¨`Adam`ä¼˜åŒ–å™¨ï¼Œä½†æ˜¯ä½ ä¹Ÿå¯ä»¥æ ¹æ®ä½ çš„å–œå¥½ä½¿ç”¨å…¶ä»–å¯ç”¨çš„ä¼˜åŒ–å™¨ã€‚

```py
model.compile(loss='sparse_categorical_crossentropy',optimizer='adam')
history=model.fit(dataset,steps_per_epoch=train_size // batch_size,epochs=1)

```

```py
31370/31370 [==============================] - 1598s 51ms/step - loss: 0.9528

```

## **ç¬¬å…­æ­¥:æµ‹è¯•æ¨¡å‹**

æˆ‘ä»¬åœ¨ä¸‹é¢æåˆ°çš„ä»£ç ç‰‡æ®µä¸­å®šä¹‰äº†ä¸€äº›å‡½æ•°ã€‚è¿™äº›å‡½æ•°å°†æ ¹æ®æˆ‘ä»¬å®šä¹‰çš„æ¨¡å‹é¢„å¤„ç†å’Œå‡†å¤‡è¾“å…¥æ•°æ®ï¼Œå¹¶é¢„æµ‹ä¸‹ä¸€ä¸ªå­—ç¬¦ï¼Œç›´åˆ°æŒ‡å®šçš„å­—ç¬¦æ•°ã€‚

```py
def preprocess(texts):
    X=np.array(tokenizer.texts_to_sequences(texts))-1
    return tf.one_hot(X,max_id)

def next_char(text,temperature=1):
    X_new=preprocess([text])
    y_proba=model.predict(X_new)[0,-1:,:]
    rescaled_logits=tf.math.log(y_proba)/temperature
    char_id=tf.random.categorical(rescaled_logits,num_samples=1)+1
    return tokenizer.sequences_to_texts(char_id.numpy())[0]

def complete_text(text,n_chars=50,temperature=1):
    for _ in range(n_chars):
        text+=next_char(text,temperature)
    return text

```

è®©æˆ‘ä»¬ä½¿ç”¨ä¸‹é¢æåˆ°çš„ä»£ç æ¥é¢„æµ‹æŸä¸ªå­—æ¯æˆ–å•è¯çš„æ–‡æœ¬ã€‚

```py
print("Some predicted texts for letter 'D' are as follows:\n ")
for i in range(3):
  print(complete_text('d'))
  print()

```

```py
Some predicted texts for letter 'D' are as follows:

d, swalld tell you in mine,
the remeiviss if i shou

dima's for me, sir, to comes what this roguty.

dening to girl, ne'er i was deckong?
which never be

```

```py
print("Some predicted texts for word 'SHINE' are as follows:\n ")
for i in range(3):
  print(complete_text('shine'))
  print()

```

**è¾“å‡º:**

```py
Some predicted texts for word 'SHINE' are as follows:

shine on here is your viririno penaite the cursue,
i'll

shine yet it the become done to-k
make you his ocrowing

shine dises'-leck a word or my head
not oning,
so long 

```

* * *

## **ç»“è®º**

æ­å–œä½ ï¼æ‚¨åˆšåˆšå­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨ RNN æ„å»ºä¸€ä¸ªèå£«æ¯”äºšæ–‡æœ¬é¢„æµ‹å™¨ã€‚å¸Œæœ›ä½ å–œæ¬¢å®ƒï¼ğŸ˜‡

å–œæ¬¢è¿™ä¸ªæ•™ç¨‹å—ï¼Ÿæ— è®ºå¦‚ä½•ï¼Œæˆ‘å»ºè®®ä½ çœ‹ä¸€ä¸‹ä¸‹é¢æåˆ°çš„æ•™ç¨‹:

1.  [åˆ©ç”¨ Python é¢„æµ‹è‚¡ä»·](https://www.askpython.com/python/examples/stock-price-prediction-python)
2.  [ç”¨ Python è¿›è¡ŒåŠ å¯†ä»·æ ¼é¢„æµ‹](https://www.askpython.com/python/examples/crypto-price-prediction)
3.  [åˆ©ç”¨ Python è¿›è¡Œè‚¡ç¥¨ä»·æ ¼é¢„æµ‹](https://www.askpython.com/python/examples/stock-price-prediction-python)
4.  [Python ä¸­çš„ç¥¨æˆ¿æ”¶å…¥é¢„æµ‹â€”â€”ç®€å•æ˜“è¡Œ](https://www.askpython.com/python/examples/box-office-revenue-prediction)

æ„Ÿè°¢æ‚¨æŠ½å‡ºæ—¶é—´ï¼å¸Œæœ›ä½ å­¦åˆ°äº†æ–°çš„ä¸œè¥¿ï¼ï¼ğŸ˜„

* * *