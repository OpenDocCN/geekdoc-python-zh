# ç”¨ Python åˆ†ç±»æ–°é—»æ ‡é¢˜â€”â€”æœºå™¨å­¦ä¹ 

> åŸæ–‡ï¼š<https://www.askpython.com/python/examples/classify-news-headlines-in-python>

æˆ‘ä»¬ç”Ÿæ´»åœ¨ä¸€ä¸ªæ•°æ®é©±åŠ¨çš„ç¤¾ä¼šï¼Œéšç€æˆ‘ä»¬æ”¶é›†è¶Šæ¥è¶Šå¤šçš„æ•°æ®ï¼Œå¯¹äº‹ç‰©è¿›è¡Œåˆ†ç±»å˜å¾—è¶Šæ¥è¶Šé‡è¦ã€‚å› æ­¤ï¼Œåœ¨æœ¬å¸–ä¸­ï¼Œæˆ‘ä»¬å°†æ ¹æ®æ–°é—»çš„ç±»å‹å¯¹æ–°é—»æ ‡é¢˜è¿›è¡Œåˆ†ç±»ã€‚æ¯”å¦‚ä½“è‚²æ–°é—»ï¼Œç§‘æŠ€æ–°é—»ï¼Œç­‰ç­‰ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å¤„ç†åŒ…å«æ–°é—»æ ‡é¢˜åŠå…¶ç±»åˆ«çš„æ•°æ®ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ©ç”¨ Python ç¼–ç¨‹è¯­è¨€ä¸­çš„æœºå™¨å­¦ä¹ æ¦‚å¿µå¯¹æ–°é—»æ ‡é¢˜è¿›è¡Œåˆ†ç±»ã€‚

* * *

## **ä»‹ç»æ•°æ®é›†**

æˆ‘ä»¬å°†ä½¿ç”¨åŒ…å«æ–°é—»æ ‡é¢˜åŠå…¶ç±»åˆ«çš„æ•°æ®é›†ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šæ·±å…¥ç»†èŠ‚ï¼Œå¦‚å¦‚ä½•æŠ“å–ç½‘é¡µã€‚æ‚¨å¯ä»¥ä» [**è¿™é‡Œ**](https://github.com/kumar-mahendra/ML-Projects/blob/main/newsfile.csv) ä¸‹è½½æ•°æ®é›†ï¼Œç„¶åæ”¾å…¥æ‚¨çš„å·¥ä½œç›®å½•ã€‚

* * *

## **ç”¨ Python åˆ†ç±»æ–°é—»æ ‡é¢˜çš„æ­¥éª¤**

è®©æˆ‘ä»¬è¿›å…¥ç”¨ Python å¯¹æ–°é—»æ ‡é¢˜è¿›è¡Œåˆ†ç±»çš„æ­¥éª¤ã€‚æŒ‰ç…§æœ¬æ•™ç¨‹æ¥ç†è§£æ•´ä¸ªè¿‡ç¨‹ã€‚

### **1ã€‚å¯¼å…¥æ¨¡å—/åº“**

æˆ‘ä»¬å°†ä»å¯¼å…¥æˆ‘ä»¬å°†ä½¿ç”¨çš„ä¸åŒæ¨¡å—å¼€å§‹ã€‚å¤åˆ¶ç²˜è´´ä¸‹é¢çš„ä»£ç ç‰‡æ®µå¹¶ç»§ç»­ã€‚

```py
import tensorflow as tf 
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd

```

* * *

### **2ã€‚åŠ è½½æ•°æ®é›†**

```py
df = pd.read_csv('news_headlines.csv')
df.head(n=10)

```

![First 10 Rows News Headlines](img/af31dc512fe28f84a8688bdf9a386c7f.png)

First 10 Rows News Headlines

* * *

### **3ã€‚åˆ—è½¦æµ‹è¯•åˆ†å‰²**

ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ 80:20 è§„åˆ™è¿›è¡Œ[è®­ç»ƒ-æµ‹è¯•åˆ†å‰²](https://www.askpython.com/python/examples/split-data-training-and-testing-set)ï¼Œå…¶ä¸­ 80%çš„æ•°æ®ç”¨äºè®­ç»ƒï¼Œå…¶ä½™ 20%ç”¨äºæµ‹è¯•ã€‚

```py
training_data,testing_data =  train_test_split(df.iloc[:5000,:],test_size=0.2)  
# 80% training data

```

ä¸ºäº†å½¢è±¡åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥å€ŸåŠ©ä¸‹é¢æåˆ°çš„ä»£ç åˆ†åˆ«ç»˜åˆ¶è®­ç»ƒå’Œæµ‹è¯•ã€‚

```py
import matplotlib.pyplot as plt
# plotting distribution of each news_category in training& testing data
plt.plot(training_data['news_category'].value_counts())
plt.plot(testing_data['news_category'].value_counts())
plt.title('Train-Test Split Visualization')
plt.show()

```

![Train Test Split News Headlines](img/153bbeab2cb4adbfb9425b4174022abe.png)

Train Test Split News Headlines

* * *

### **4ã€‚æ ‡è®°åŒ–åŠŸèƒ½**

è¿™ä¸ªå‡½æ•°éå¸¸ç®€å•ï¼Œå®ƒå‘ç”Ÿåœ¨æ–°é—»æ ‡é¢˜æ•°æ®çš„è®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œå¹¶è¿”å›ä¸ä¹‹ç›¸å…³çš„åºåˆ—ã€‚

ä½ å¯ä»¥å‚è€ƒ [**è¿™ç¯‡**](https://www.askpython.com/python-modules/tokenization-in-python-using-nltk) æ•™ç¨‹æ¥äº†è§£æ›´å¤šå…³äºæ ‡è®°åŒ–çš„è¿‡ç¨‹ã€‚

```py
def tokenization_(training_headings, testing_headings, max_length=20,vocab_size = 5000):
    tokenizer = Tokenizer(num_words = vocab_size, oov_token= '<oov>')
    #Tokenization and padding

    tokenizer.fit_on_texts(training_headings)
    word_index = tokenizer.word_index
    training_sequences = tokenizer.texts_to_sequences(training_headings)
    training_padded = pad_sequences(training_sequences,padding= 'post',maxlen = max_length, truncating='post')

    testing_sequences = tokenizer.texts_to_sequences(testing_headings)
    testing_padded = pad_sequences(testing_sequences,padding= 'post',maxlen = max_length, truncating='post')

    return tokenizer,training_padded,testing_padded

```

ä¸ºäº†å°† tokenizer å‡½æ•°åº”ç”¨äºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ï¼Œæˆ‘ä»¬éœ€è¦è¿è¡Œä¸‹é¢æåˆ°çš„ä»£ç ç‰‡æ®µã€‚

```py
tokenizer,X_train,X_test = tokenization_(training_data['news_headline'],
                                         testing_data['news_headline'])

labels = {'sports':[0,1,0],'tech':[1,0,0],'world':[0,0,1],}
Y_train = np.array([labels[y] for y in training_data['news_category']])
Y_test = np.array([labels[y]  for y in testing_data['news_category'] ])

```

æˆ‘ä»¬è¿˜ä¼šå°† news_headline å’Œå®ƒä»¬çš„æ ‡ç­¾åˆ†ç¦»åˆ°ä¸åŒçš„åˆ—è¡¨ä¸­ï¼Œå› ä¸ºå®ƒä»¬å°†åœ¨æ¨¡å‹ä¸­åˆ†åˆ«ç”¨äºè®­ç»ƒå’Œæµ‹è¯•ç›®çš„ã€‚

* * *

### **5ã€‚æ„å»ºç¥ç»ç½‘ç»œ**

```py
def build_model( n, vocab_size, embedding_size):
    model = tf.keras.models.Sequential()
    model.add(tf.keras.layers.Embedding(vocab_size,
              embedding_size,input_length=n))
    model.add(tf.keras.layers.GlobalAveragePooling1D()) 
    model.add(tf.keras.layers.Dense(3,activation = 'softmax'))       
    model.compile(loss='categorical_crossentropy',optimizer='adam',
                   metrics='accuracy')
    print(model.summary())
    return model

```

ä¸Šé¢çš„ä»£ç æ‰§è¡Œä»¥ä¸‹æ“ä½œ:

1.  åˆ›å»ºé¡ºåºæ¨¡å‹
2.  å‘é¡ºåºæ¨¡å‹æ·»åŠ è¾“å…¥å’Œè¾“å‡ºå›¾å±‚
3.  ç¼–è¯‘æ¨¡å‹å¹¶åœ¨è®­ç»ƒåæ˜¾ç¤ºæ¨¡å‹çš„æ‘˜è¦
4.  æœ€åï¼Œè¿”å›è®­ç»ƒå¥½çš„æ¨¡å‹

åœ¨è¿™ä¸ªæ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨ä¸¤å±‚ï¼Œå…¶ä¸­ç¬¬ä¸€å±‚æ˜¯åµŒå…¥å±‚ï¼Œç¬¬äºŒå±‚æ˜¯è¾“å‡ºå±‚ã€‚

* * *

### **6ã€‚è®­ç»ƒç¥ç»æ¨¡å‹**

```py
epochs = 25
history = model.fit(X_train,Y_train,
                    validation_data = (X_test,Y_test),
                    epochs = epochs)

```

æœ€åˆï¼Œæˆ‘ä»¬å°†è®¾ç½®ä¸€ä¸ªçºªå…ƒå€¼ã€‚ä½ å¯ä»¥æŠŠå®ƒè®¾ç½®æˆä½ å–œæ¬¢çš„ä»»ä½•å€¼ï¼Œå› ä¸ºè¿™ä¸ªæ¨¡å‹æœ‰ 25 ä¸ªçºªå…ƒå°±è¶³å¤Ÿäº†ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æŠŠæˆ‘ä»¬çš„è®­ç»ƒå’Œæµ‹è¯•æ•°æ®æ‹Ÿåˆåˆ°ç¥ç»æ¨¡å‹ä¸­ã€‚

* * *

è¯¥æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šç»™å‡ºäº† 97% çš„å‡†ç¡®ç‡**ï¼Œåœ¨éªŒè¯/æµ‹è¯•æ•°æ®é›†ä¸Šç»™å‡ºäº† 94%** çš„å‡†ç¡®ç‡**ï¼Œè¿™æ˜¯ç›¸å½“å¥½çš„ï¼Œå› æ­¤è¯¥æ¨¡å‹å·¥ä½œå¾—ç›¸å½“å¥½ã€‚**

* * *

## **ç»“è®º**

æ­å–œä½ ï¼æ‚¨åˆšåˆšå­¦ä¹ äº†å¦‚ä½•åˆ¶ä½œä¸€ä¸ªåˆ†ç±»ç¥ç»æ¨¡å‹ï¼Œä»¥ä¾¿é¢„æµ‹æ–°é—»æ ‡é¢˜çš„ç±»åˆ«ã€‚å¸Œæœ›ä½ å–œæ¬¢å®ƒï¼ğŸ˜‡

å–œæ¬¢è¿™ä¸ªæ•™ç¨‹å—ï¼Ÿæ— è®ºå¦‚ä½•ï¼Œæˆ‘å»ºè®®ä½ çœ‹ä¸€ä¸‹ä¸‹é¢æåˆ°çš„æ•™ç¨‹:

1.  [ç”¨ Python åˆ†ç±»æœè£…å›¾åƒâ€”â€”å®Œå…¨æŒ‡å—](https://www.askpython.com/python/examples/classifying-clothing-images)
2.  [ä½¿ç”¨ Python è¿›è¡Œè‘¡è„é…’åˆ†ç±»â€”â€”ç®€å•æ˜“æ‡‚](https://www.askpython.com/python/wine-classification)
3.  [Python ä¸­çš„åƒåœ¾é‚®ä»¶åˆ†ç±»](https://www.askpython.com/python/examples/email-spam-classification)
4.  [å¦‚ä½•ç”¨ Python åˆ›å»ºå‡æ–°é—»æ£€æµ‹å™¨ï¼Ÿ](https://www.askpython.com/python/examples/fake-news-detector)

æ„Ÿè°¢æ‚¨æŠ½å‡ºæ—¶é—´ï¼å¸Œæœ›ä½ å­¦åˆ°äº†æ–°çš„ä¸œè¥¿ï¼ï¼ğŸ˜„