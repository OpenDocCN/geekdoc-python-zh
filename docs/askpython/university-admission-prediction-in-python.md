# Python ä¸­çš„å¤§å­¦å½•å–é¢„æµ‹

> åŸæ–‡ï¼š<https://www.askpython.com/python/examples/university-admission-prediction-in-python>

å¤§å­¦æ•™è‚²æ­£åœ¨æˆä¸º 21 ä¸–çºªç¤¾ä¼šå’Œç»æµç”Ÿæ´»çš„é‡è¦æ”¯æŸ±ã€‚è¿™ä¸ä»…åœ¨æ•™è‚²è¿‡ç¨‹ä¸­æ˜¯è‡³å…³é‡è¦çš„ï¼Œè€Œä¸”åœ¨ä¿è¯ä¸¤ä»¶é‡è¦çš„äº‹æƒ…ä¸Šä¹Ÿæ˜¯è‡³å…³é‡è¦çš„:ä¸€ä»½å¥½å·¥ä½œå’Œè´¢åŠ¡ç¨³å®šã€‚å¦ä¸€æ–¹é¢ï¼Œé¢„æµ‹å¤§å­¦å…¥å­¦å¯èƒ½æå…·æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå­¦ç”Ÿä¸çŸ¥é“å…¥å­¦æ ‡å‡†ã€‚

å› æ­¤ï¼Œåœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Python ç¼–ç¨‹è¯­è¨€æ„å»ºè‡ªå·±çš„å¤§å­¦å½•å–é¢„æµ‹æ¨¡å‹ã€‚

* * *

## æ•°æ®é›†ç®€ä»‹

åœ¨å›½å¤–ç”³è¯·ç¡•å£«æ—¶ï¼Œæœ‰å‡ ä¸ªå˜é‡éœ€è¦è€ƒè™‘ã€‚ä½ å¿…é¡»æœ‰ä¸€ä¸ªä½“é¢çš„ GRE æˆç»©ï¼Œä¸€ä¸ª sop(ç›®çš„å£°æ˜)ï¼Œæˆ–è€…ä¸€å°æ¨èä¿¡ï¼Œç­‰ç­‰ã€‚å¦‚æœä½ ä¸æ˜¯æ¥è‡ªè‹±è¯­å›½å®¶ï¼Œä½ ä¹Ÿéœ€è¦æäº¤æ‰˜ç¦æˆç»©ã€‚

åœ¨ å¯ä»¥è®¿é—®æ•°æ®é›† *[ã€‚æ•°æ®é›†åŒ…æ‹¬ä»¥ä¸‹å±æ€§:](https://www.kaggle.com/mohansacharya/graduate-admissions)*

1.  GRE æˆç»©(æ»¡åˆ† 340 åˆ†)
2.  æ‰˜ç¦æˆç»©(æ»¡åˆ† 120 åˆ†)
3.  å¤§å­¦è¯„çº§(æ»¡åˆ† 5 åˆ†)
4.  ç›®çš„é™ˆè¿°å’Œæ¨èä¿¡å¼ºåº¦(æ»¡åˆ† 5 åˆ†)
5.  æœ¬ç§‘ GPA(æ»¡åˆ† 10 åˆ†)
6.  ç ”ç©¶ç»éªŒ(0 æˆ– 1)
7.  å½•å–æœºä¼š(èŒƒå›´ä» 0 åˆ° 1)

* * *

## ç”¨ Python å®ç°å¤§å­¦å½•å–ä¿æŠ¤

æˆ‘ä»¬å°†æŠŠæ•´ä¸ªä»£ç å®ç°åˆ†æˆå¦‚ä¸‹æ‰€è¿°çš„è‹¥å¹²æ­¥éª¤:

### æ­¥éª¤ 1:å¯¼å…¥å¿…è¦çš„æ¨¡å—/åº“

```py
import numpy as np 
import pandas as pd
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense ,Dropout,BatchNormalization
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor

```

### æ­¥éª¤ 2:å°†æ•°æ®é›†åŠ è½½åˆ°ç¨‹åºä¸­

```py
df = pd.read_csv('Admission_Predict.csv')
df.head()

```

![First5rows Of University Adm Pred Dataset](img/8ad7c6cd55105093ae374cc2bf4db90b.png)

First5rows Of University Adm Pred Dataset

### ç¬¬ä¸‰æ­¥:æ•°æ®é¢„å¤„ç†å’Œæ•°æ®åˆ†å‰²

åœ¨æ„å»ºæˆ‘ä»¬çš„ä¸»æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ä¸€äº›é¢„å¤„ç†ï¼ŒåŒ…æ‹¬åˆ é™¤æ¨¡å‹ä¸éœ€è¦çš„ä»»ä½•åˆ—ã€‚

åœ¨è¿™é‡Œ,â€œåºåˆ—å·â€åˆ—å¯¹äºå…¥é™¢é¢„æµ‹æ˜¯ä¸å¿…è¦çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å°†å…¶ä»æ•°æ®ä¸­åˆ é™¤ã€‚

```py
df=df.drop("Serial No.",axis=1)

```

åœ¨æ­¤ä¹‹åï¼Œæˆ‘ä»¬å°†æŠŠæ•°æ®é›†åˆ†æˆ X å’Œ Y å­æ•°æ®é›†ï¼Œå…¶ä¸­ X å°†åŒ…å«æ‰€æœ‰ä¿¡æ¯ï¼ŒY å°†åŒ…å«æœ€ç»ˆæ¦‚ç‡ã€‚

```py
Y=np.array(df[df.columns[-1]])
X=np.array(df.drop(df.columns[-1],axis=1))

```

ç°åœ¨ï¼Œä¸‹ä¸€æ­¥æ˜¯ä½¿ç”¨ 80:20 è®­ç»ƒæµ‹è¯•æ‹†åˆ†è§„åˆ™å°†æ•°æ®é›†æ‹†åˆ†ä¸ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ï¼Œå…¶ä¸­ 80%çš„æ•°æ®ç”¨äºè®­ç»ƒï¼Œå…¶ä½™ 20%ç”¨äºæµ‹è¯•ã€‚

```py
X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=0)

```

é¢„å¤„ç†è¿˜å°†æ¶‰åŠè§„èŒƒåŒ–è®­ç»ƒæ•°æ®é›†ï¼Œè¿™å¯ä»¥é€šè¿‡ä¸‹é¢æåˆ°çš„ä»£ç æ¥å®ç°ã€‚

```py
from sklearn.preprocessing import MinMaxScaler
scaler =  MinMaxScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.fit_transform(X_test)

```

### æ­¥éª¤ 3:æ„å»ºæ¨¡å‹

ä¸‹é¢æåˆ°çš„ä»£ç æ˜¯æè¿°æ•´ä¸ªæ¨¡å‹çš„ä¸»è¦åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ¨¡å‹çš„å£°æ˜å’Œå‘æ¨¡å‹æ·»åŠ å±‚ã€‚

è¯¥åŠŸèƒ½è¿˜æ¶‰åŠæ¨¡å‹çš„ç¼–è¯‘å’ŒæŸå¤±çš„è®¡ç®—ã€‚

```py
def baseline_model():
    model = Sequential()
    model.add(Dense(16, input_dim=7, activation='relu'))
    model.add(Dense(16, input_dim=7, activation='relu'))
    model.add(Dense(16, input_dim=7, activation='relu'))
    model.add(Dense(16, input_dim=7, activation='relu'))
    model.add(Dense(1))    
    model.compile(loss='mean_squared_error', optimizer='adam')
    return model

```

### ç¬¬å››æ­¥:æ¨¡å‹çš„è®­ç»ƒ

ä¸‹ä¸€æ­¥æ˜¯åˆ›å»ºæ¨¡å‹å¯¹è±¡ï¼Œå¹¶åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šå¯¹å…¶è¿›è¡Œè®­ç»ƒï¼Œå¦‚ä¸‹é¢çš„ä»£ç æ‰€ç¤ºã€‚ä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½ä¿ç•™å†å…ƒçš„æ•°é‡ã€‚

```py
estimator = KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=3, verbose=1)
estimator.fit(X_train,y_train)

```

åŸ¹è®­çš„æˆæœå¦‚ä¸‹:

```py
Epoch 1/50
107/107 [==============================] - 1s 3ms/step - loss: 0.1087
Epoch 2/50
107/107 [==============================] - 0s 4ms/step - loss: 0.0065
Epoch 3/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0057
Epoch 4/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0052
Epoch 5/50
107/107 [==============================] - 0s 4ms/step - loss: 0.0049
Epoch 6/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0050
Epoch 7/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0047
Epoch 8/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0049
Epoch 9/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0044
Epoch 10/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0043
Epoch 11/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0044
Epoch 12/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0044
Epoch 13/50
107/107 [==============================] - 0s 4ms/step - loss: 0.0043
Epoch 14/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0041
Epoch 15/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0043
Epoch 16/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0042
Epoch 17/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0040
Epoch 18/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0043
Epoch 19/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0039
Epoch 20/50
107/107 [==============================] - 0s 4ms/step - loss: 0.0040
Epoch 21/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0039
Epoch 22/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0042
Epoch 23/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0040
Epoch 24/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0038
Epoch 25/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0042
Epoch 26/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0038
Epoch 27/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0040
Epoch 28/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0042
Epoch 29/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0039
Epoch 30/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0037
Epoch 31/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0038
Epoch 32/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0043
Epoch 33/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0040
Epoch 34/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0037
Epoch 35/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0039
Epoch 36/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0037
Epoch 37/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0038
Epoch 38/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0036
Epoch 39/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0036
Epoch 40/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0036
Epoch 41/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0037
Epoch 42/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0037
Epoch 43/50
107/107 [==============================] - 0s 4ms/step - loss: 0.0036
Epoch 44/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0037
Epoch 45/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0037
Epoch 46/50
107/107 [==============================] - 0s 4ms/step - loss: 0.0038
Epoch 47/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0036
Epoch 48/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0037
Epoch 49/50
107/107 [==============================] - 0s 4ms/step - loss: 0.0037
Epoch 50/50
107/107 [==============================] - 0s 3ms/step - loss: 0.0034
<keras.callbacks.History at 0x7f10c0173e10>
[19]
0s

```

### æ­¥éª¤ 5:æµ‹è¯•æ¨¡å‹

ç°åœ¨ï¼Œè®©æˆ‘ä»¬å°è¯•é¢„æµ‹æµ‹è¯•æ•°æ®é›†çš„å€¼ï¼Œå¹¶å°†å®ƒä»¬ä¸åŸå§‹å€¼è¿›è¡ŒåŒ¹é…ã€‚

```py
prediction = estimator.predict(X_test)
print("ORIGINAL DATA")
print(y_test)
print()
print("PREDICTED DATA")
print(prediction)

```

è¾“å‡ºçœ‹èµ·æ¥æœ‰ç‚¹åƒè¿™æ ·:

```py
ORIGINAL DATA
[0.71 0.7  0.79 0.73 0.72 0.48 0.77 0.71 0.9  0.94 0.58 0.89 0.72 0.57
 0.78 0.42 0.64 0.84 0.63 0.72 0.9  0.83 0.57 0.47 0.85 0.67 0.44 0.54
 0.92 0.62 0.68 0.73 0.73 0.61 0.55 0.74 0.64 0.89 0.73 0.95 0.71 0.72
 0.75 0.76 0.86 0.7  0.39 0.79 0.61 0.64 0.71 0.8  0.61 0.89 0.68 0.79
 0.78 0.52 0.76 0.88 0.74 0.49 0.65 0.59 0.87 0.89 0.81 0.9  0.8  0.76
 0.68 0.87 0.68 0.64 0.91 0.61 0.69 0.62 0.93 0.43]

PREDICTED DATA
[0.64663166 0.6811929  0.77187485 0.59903866 0.70518774 0.5707331
 0.6844891  0.6232987  0.8559068  0.9225058  0.50917023 0.9055291
 0.6913604  0.40199894 0.8595592  0.6155516  0.5891675  0.793468
 0.5415057  0.7054745  0.8786436  0.8063141  0.55548865 0.3587063
 0.77944946 0.5391258  0.43374807 0.62050253 0.90883577 0.6109837
 0.64160395 0.7341113  0.73316455 0.5032365  0.7664028  0.76009744
 0.59858805 0.86267006 0.60282356 0.94984144 0.7196544  0.63529354
 0.7032968  0.8164513  0.8044792  0.6359613  0.54865533 0.6914524
 0.589018   0.55952907 0.6446153  0.77345765 0.6449453  0.8998446
 0.68746895 0.74362046 0.71107167 0.73258513 0.7594558  0.8374823
 0.7504637  0.4027493  0.61975926 0.46762955 0.8579673  0.814696
 0.7111042  0.8707262  0.7539967  0.7515583  0.5506843  0.8436626
 0.8139006  0.5593421  0.933276   0.61958474 0.6084135  0.63294107
 0.9234169  0.44476634]

```

æ‚¨å¯ä»¥çœ‹åˆ°è¿™äº›å€¼åœ¨æŸç§ç¨‹åº¦ä¸Šç¡®å®åŒ¹é…ã€‚ä½†æ˜¯è®©æˆ‘ä»¬ç¡®å®šä¸€ä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿè®¡ç®—äº†å¹³å‡è¯¯å·®ã€‚

### ç¬¬å…­æ­¥:è®¡ç®—å¹³å‡è¯¯å·®

```py
from sklearn.metrics import accuracy_score

train_error =  np.abs(y_test - prediction)
mean_error = np.mean(train_error)

print("Mean Error: ",mean_error)

```

å¹³å‡è¯¯å·®ä¸º***0.0577927375137806***ï¼Œè¿™è¶³ä»¥è¯´æ˜æˆ‘ä»¬çš„ç»“æœç›¸å½“å‡†ç¡®ã€‚

* * *

##  **ç»“è®º**

æ­å–œä½ ï¼ä½ åˆšåˆšå­¦ä¹ äº†å¦‚ä½•åˆ¶ä½œè‡ªå·±çš„å¤§å­¦å½•å–é¢„æµ‹å™¨ã€‚å¸Œæœ›ä½ å–œæ¬¢å®ƒï¼ğŸ˜‡

å–œæ¬¢è¿™ä¸ªæ•™ç¨‹å—ï¼Ÿæ— è®ºå¦‚ä½•ï¼Œæˆ‘å»ºè®®ä½ çœ‹ä¸€ä¸‹ä¸‹é¢æåˆ°çš„æ•™ç¨‹:

1.  [ç”¨ Python è¿›è¡ŒåŠ å¯†ä»·æ ¼é¢„æµ‹](https://www.askpython.com/python/examples/crypto-price-prediction)
2.  [Python ä¸­çš„ç¥¨æˆ¿æ”¶å…¥é¢„æµ‹â€”â€”ç®€å•æ˜“è¡Œ](https://www.askpython.com/python/examples/box-office-revenue-prediction)
3.  [åˆ©ç”¨ Python è¿›è¡Œè‚¡ç¥¨ä»·æ ¼é¢„æµ‹](https://www.askpython.com/python/examples/stock-price-prediction-python)
4.  [ä½¿ç”¨ Python è¿›è¡Œè‘¡è„é…’åˆ†ç±»â€”â€”ç®€å•æ˜“æ‡‚](https://www.askpython.com/python/wine-classification)

æ„Ÿè°¢æ‚¨æŠ½å‡ºæ—¶é—´ï¼å¸Œæœ›ä½ å­¦åˆ°äº†æ–°çš„ä¸œè¥¿ï¼ï¼ğŸ˜„

* * *