# æ ¹æ® Python ä¸­çš„åç§°é¢„æµ‹å›½ç±

> åŸæ–‡ï¼š<https://www.askpython.com/python/examples/predict-nationality-using-names>

å˜¿ä¼™è®¡ä»¬ï¼åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å»ºç«‹ä¸€ä¸ª RNN å’Œ LSTM æ¨¡å‹ï¼Œå¸®åŠ©æˆ‘ä»¬æ ¹æ®æ¯ä¸ªè§’è‰²çš„åå­—æ¥é¢„æµ‹å›½ç±ã€‚

è®©æˆ‘ä»¬ä»äº†è§£æˆ‘ä»¬æ‹¥æœ‰çš„æ•°æ®é›†å¼€å§‹ã€‚

* * *

## **äº†è§£æ•°æ®é›†**

Dataset æ˜¯ä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼ŒåŒ…å«æ¯ä¸ªè¡Œä¸­ç”¨é€—å·åˆ†éš”çš„äººåå’Œå§“åçš„å›½ç±ã€‚è¯¥æ•°æ®é›†åŒ…å«è¶…è¿‡ 2 ä¸‡ä¸ªåå­—å’Œ 18 ä¸ªç‹¬ç‰¹çš„å›½ç±ï¼Œå¦‚è‘¡è„ç‰™è¯­ã€çˆ±å°”å…°è¯­ã€è¥¿ç­ç‰™è¯­ç­‰ç­‰ã€‚

æ•°æ®çš„å¿«ç…§å¦‚ä¸‹æ‰€ç¤ºã€‚ä½ å¯ä»¥åœ¨è¿™é‡Œä¸‹è½½æ•°æ®é›†[ã€‚](https://www.kaggle.com/rp1985/name2lang)

![Dataset Snapshot Nationality Predictor](img/ce05c037595fe7444434a52dc1642a7e.png)

Dataset Snapshot Nationality Predictor

* * *

## **ç”¨ Python ä¸­çš„äººåé¢„æµ‹å›½ç±**

è®©æˆ‘ä»¬ç›´æ¥è¿›å…¥ä»£ç å®ç°ã€‚æˆ‘ä»¬å°†ä»å¯¼å…¥æ¨¡å—å¼€å§‹ï¼Œç„¶åå¯¼å…¥æˆ‘ä»¬ä¸ºæœ¬æ¬¡æ¼”ç¤ºé€‰æ‹©çš„åç§°å’Œå›½ç±æ•°æ®é›†ã€‚

### **ç¬¬ä¸€æ­¥:å¯¼å…¥æ¨¡å—**

åœ¨å¼€å§‹æ„å»ºä»»ä½•æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰éœ€è¦çš„åº“å¯¼å…¥åˆ°æˆ‘ä»¬çš„ç¨‹åºä¸­ã€‚

```py
from io import open
import os, string, random, time, math
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split
import torch 
import torch.nn as nn
import torch.optim as optim
from IPython.display import clear_output

```

### **ç¬¬äºŒæ­¥:åŠ è½½æ•°æ®é›†**

ä¸ºäº†åŠ è½½æ•°æ®é›†ï¼Œæˆ‘ä»¬éå†æ•°æ®ä¸­çš„æ¯ä¸€è¡Œï¼Œå¹¶åˆ›å»ºä¸€ä¸ªåŒ…å«å§“åå’Œå›½ç±çš„å…ƒç»„åˆ—è¡¨ã€‚è¿™å°†ä½¿æ¨¡å‹æ›´å®¹æ˜“ç†è§£åé¢éƒ¨åˆ†ä¸­çš„æ•°æ®ã€‚

```py
languages = []
data = []
X = []
y = []

with open("name2lang.txt", 'r') as f:
    #read the dataset
    for line in f:
        line = line.split(",")
        name = line[0].strip()
        lang = line[1].strip()
        if not lang in languages:
            languages.append(lang)
        X.append(name)
        y.append(lang)
        data.append((name, lang))

n_languages = len(languages)
print("Number of  Names: ", len(X))
print("Number of Languages: ",n_languages)
print("All Names: ", X)
print("All languages: ",languages)
print("Final Data: ", data)

```

![Load Dataset Nationality Predictor](img/7194b8e1e324a0c7205507f1a625b2d8.png)

Load Dataset Nationality Predictor

### **ç¬¬ä¸‰æ­¥:åˆ—è½¦æµ‹è¯•åˆ†å‰²**

æˆ‘ä»¬å°†[å°†æ•°æ®æŒ‰ 80:20 çš„æ¯”ä¾‹åˆ†æˆåŸ¹è®­å’Œæµ‹è¯•](https://www.askpython.com/python/examples/split-data-training-and-testing-set)ï¼Œå…¶ä¸­ 80%çš„æ•°æ®ç”¨äºåŸ¹è®­ï¼Œå…¶ä½™ 20%ç”¨äºæµ‹è¯•ã€‚

```py
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123, stratify = y)
print("Training Data: ", len(X_train))
print("Testing Data: ", len(X_test))

```

```py
Training Data:  16040
Testing Data:  4010

```

### **æ­¥éª¤ 4:ç¼–ç æ•°æ®**

å­—ç¬¦ç¼–ç å°†è¢«ç”¨ä½œåºåˆ—æ¨¡å‹çš„è¾“å…¥ï¼Œè€Œä¸æ˜¯åŸå§‹æ–‡æœ¬æ•°æ®ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»å¯¹è¾“å…¥è¿›è¡ŒåŠ å¯†ï¼Œå¹¶åœ¨å­—ç¬¦çº§åˆ«å¯¹å…¶è¿›è¡Œè¯†åˆ«ã€‚

ä¸€æ—¦æˆ‘ä»¬åœ¨å­—ç¬¦çº§åˆ›å»ºäº†ç¼–ç ï¼Œæˆ‘ä»¬éœ€è¦è¿æ¥æ‰€æœ‰çš„å­—ç¬¦çº§ç¼–ç æ¥è·å¾—æ•´ä¸ªå•è¯çš„ç¼–ç ã€‚è¿™ä¸€è¿‡ç¨‹é€‚ç”¨äºæ‰€æœ‰å§“åå’Œå›½ç±ã€‚

```py
all_letters = string.ascii_letters + ".,;"
print(string.ascii_letters)
n_letters = len(all_letters)

def name_rep(name):
  rep = torch.zeros(len(name), 1, n_letters)
  for index, letter in enumerate(name):
    pos = all_letters.find(letter)
    rep[index][0][pos] = 1
  return rep

```

ä¸Šé¢çš„å‡½æ•° name_rep ä¸ºåç§°ç”Ÿæˆä¸€æ¬¡æ€§ç¼–ç ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å£°æ˜ä¸€ä¸ªé›¶å¼ é‡ï¼Œè¾“å…¥å¤§å°ç­‰äºåå­—çš„é•¿åº¦ï¼Œå¤–éƒ¨å¤§å°ç­‰äºåˆ—è¡¨ä¸­çš„å…¨éƒ¨å­—ç¬¦æ•°ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¾ªç¯éå†æ¯ä¸ªå­—ç¬¦ä»¥æ ‡è¯†å­—æ¯çš„ç´¢å¼•ï¼Œå¹¶å°†è¯¥ç´¢å¼•ä½ç½®å€¼è®¾ç½®ä¸º 1ï¼Œå…¶ä½™å€¼ä¸º 0ã€‚

```py
def nat_rep(lang):
    return torch.tensor([languages.index(lang)], dtype = torch.long)

```

å¯¹å›½ç±è¿›è¡Œç¼–ç éµå¾ªçš„é€»è¾‘æ¯”å¯¹å§“åè¿›è¡Œç¼–ç ç®€å•å¾—å¤šã€‚æˆ‘ä»¬åªéœ€ç¡®å®šç‰¹å®šå›½ç±åœ¨æˆ‘ä»¬çš„å›½ç±åˆ—è¡¨ä¸­å‡ºç°çš„ç´¢å¼•ï¼Œä»¥å¯¹å›½ç±è¿›è¡Œç¼–ç ã€‚ç„¶åï¼Œç´¢å¼•è¢«æŒ‡å®šä¸ºç¼–ç ã€‚

### **ç¬¬äº”æ­¥:å»ºç«‹ç¥ç»ç½‘ç»œæ¨¡å‹**

æˆ‘ä»¬å°†ä½¿ç”¨ Pytorch å»ºç«‹ä¸€ä¸ª RNN æ¨¡å‹ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç±»æ¥å®ç°è¿™ä¸ªç›®æ ‡ã€‚

**init** å‡½æ•°(æ„é€ å‡½æ•°)å¸®åŠ©æˆ‘ä»¬åˆå§‹åŒ–ç½‘ç»œç‰¹å¾ï¼Œä¾‹å¦‚ä¸éšè—å±‚ç›¸å…³çš„æƒé‡å’Œåå·®ã€‚

```py
class RNN_net(nn.Module):

    def __init__(self, input_size, hidden_size, output_size):
        super(RNN_net, self).__init__()
        self.hidden_size = hidden_size
        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)
        self.i2o = nn.Linear(input_size + hidden_size, output_size)
        self.softmax = nn.LogSoftmax(dim = 1)

    def forward(self, input_, hidden):
        combined = torch.cat((input_, hidden), 1)
        hidden = self.i2h(combined)
        output = self.i2o(combined)
        output = self.softmax(output)
        return output, hidden

    def init_hidden(self):
        return torch.zeros(1, self.hidden_size)

```

forward å‡½æ•°é¦–å…ˆè¿æ¥è§’è‰²çš„è¾“å…¥å’Œéšè—è¡¨ç¤ºï¼Œç„¶åä½¿ç”¨ i2hã€i2o å’Œ softmax å±‚å°†å…¶ä½œä¸ºè¾“å…¥æ¥è®¡ç®—è¾“å‡ºæ ‡ç­¾ã€‚

```py
def infer(net, name):
    net.eval()
    name_ohe = name_rep(name)
    hidden = net.init_hidden()
    for i in range(name_ohe.size()[0]):
        output, hidden = net(name_ohe[i], hidden)
    return output
n_hidden = 128
net = RNN_net(n_letters, n_hidden, n_languages)
output = infer(net, "Adam")
index = torch.argmax(output)
print(output, index)

```

ç½‘ç»œå®ä¾‹å’Œäººåä½œä¸ºè¾“å…¥å‚æ•°ä¼ é€’ç»™ infer å‡½æ•°ã€‚æˆ‘ä»¬å°†ç½‘ç»œè®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œå¹¶åœ¨æ­¤å‡½æ•°ä¸­è®¡ç®—è¾“å…¥äººåçš„ä¸€é”®è¡¨ç¤ºã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ ¹æ®éšè—å¤§å°è®¡ç®—éšè—è¡¨ç¤ºï¼Œå¹¶åœ¨å°†è®¡ç®—çš„éšè—è¡¨ç¤ºè¿”å›åˆ°ç½‘ç»œä¹‹å‰å¾ªç¯æ‰€æœ‰å­—ç¬¦ã€‚

æœ€åï¼Œæˆ‘ä»¬å°†è®¡ç®—è¾“å‡ºï¼Œå³è¿™ä¸ªäººçš„å›½ç±ã€‚

### **ç¬¬å…­æ­¥:è®¡ç®— RNN æ¨¡å‹çš„ç²¾åº¦**

åœ¨ç»§ç»­è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œè®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

ä¸ºäº†è¾¾åˆ°åŒæ ·çš„ç›®çš„ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªè¯„ä¼°å‡½æ•°ï¼Œå°†ä»¥ä¸‹å†…å®¹ä½œä¸ºè¾“å…¥:

1.  ç½‘ç»œå®ä¾‹
2.  æ•°æ®ç‚¹çš„æ•°é‡
3.  k çš„å€¼
4.  x å’Œ Y æµ‹è¯•æ•°æ®

```py
def dataloader(npoints, X_, y_):
    to_ret = []
    for i in range(npoints):
        index_ = np.random.randint(len(X_))
        name, lang = X_[index_], y_[index_]
        to_ret.append((name, lang, name_rep(name), nat_rep(lang)))

    return to_ret

def eval(net, n_points, k, X_, y_):
     data_ = dataloader(n_points, X_, y_)
     correct = 0

     for name, language, name_ohe, lang_rep in data_:
         output = infer(net, name)
         val, indices = output.topk(k)
         if lang_rep in indices:
             correct += 1
     accuracy = correct/n_points
     return accuracy 

```

åœ¨å‡½æ•°å†…éƒ¨ï¼Œæˆ‘ä»¬å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œ:

1.  ä½¿ç”¨`data loader`åŠ è½½æ•°æ®ã€‚
2.  è¿­ä»£æ•°æ®åŠ è½½å™¨ä¸­å‡ºç°çš„æ‰€æœ‰äººåã€‚
3.  å¯¹è¾“å…¥è°ƒç”¨æ¨¡å‹å¹¶è·å¾—è¾“å‡ºã€‚
4.  è®¡ç®—é¢„æµ‹ç±»ã€‚
5.  è®¡ç®—æ­£ç¡®é¢„æµ‹çš„ç±»åˆ«æ€»æ•°
6.  è¿”å›æœ€ç»ˆç™¾åˆ†æ¯”ã€‚

### **ç¬¬ä¸ƒæ­¥:è®­ç»ƒ RNN æ¨¡å‹**

ä¸ºäº†è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å°†ç¼–å†™ä¸€ä¸ªç®€å•çš„å‡½æ•°æ¥è®­ç»ƒæˆ‘ä»¬çš„ç½‘ç»œã€‚

```py
def train(net, opt, criterion, n_points):
    opt.zero_grad()
    total_loss = 0
    data_ = dataloader(n_points, X_train, y_train)
    for name, language, name_ohe, lang_rep in data_:
        hidden = net.init_hidden()
        for i in range(name_ohe.size()[0]):
            output, hidden = net(name_ohe[i], hidden)
        loss = criterion(output, lang_rep)
        loss.backward(retain_graph=True)
        total_loss += loss  
    opt.step()       
    return total_loss/n_points

def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq = 5):
    criterion = nn.NLLLoss()
    opt = optim.SGD(net.parameters(), lr = lr, momentum = momentum)
    loss_arr = np.zeros(n_batches + 1)
    for i in range(n_batches):
        loss_arr[i + 1] = (loss_arr[i]*i + train(net, opt, criterion, batch_size))/(i + 1)
        if i%display_freq == display_freq - 1:
            clear_output(wait = True)
            print("Iteration number ", i + 1, "Top - 1 Accuracy:", round(eval(net, len(X_test), 1, X_test, y_test),4), 'Top-2 Accuracy:', round(eval(net, len(X_test), 2, X_test, y_test),4), 'Loss:', round(loss_arr[i]),4)
            plt.figure()
            plt.plot(loss_arr[1:i], "-*")
            plt.xlabel("Iteration")
            plt.ylabel("Loss")
            plt.show()
            print("\n\n")
n_hidden = 128
net = RNN_net(n_letters, n_hidden, n_languages)
train_setup(net, lr = 0.0005, n_batches = 100, batch_size = 256)

```

åœ¨å¯¹ 100 ä¸ªæ‰¹æ¬¡çš„æ¨¡å‹è¿›è¡Œè®­ç»ƒä¹‹åï¼Œæˆ‘ä»¬èƒ½å¤Ÿåˆ©ç”¨ RNN æ¨¡å‹å®ç° 66.5%çš„å‰ 1 åå‡†ç¡®åº¦å’Œ 79%çš„å‰ 2 åå‡†ç¡®åº¦ã€‚

![Loss Plot Nationality Predictor](img/85167e4cd5711943688293159e80c5af.png)

Loss Plot Nationality Predictor

### **ç¬¬å…«æ­¥:LSTM æ¨¡å¼åŸ¹è®­**

æˆ‘ä»¬è¿˜å°†è®¨è®ºå¦‚ä½•å®ç° LSTM æ¨¡å‹æ¥å¯¹äººåçš„å›½ç±è¿›è¡Œåˆ†ç±»ã€‚ä¸ºäº†è¾¾åˆ°åŒæ ·çš„ç›®çš„ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Pytorch å¹¶åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰çš„ LSTM ç±»ã€‚

```py
class LSTM_net(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(LSTM_net, self).__init__()
        self.hidden_size = hidden_size
        self.lstm_cell = nn.LSTM(input_size, hidden_size) #LSTM cell
        self.h2o = nn.Linear(hidden_size, output_size)
        self.softmax = nn.LogSoftmax(dim = 2)

    def forward(self, input_, hidden):
        out, hidden = self.lstm_cell(input_.view(1, 1, -1), hidden)
        output = self.h2o(hidden[0])
        output = self.softmax(output)
        return output.view(1, -1), hidden

    def init_hidden(self):
        return (torch.zeros(1, 1, self.hidden_size), torch.zeros(1, 1, self.hidden_size))

n_hidden = 128
net = LSTM_net(n_letters, n_hidden, n_languages)
train_setup(net, lr = 0.0005, n_batches = 100, batch_size = 256)

```

åœ¨å¯¹ 100 ä¸ªæ‰¹æ¬¡çš„æ¨¡å‹è¿›è¡Œè®­ç»ƒä¹‹åï¼Œæˆ‘ä»¬èƒ½å¤Ÿåˆ©ç”¨ LSTM æ¨¡å‹å®ç° 52.6%çš„å‰ 1 åå‡†ç¡®åº¦å’Œ 66.9%çš„å‰ 2 åå‡†ç¡®åº¦ã€‚

![Loss Plot Nationality Predictor LSTM](img/360c44c3f9152393d4710c056aed9ea3.png)

Loss Plot Nationality Predictor LSTM

* * *

## **ç»“è®º**

æ­å–œä½ ï¼æ‚¨åˆšåˆšå­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨ Pytorch æ„å»ºå›½ç±åˆ†ç±»æ¨¡å‹ã€‚å¸Œæœ›ä½ å–œæ¬¢å®ƒï¼ğŸ˜‡

å–œæ¬¢è¿™ä¸ªæ•™ç¨‹å—ï¼Ÿæ— è®ºå¦‚ä½•ï¼Œæˆ‘å»ºè®®ä½ çœ‹ä¸€ä¸‹ä¸‹é¢æåˆ°çš„æ•™ç¨‹:

1.  [ç”¨ Python åˆ†ç±»æœè£…å›¾åƒâ€”â€”å®Œå…¨æŒ‡å—](https://www.askpython.com/python/examples/classifying-clothing-images)
2.  [ä½¿ç”¨ Python è¿›è¡Œè‘¡è„é…’åˆ†ç±»â€”â€”ç®€å•æ˜“æ‡‚](https://www.askpython.com/python/wine-classification)

æ„Ÿè°¢æ‚¨æŠ½å‡ºæ—¶é—´ï¼å¸Œæœ›ä½ å­¦åˆ°äº†æ–°çš„ä¸œè¥¿ï¼ï¼ğŸ˜„

* * *