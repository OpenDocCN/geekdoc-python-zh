# Python ä¸­çš„é€»è¾‘å›žå½’

> åŽŸæ–‡ï¼š<https://realpython.com/logistic-regression-python/>

éšç€å¯ç”¨æ•°æ®çš„æ•°é‡ã€è®¡ç®—èƒ½åŠ›çš„å¼ºåº¦å’Œç®—æ³•æ”¹è¿›çš„æ•°é‡ä¸æ–­ä¸Šå‡ï¼Œ[æ•°æ®ç§‘å­¦](https://realpython.com/tutorials/data-science/)å’Œ[æœºå™¨å­¦ä¹ ](https://realpython.com/tutorials/machine-learning/)çš„é‡è¦æ€§ä¹Ÿåœ¨å¢žåŠ ã€‚**åˆ†ç±»**æ˜¯æœºå™¨å­¦ä¹ æœ€é‡è¦çš„é¢†åŸŸä¹‹ä¸€ï¼Œè€Œ**é€»è¾‘å›žå½’**æ˜¯å…¶åŸºæœ¬æ–¹æ³•ä¹‹ä¸€ã€‚åˆ°æœ¬æ•™ç¨‹ç»“æŸæ—¶ï¼Œæ‚¨å°†å·²ç»å­¦ä¹ äº†åˆ†ç±»çš„ä¸€èˆ¬çŸ¥è¯†ï¼Œç‰¹åˆ«æ˜¯é€»è¾‘å›žå½’çš„åŸºç¡€çŸ¥è¯†ï¼Œä»¥åŠå¦‚ä½•åœ¨ Python ä¸­å®žçŽ°é€»è¾‘å›žå½’ã€‚

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ :

*   ä»€ä¹ˆæ˜¯é€»è¾‘å›žå½’
*   é€»è¾‘å›žå½’æœ‰ä»€ä¹ˆç”¨
*   é€»è¾‘å›žå½’å¦‚ä½•å·¥ä½œ
*   å¦‚ä½•åœ¨ Python ä¸­é€æ­¥å®žçŽ°é€»è¾‘å›žå½’

**å…è´¹å¥–åŠ±:** [ç‚¹å‡»æ­¤å¤„èŽ·å–å…è´¹çš„ NumPy èµ„æºæŒ‡å—](#)ï¼Œå®ƒä¼šä¸ºæ‚¨æŒ‡å‡ºæé«˜ NumPy æŠ€èƒ½çš„æœ€ä½³æ•™ç¨‹ã€è§†é¢‘å’Œä¹¦ç±ã€‚

## åˆ†ç±»

[åˆ†ç±»](https://en.wikipedia.org/wiki/Statistical_classification)æ˜¯[ç›‘ç£æœºå™¨å­¦ä¹ ](https://en.wikipedia.org/wiki/Supervised_learning)çš„ä¸€ä¸ªéžå¸¸é‡è¦çš„é¢†åŸŸã€‚å¤§é‡é‡è¦çš„æœºå™¨å­¦ä¹ é—®é¢˜éƒ½å±žäºŽè¿™ä¸ªé¢†åŸŸã€‚åˆ†ç±»æ–¹æ³•æœ‰å¾ˆå¤šç§ï¼Œlogistic å›žå½’æ˜¯å…¶ä¸­ä¸€ç§ã€‚

[*Remove ads*](/account/join/)

### ä»€ä¹ˆæ˜¯åˆ†ç±»ï¼Ÿ

ç›‘ç£æœºå™¨å­¦ä¹ ç®—æ³•å®šä¹‰äº†æ•æ‰æ•°æ®ä¹‹é—´å…³ç³»çš„æ¨¡åž‹ã€‚**åˆ†ç±»**æ˜¯ç›‘ç£æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé¢†åŸŸï¼Œå®ƒè¯•å›¾æ ¹æ®æŸä¸ªå®žä½“çš„ç‰¹å¾æ¥é¢„æµ‹å®ƒå±žäºŽå“ªä¸ªç±»æˆ–ç±»åˆ«ã€‚

ä¾‹å¦‚ï¼Œä½ å¯èƒ½ä¼šåˆ†æžæŸä¸ªå…¬å¸çš„å‘˜å·¥ï¼Œå¹¶è¯•å›¾å»ºç«‹å¯¹**ç‰¹å¾**æˆ–**å˜é‡**çš„ä¾èµ–å…³ç³»ï¼Œå¦‚æ•™è‚²æ°´å¹³ã€åœ¨å½“å‰èŒä½ä¸Šçš„å¹´æ•°ã€å¹´é¾„ã€å·¥èµ„ã€æ™‹å‡æœºä¼šç­‰ç­‰ã€‚ä¸Žå•ä¸ªé›‡å‘˜ç›¸å…³çš„æ•°æ®é›†æ˜¯ä¸€ä¸ª**è§‚å¯Ÿ**ã€‚ç‰¹å¾æˆ–[å˜é‡](https://realpython.com/python-variables/)å¯ä»¥é‡‡å–ä¸¤ç§å½¢å¼ä¹‹ä¸€:

1.  **ç‹¬ç«‹å˜é‡**ï¼Œä¹Ÿç§°ä¸ºè¾“å…¥æˆ–é¢„æµ‹å€¼ï¼Œä¸ä¾èµ–äºŽå…¶ä»–æ„Ÿå…´è¶£çš„ç‰¹å¾(æˆ–è€…è‡³å°‘ä½ å‡è®¾æ˜¯ä¸ºäº†åˆ†æž)ã€‚
2.  **å› å˜é‡**ï¼Œä¹Ÿç§°ä¸ºè¾“å‡ºæˆ–å“åº”ï¼Œå–å†³äºŽè‡ªå˜é‡ã€‚

åœ¨ä¸Šé¢åˆ†æžå‘˜å·¥çš„ä¾‹å­ä¸­ï¼Œæ‚¨å¯èƒ½å‡è®¾æ•™è‚²æ°´å¹³ã€åœ¨å½“å‰èŒä½ä¸Šçš„æ—¶é—´å’Œå¹´é¾„æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼Œå¹¶å°†å®ƒä»¬è§†ä¸ºè¾“å…¥ã€‚å·¥èµ„å’Œæ™‹å‡æœºä¼šå¯èƒ½æ˜¯ä¾èµ–äºŽæŠ•å…¥çš„äº§å‡ºã€‚

**æ³¨:**æœ‰ç›‘ç£çš„æœºå™¨å­¦ä¹ ç®—æ³•åˆ†æžå¤§é‡çš„è§‚å¯Ÿå€¼ï¼Œå¹¶è¯•å›¾ç”¨æ•°å­¦æ–¹å¼è¡¨è¾¾è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚è¿™äº›ä¾èµ–å…³ç³»çš„æ•°å­¦è¡¨ç¤ºå°±æ˜¯**æ¨¡åž‹**ã€‚

å› å˜é‡çš„æ€§è´¨åŒºåˆ†äº†[å›žå½’](https://realpython.com/linear-regression-in-python/#regression)å’Œåˆ†ç±»é—®é¢˜ã€‚**å›žå½’**é—®é¢˜æœ‰è¿žç»­ä¸”é€šå¸¸æ— ç•Œçš„è¾“å‡ºã€‚ä¸€ä¸ªä¾‹å­æ˜¯å½“ä½ æ ¹æ®ç»éªŒå’Œæ•™è‚²æ°´å¹³æ¥ä¼°ç®—å·¥èµ„æ—¶ã€‚å¦ä¸€æ–¹é¢ï¼Œ**åˆ†ç±»**é—®é¢˜å…·æœ‰ç¦»æ•£ä¸”æœ‰é™çš„è¾“å‡ºï¼Œç§°ä¸º**ç±»**æˆ–**ç±»**ã€‚ä¾‹å¦‚ï¼Œé¢„æµ‹ä¸€ä¸ªå‘˜å·¥æ˜¯å¦å°†è¢«æå‡(å¯¹æˆ–é”™)æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ã€‚

åˆ†ç±»é—®é¢˜ä¸»è¦æœ‰ä¸¤ç§ç±»åž‹:

1.  **äºŒè¿›åˆ¶**æˆ–**äºŒé¡¹å¼åˆ†ç±»:**æ­£å¥½ä¸¤ä¸ªç±»åˆ«å¯ä¾›é€‰æ‹©(é€šå¸¸æ˜¯ 0 å’Œ 1ï¼ŒçœŸå’Œå‡ï¼Œæˆ–æ­£å’Œè´Ÿ)
2.  **å¤šç±»**æˆ–**å¤šé¡¹åˆ†ç±»:**ä¸‰ç±»æˆ–æ›´å¤šç±»çš„è¾“å‡ºå¯ä¾›é€‰æ‹©

å¦‚æžœåªæœ‰ä¸€ä¸ªè¾“å…¥å˜é‡ï¼Œé‚£ä¹ˆé€šå¸¸ç”¨ð‘¥.è¡¨ç¤ºå¯¹äºŽå¤šä¸ªè¾“å…¥ï¼Œæ‚¨é€šå¸¸ä¼šçœ‹åˆ°å‘é‡ç¬¦å·ð± = (ð‘¥â‚ï¼Œâ€¦ï¼Œð‘¥áµ£)ï¼Œå…¶ä¸­ð‘Ÿæ˜¯é¢„æµ‹å€¼(æˆ–ç‹¬ç«‹ç‰¹å¾)çš„æ•°é‡ã€‚è¾“å‡ºå˜é‡é€šå¸¸ç”¨ð‘¦è¡¨ç¤ºï¼Œå–å€¼ä¸º 0 æˆ– 1ã€‚

### ä»€ä¹ˆæ—¶å€™éœ€è¦åˆ†ç±»ï¼Ÿ

ä½ å¯ä»¥åœ¨å¾ˆå¤šç§‘æŠ€é¢†åŸŸåº”ç”¨åˆ†ç±»ã€‚ä¾‹å¦‚ï¼Œæ–‡æœ¬åˆ†ç±»ç®—æ³•ç”¨äºŽåŒºåˆ†åˆæ³•å’Œåžƒåœ¾é‚®ä»¶ï¼Œä»¥åŠæ­£é¢å’Œè´Ÿé¢è¯„è®ºã€‚æ‚¨å¯ä»¥æŸ¥çœ‹ä½¿ç”¨ Python å’Œ Keras çš„[å®žç”¨æ–‡æœ¬åˆ†ç±»æ¥æ·±å…¥äº†è§£è¿™ä¸ªä¸»é¢˜ã€‚å…¶ä»–ä¾‹å­åŒ…æ‹¬åŒ»ç–—åº”ç”¨ã€ç”Ÿç‰©åˆ†ç±»ã€ä¿¡ç”¨è¯„åˆ†ç­‰ç­‰ã€‚](https://realpython.com/python-keras-text-classification/)

å›¾åƒè¯†åˆ«ä»»åŠ¡é€šå¸¸è¢«è¡¨ç¤ºä¸ºåˆ†ç±»é—®é¢˜ã€‚ä¾‹å¦‚ï¼Œä½ å¯èƒ½ä¼šé—®ä¸€å¹…å›¾åƒæ˜¯å¦æç»˜äº†ä¸€å¼ äººè„¸ï¼Œæˆ–è€…å®ƒæ˜¯ä¸€åªè€é¼ è¿˜æ˜¯ä¸€åªå¤§è±¡ï¼Œæˆ–è€…å®ƒä»£è¡¨ 0 åˆ° 9 ä¸­çš„å“ªä¸€ä¸ªæ•°å­—ï¼Œç­‰ç­‰ã€‚è¦äº†è§£æ›´å¤šè¿™æ–¹é¢çš„å†…å®¹ï¼Œè¯·æŸ¥çœ‹ç”¨ Python å®žçŽ°çš„[ä¼ ç»Ÿäººè„¸æ£€æµ‹](https://realpython.com/traditional-face-detection-python/)å’Œç”¨ Python å®žçŽ°çš„[äººè„¸è¯†åˆ«ï¼Œä¸åˆ° 25 è¡Œä»£ç ](https://realpython.com/face-recognition-with-python/)ã€‚

## é€»è¾‘å›žå½’æ¦‚è¿°

é€»è¾‘å›žå½’æ˜¯ä¸€ç§åŸºæœ¬çš„åˆ†ç±»æŠ€æœ¯ã€‚å±žäºŽ **[çº¿æ€§åˆ†ç±»å™¨](https://en.wikipedia.org/wiki/Linear_classifier)** çš„ä¸€ç»„ï¼Œæœ‰ç‚¹ç±»ä¼¼äºŽå¤šé¡¹å¼å’Œ [**çº¿æ€§å›žå½’**](https://realpython.com/linear-regression-in-python/) ã€‚é€»è¾‘å›žå½’å¿«é€Ÿä¸”ç›¸å¯¹ç®€å•ï¼Œä¾¿äºŽä½ è§£è¯»ç»“æžœã€‚å°½ç®¡å®ƒæœ¬è´¨ä¸Šæ˜¯ä¸€ç§äºŒå…ƒåˆ†ç±»çš„æ–¹æ³•ï¼Œä½†å®ƒä¹Ÿå¯ä»¥åº”ç”¨äºŽå¤šç±»é—®é¢˜ã€‚

### æ•°å­¦å…ˆå†³æ¡ä»¶

ä¸ºäº†ç†è§£ä»€ä¹ˆæ˜¯é€»è¾‘å›žå½’ä»¥åŠå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œä½ éœ€è¦ç†è§£ sigmoid å‡½æ•° T1 å’Œ T2 è‡ªç„¶å¯¹æ•°å‡½æ•° T3ã€‚

æ­¤å›¾æ˜¾ç¤ºäº†ä¸€äº›å¯å˜ð‘¥:çš„ s å½¢å‡½æ•°(æˆ– s å½¢æ›²çº¿)

[![Sigmoid Function](img/1bf189c102f2466566c2da8e0ab13649.png)](https://files.realpython.com/media/log-reg-1.e32deaa7cbac.png)

åœ¨ sigmoid å‡½æ•°çš„å¤§éƒ¨åˆ†èŒƒå›´å†…ï¼Œå…¶å€¼éžå¸¸æŽ¥è¿‘ 0 æˆ– 1ã€‚è¿™ä¸€äº‹å®žä½¿å®ƒé€‚åˆåº”ç”¨äºŽåˆ†ç±»æ–¹æ³•ã€‚

æ­¤å›¾æç»˜äº†æŸä¸ªå˜é‡ð‘¥çš„è‡ªç„¶å¯¹æ•° log(ð‘¥ï¼Œð‘¥å€¼åœ¨ 0 å’Œ 1 ä¹‹é—´:

[![Natural Logarithm](img/789eb13540cb60facc98aa08d1477c20.png)](https://files.realpython.com/media/log-reg-4.81e9806a86fa.png)

å½“ð‘¥æŽ¥è¿‘é›¶æ—¶ï¼Œð‘¥çš„è‡ªç„¶å¯¹æ•°å‘è´Ÿæ— ç©·å¤§ä¸‹é™ã€‚å½“ð‘¥ = 1 æ—¶ï¼Œlog(ð‘¥)æ˜¯ 0ã€‚å¯¹æ•°(1 ð‘¥).)åˆ™ç›¸å

æ³¨æ„ï¼Œä½ ç»å¸¸ä¼šå‘çŽ°åœ¨ä¸­ç”¨**è¡¨ç¤ºçš„è‡ªç„¶å¯¹æ•°ï¼Œè€Œä¸æ˜¯ **log** ã€‚åœ¨ Python ä¸­ï¼Œ`math.log(x)`å’Œ`numpy.log(x)`ä»£è¡¨`x`çš„è‡ªç„¶å¯¹æ•°ï¼Œæ‰€ä»¥åœ¨æœ¬æ•™ç¨‹ä¸­æ‚¨å°†éµå¾ªè¿™ç§ç¬¦å·ã€‚**

[*Remove ads*](/account/join/)

### é—®é¢˜è¡¨è¿°

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†çœ‹åˆ°å¯¹åº”ç”¨äºŽäºŒå…ƒåˆ†ç±»çš„é€»è¾‘å›žå½’çš„å¸¸è§æƒ…å†µçš„è§£é‡Šã€‚å½“ä½ åœ¨è‡ªå˜é‡é›†ð± = (ð‘¥â‚ï¼Œâ€¦ï¼Œð‘¥áµ£)ä¸Šå®žçŽ°æŸå› å˜é‡ð‘¦çš„é€»è¾‘å›žå½’æ—¶ï¼Œå…¶ä¸­ð‘Ÿæ˜¯é¢„æµ‹å™¨(æˆ–è¾“å…¥)çš„æ•°é‡ï¼Œä½ ä»Žé¢„æµ‹å™¨çš„å·²çŸ¥å€¼ð±áµ¢å’Œæ¯ä¸ªè§‚æµ‹å€¼å¯¹åº”çš„å®žé™…å“åº”(æˆ–è¾“å‡º)ð‘¦áµ¢å¼€å§‹ð‘– = 1ï¼Œâ€¦ï¼Œ1ã€‚

ä½ çš„ç›®æ ‡æ˜¯æ‰¾åˆ°**é€»è¾‘å›žå½’å‡½æ•°** ð‘(ð±)ä½¿å¾—**é¢„æµ‹å“åº”** ð‘(ð±áµ¢)å°½å¯èƒ½æŽ¥è¿‘æ¯æ¬¡è§‚å¯Ÿçš„**å®žé™…å“åº”**ð‘¦áµ¢ð‘–= 1ï¼Œâ€¦ï¼Œð‘›.è®°ä½ï¼Œåœ¨äºŒè¿›åˆ¶åˆ†ç±»é—®é¢˜ä¸­ï¼Œå®žé™…å“åº”åªèƒ½æ˜¯ 0 æˆ– 1ï¼è¿™æ„å‘³ç€æ¯ä¸ªð‘(ð±áµ¢)åº”è¯¥æŽ¥è¿‘ 0 æˆ– 1ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä½¿ç”¨ sigmoid å‡½æ•°å¾ˆæ–¹ä¾¿ã€‚

ä¸€æ—¦ä½ æœ‰äº†é€»è¾‘å›žå½’å‡½æ•°ð‘(ð±ï¼Œä½ å°±å¯ä»¥ç”¨å®ƒæ¥é¢„æµ‹æ–°çš„å’ŒæœªçŸ¥çš„è¾“å…¥çš„è¾“å‡ºï¼Œå‡è®¾åŸºæœ¬çš„æ•°å­¦ä¾èµ–å…³ç³»ä¸å˜ã€‚

### æ–¹æ³•å­¦

é€»è¾‘å›žå½’æ˜¯ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ï¼Œå› æ­¤æ‚¨å°†ä½¿ç”¨ä¸€ä¸ªçº¿æ€§å‡½æ•°ð‘“(ð±) = ð‘â‚€ + ð‘â‚ð‘¥â‚ + â‹¯ + ð‘áµ£ð‘¥áµ£ï¼Œä¹Ÿç§°ä¸º **logit** ã€‚å˜é‡ð‘â‚€ã€ð‘â‚ã€â€¦ã€ð‘áµ£æ˜¯å›žå½’ç³»æ•°çš„**ä¼°è®¡é‡**ï¼Œä¹Ÿç§°ä¸º**é¢„æµ‹æƒé‡**æˆ–ç®€ç§°ä¸º**ç³»æ•°**ã€‚

é€»è¾‘å›žå½’å‡½æ•°ð‘(ð±)æ˜¯ð‘“(ð±): ð‘(ð±çš„ sigmoid å‡½æ•°)= 1 / (1 + exp(âˆ’ð‘“(ð±)).å› æ­¤ï¼Œå®ƒé€šå¸¸æŽ¥è¿‘ 0 æˆ– 1ã€‚å‡½æ•°ð‘(ð±)é€šå¸¸è¢«è§£é‡Šä¸ºç»™å®šð±çš„è¾“å‡ºç­‰äºŽ 1 çš„é¢„æµ‹æ¦‚çŽ‡ã€‚å› æ­¤ï¼Œ1ð‘(ð‘¥)æ˜¯è¾“å‡ºä¸º 0 çš„æ¦‚çŽ‡ã€‚

é€»è¾‘å›žå½’ç¡®å®šæœ€ä½³é¢„æµ‹æƒé‡ð‘â‚€ã€ð‘â‚ã€â€¦ã€ð‘áµ£ï¼Œä½¿å¾—å‡½æ•°ð‘(ð±å°½å¯èƒ½æŽ¥è¿‘æ‰€æœ‰å®žé™…å“åº”ð‘¦áµ¢ã€ð‘– = 1ã€â€¦ã€ð‘›ï¼Œå…¶ä¸­ð‘›æ˜¯è§‚å¯Ÿæ¬¡æ•°ã€‚ä½¿ç”¨å¯ç”¨è§‚æµ‹å€¼è®¡ç®—æœ€ä½³æƒé‡çš„è¿‡ç¨‹è¢«ç§°ä¸º**æ¨¡åž‹è®­ç»ƒ**æˆ–**æ‹Ÿåˆ**ã€‚

ä¸ºäº†å¾—åˆ°æœ€å¥½çš„æƒé‡ï¼Œä½ é€šå¸¸æœ€å¤§åŒ–æ‰€æœ‰è§‚æµ‹å€¼çš„**å¯¹æ•°ä¼¼ç„¶å‡½æ•°(llf)**ð‘–= 1ï¼Œâ€¦ï¼Œð‘›.è¿™ç§æ–¹æ³•è¢«ç§°ä¸º**æœ€å¤§ä¼¼ç„¶ä¼°è®¡**ï¼Œç”±ç­‰å¼ llf =Ïƒáµ¢(ð‘¦áµ¢log(ð‘(ð±áµ¢)+(1ð‘¦áµ¢)å¯¹æ•°(1 ð‘(ð±áµ¢))).)è¡¨ç¤º

å½“ð‘¦áµ¢ = 0 æ—¶ï¼Œç›¸åº”è§‚æµ‹å€¼çš„ LLF ç­‰äºŽ log(1 ð‘(ð±áµ¢)).å¦‚æžœð‘(ð±áµ¢)æŽ¥è¿‘ð‘¦áµ¢ = 0ï¼Œé‚£ä¹ˆ log(1ð‘(ð±áµ¢))æŽ¥è¿‘ 0ã€‚è¿™å°±æ˜¯ä½ æƒ³è¦çš„ç»“æžœã€‚å¦‚æžœð‘(ð±áµ¢)è¿œç¦» 0ï¼Œåˆ™ log(1ð‘(ð±áµ¢)æ˜¾è‘—ä¸‹é™ã€‚ä½ ä¸æƒ³è¦é‚£ä¸ªç»“æžœï¼Œå› ä¸ºä½ çš„ç›®æ ‡æ˜¯èŽ·å¾—æœ€å¤§çš„ LLFã€‚ç±»ä¼¼åœ°ï¼Œå½“ð‘¦áµ¢ = 1 æ—¶ï¼Œè¯¥è§‚å¯Ÿçš„ LLF æ˜¯ð‘¦áµ¢ log(ð‘(ð±áµ¢)).å¦‚æžœð‘(ð±áµ¢)æŽ¥è¿‘ð‘¦áµ¢ = 1ï¼Œé‚£ä¹ˆ log(ð‘(ð±áµ¢))æŽ¥è¿‘ 0ã€‚å¦‚æžœð‘(ð±áµ¢)è¿œç¦» 1ï¼Œé‚£ä¹ˆ log(ð‘(ð±áµ¢)æ˜¯ä¸€ä¸ªå¤§çš„è´Ÿæ•°ã€‚

æœ‰å‡ ç§æ•°å­¦æ–¹æ³•å¯ä»¥è®¡ç®—æœ€å¤§ LLF å¯¹åº”çš„æœ€ä½³æƒé‡ï¼Œä½†è¿™è¶…å‡ºäº†æœ¬æ•™ç¨‹çš„èŒƒå›´ã€‚çŽ°åœ¨ï¼Œæ‚¨å¯ä»¥å°†è¿™äº›ç»†èŠ‚ç•™ç»™æ‚¨å°†åœ¨è¿™é‡Œå­¦ä¹ ä½¿ç”¨çš„é€»è¾‘å›žå½’ Python åº“ï¼

ä¸€æ—¦ç¡®å®šäº†å®šä¹‰å‡½æ•°ð‘(ð±çš„æœ€ä½³æƒé‡ï¼Œå°±å¯ä»¥å¾—åˆ°ä»»ä½•ç»™å®šè¾“å…¥ð±áµ¢.çš„é¢„æµ‹è¾“å‡ºð‘(ð±áµ¢å¯¹äºŽæ¯ä¸ªè§‚å¯Ÿå€¼ð‘– = 1ï¼Œâ€¦ï¼Œð‘›ï¼Œå¦‚æžœð‘(ð±áµ¢) > 0.5ï¼Œé¢„æµ‹è¾“å‡ºä¸º 1ï¼Œå¦åˆ™ä¸º 0ã€‚é˜ˆå€¼ä¸ä¸€å®šæ˜¯ 0.5ï¼Œä½†é€šå¸¸æ˜¯ 0.5ã€‚å¦‚æžœæ›´é€‚åˆæ‚¨çš„æƒ…å†µï¼Œæ‚¨å¯ä»¥å®šä¹‰ä¸€ä¸ªè¾ƒä½Žæˆ–è¾ƒé«˜çš„å€¼ã€‚

ð‘(ð±)å’Œð‘“(ð±)ä¹‹é—´è¿˜æœ‰ä¸€ä¸ªæ›´é‡è¦çš„å…³ç³»ï¼Œé‚£å°±æ˜¯ log(ð‘(ð±)/(1ð‘(ð±)))= ð‘“(ð±).è¿™ä¸ªç­‰å¼è§£é‡Šäº†ä¸ºä»€ä¹ˆð‘“(ð±æ˜¯é€»è¾‘ã€‚è¿™æ„å‘³ç€å½“ð‘“(ð±= 0 æ—¶ï¼Œð‘(ð±= 0.5ï¼Œå¦‚æžœð‘“(ð±ä¸º 0ï¼Œåˆ™é¢„æµ‹è¾“å‡ºä¸º 1ï¼Œå¦åˆ™ä¸º 0ã€‚

### åˆ†ç±»æ€§èƒ½

äºŒå…ƒåˆ†ç±»æœ‰å››ç§å¯èƒ½çš„[ç±»åž‹çš„ç»“æžœ](https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative):

1.  **çœŸå¦å®š:**æ­£ç¡®é¢„æµ‹çš„å¦å®š(é›¶)
2.  **çœŸé˜³æ€§:**æ­£ç¡®é¢„æµ‹é˜³æ€§(ä¸ª)
3.  **å‡é˜´æ€§:**é”™è¯¯é¢„æµ‹çš„é˜´æ€§(é›¶)
4.  **å‡é˜³æ€§:**é”™è¯¯é¢„æµ‹çš„é˜³æ€§(ä¸ª)

æ‚¨é€šå¸¸é€šè¿‡æ¯”è¾ƒå®žé™…è¾“å‡ºå’Œé¢„æµ‹è¾“å‡ºå¹¶è®¡ç®—æ­£ç¡®å’Œä¸æ­£ç¡®çš„é¢„æµ‹æ¥è¯„ä¼°åˆ†ç±»å™¨çš„æ€§èƒ½ã€‚

**åˆ†ç±»ç²¾åº¦**æœ€ç›´è§‚çš„æŒ‡æ ‡æ˜¯æ­£ç¡®é¢„æµ‹æ•°ä¸Žé¢„æµ‹(æˆ–è§‚æµ‹)æ€»æ•°çš„æ¯”å€¼ã€‚äºŒå…ƒåˆ†ç±»å™¨çš„å…¶ä»–æŒ‡æ ‡åŒ…æ‹¬:

*   **[é˜³æ€§é¢„æµ‹å€¼](https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values#Positive_predictive_value)** æ˜¯çœŸé˜³æ€§æ•°é‡ä¸ŽçœŸé˜³æ€§å’Œå‡é˜³æ€§æ•°é‡ä¹‹å’Œçš„æ¯”å€¼ã€‚
*   **[é˜´æ€§é¢„æµ‹å€¼](https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values#Negative_predictive_value)** æ˜¯çœŸé˜´æ€§æ•°é‡ä¸ŽçœŸé˜´æ€§å’Œå‡é˜´æ€§æ•°é‡ä¹‹å’Œçš„æ¯”å€¼ã€‚
*   (ä¹Ÿç§°ä¸ºå›žå¿†æˆ–çœŸé˜³æ€§çŽ‡)æ˜¯çœŸé˜³æ€§çš„æ•°é‡ä¸Žå®žé™…é˜³æ€§çš„æ•°é‡ä¹‹æ¯”ã€‚
*   (æˆ–çœŸé˜´æ€§çŽ‡)æ˜¯çœŸé˜´æ€§æ•°ä¸Žå®žé™…é˜´æ€§æ•°ä¹‹æ¯”ã€‚

æœ€åˆé€‚çš„æŒ‡æ ‡å–å†³äºŽå…´è¶£é—®é¢˜ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†ä½¿ç”¨æœ€ç®€å•çš„åˆ†ç±»ç²¾åº¦å½¢å¼ã€‚

[*Remove ads*](/account/join/)

### å•å˜é‡é€»è¾‘å›žå½’

**å•å˜é‡é€»è¾‘å›žå½’**æ˜¯é€»è¾‘å›žå½’æœ€ç›´æŽ¥çš„ä¾‹å­ã€‚è‡ªå˜é‡(æˆ–ç‰¹å¾)åªæœ‰ä¸€ä¸ªï¼Œå°±æ˜¯ð± = ð‘¥.ä¸‹å›¾è¯´æ˜Žäº†å•å˜é‡é€»è¾‘å›žå½’:

[![1D Logistic Regression](img/35e3ba6285f8fb3e941f99d3861b8bae.png)](https://files.realpython.com/media/log-reg-2.e88a21607ba3.png)

è¿™é‡Œï¼Œæ‚¨æœ‰ä¸€ç»„ç»™å®šçš„è¾“å…¥è¾“å‡º(æˆ–ð‘¥-ð‘¦)å¯¹ï¼Œç”¨ç»¿è‰²åœ†åœˆè¡¨ç¤ºã€‚è¿™äº›æ˜¯ä½ çš„è§‚å¯Ÿã€‚è®°ä½ð‘¦åªèƒ½æ˜¯ 0 æˆ– 1ã€‚ä¾‹å¦‚ï¼Œæœ€å·¦è¾¹çš„ç»¿è‰²åœ†åœˆçš„è¾“å…¥ð‘¥ = 0ï¼Œå®žé™…è¾“å‡ºð‘¦ = 0ã€‚æœ€å³è¾¹çš„è§‚å¯Ÿç»“æžœæ˜¯ð‘¥ = 9ï¼Œð‘¦ = 1ã€‚

é€»è¾‘å›žå½’æ‰¾åˆ°å¯¹åº”äºŽæœ€å¤§ LLF çš„æƒé‡ð‘â‚€å’Œð‘â‚ã€‚è¿™äº›æƒé‡å®šä¹‰äº† logit ð‘“(ð‘¥) = ð‘â‚€ + ð‘â‚ð‘¥ï¼Œè¿™æ˜¯é»‘è‰²è™šçº¿ã€‚ä»–ä»¬è¿˜å®šä¹‰äº†é¢„æµ‹æ¦‚çŽ‡ð‘(ð‘¥) = 1 / (1 + exp(âˆ’ð‘“(ð‘¥))ï¼Œè¿™é‡Œæ˜¾ç¤ºä¸ºé»‘è‰²å®žçº¿ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé˜ˆå€¼ð‘(ð‘¥) = 0.5 å’Œð‘“(ð‘¥) = 0 å¯¹åº”äºŽç•¥é«˜äºŽ 3 çš„ð‘¥å€¼ã€‚è¯¥å€¼æ˜¯é¢„æµ‹è¾“å‡ºä¸º 0 å’Œ 1 çš„è¾“å…¥ä¹‹é—´çš„ç•Œé™ã€‚

### å¤šå˜é‡é€»è¾‘å›žå½’

**å¤šå˜é‡é€»è¾‘å›žå½’**æœ‰å¤šä¸ªè¾“å…¥å˜é‡ã€‚è¯¥å›¾æ˜¾ç¤ºäº†å…·æœ‰ä¸¤ä¸ªç‹¬ç«‹å˜é‡çš„åˆ†ç±»ï¼Œð‘¥â‚å’Œð‘¥â‚‚:

[![2D Logistic Regression](img/6fc32fa8b3b0f37c94ee181116e30110.png)](https://files.realpython.com/media/log-reg-3.b1634d335c4f.png)

è¯¥å›¾ä¸Žå•å˜é‡å›¾ä¸åŒï¼Œå› ä¸ºä¸¤ä¸ªè½´éƒ½ä»£è¡¨è¾“å…¥ã€‚è¾“å‡ºçš„é¢œè‰²ä¹Ÿä¸åŒã€‚ç™½è‰²åœ†åœˆè¡¨ç¤ºåˆ†ç±»ä¸ºé›¶çš„è§‚å¯Ÿå€¼ï¼Œè€Œç»¿è‰²åœ†åœˆè¡¨ç¤ºåˆ†ç±»ä¸ºä¸€çš„è§‚å¯Ÿå€¼ã€‚

é€»è¾‘å›žå½’ç¡®å®šä½¿ LLF æœ€å¤§åŒ–çš„ð‘â‚€ã€ð‘â‚å’Œð‘â‚‚çš„æƒé‡ã€‚ä¸€æ—¦ä½ æœ‰äº†ð‘â‚€ã€ð‘â‚å’Œð‘â‚‚ï¼Œä½ å°±èƒ½å¾—åˆ°:

*   **the logit**ð‘¥â‚‚ð‘“(ð‘¥â‚)=ð‘â‚€+ð‘â‚ð‘¥â‚+ð‘â‚‚ð‘¥â‚‚
*   **æ¦‚çŽ‡** ð‘(ð‘¥â‚ï¼Œð‘¥â‚‚) = 1 / (1 + exp(âˆ’ð‘“(ð‘¥â‚ï¼Œð‘¥â‚‚))

è™šçº¿é»‘çº¿å°†ä¸¤ä¸ªç±»åˆ«çº¿æ€§åˆ†å¼€ã€‚è¿™æ¡çº¿å¯¹åº”äºŽð‘¥â‚‚çš„ð‘(ð‘¥â‚)= 0.5 å’Œð‘¥â‚‚çš„ð‘“(ð‘¥â‚)= 0ã€‚

### æ­£è§„åŒ–

[](https://realpython.com/linear-regression-in-python/#underfitting-and-overfitting)**è¿‡æ‹Ÿåˆæ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€ä¸¥é‡çš„é—®é¢˜ä¹‹ä¸€ã€‚å½“æ¨¡åž‹å¯¹è®­ç»ƒæ•°æ®å­¦ä¹ å¾—å¤ªå¥½æ—¶ï¼Œå°±ä¼šå‘ç”Ÿè¿™ç§æƒ…å†µã€‚ç„¶åŽï¼Œè¯¥æ¨¡åž‹ä¸ä»…å­¦ä¹ æ•°æ®ä¹‹é—´çš„å…³ç³»ï¼Œè¿˜å­¦ä¹ æ•°æ®é›†ä¸­çš„å™ªå£°ã€‚è¿‡åº¦æ‹Ÿåˆçš„æ¨¡åž‹åœ¨ç”¨äºŽæ‹Ÿåˆå®ƒä»¬çš„æ•°æ®(è®­ç»ƒæ•°æ®)ä¸‹å¾€å¾€å…·æœ‰è‰¯å¥½çš„æ€§èƒ½ï¼Œä½†æ˜¯åœ¨æœªçœ‹åˆ°çš„æ•°æ®(æˆ–æµ‹è¯•æ•°æ®ï¼Œå³æœªç”¨äºŽæ‹Ÿåˆæ¨¡åž‹çš„æ•°æ®)ä¸‹è¡¨çŽ°ä¸ä½³ã€‚*

*è¿‡åº¦æ‹Ÿåˆé€šå¸¸å‘ç”Ÿåœ¨å¤æ‚æ¨¡åž‹ä¸­ã€‚**æ­£åˆ™åŒ–**é€šå¸¸è¯•å›¾é™ä½Žæˆ–æƒ©ç½šæ¨¡åž‹çš„å¤æ‚æ€§ã€‚åº”ç”¨é€»è¾‘å›žå½’çš„æ­£åˆ™åŒ–æŠ€æœ¯å¤§å¤šå€¾å‘äºŽæƒ©ç½šå¤§ç³»æ•°ð‘â‚€ï¼Œð‘â‚ï¼Œâ€¦ï¼Œð‘áµ£:

*   **L1 æ­£åˆ™åŒ–**ç”¨åŠ æƒç»å¯¹å€¼çš„ç¼©æ”¾å’Œæƒ©ç½š llf:|ð‘â‚€|+|ð‘â‚|+â‹¯+|ð‘áµ£|.
*   **L2 æ­£åˆ™åŒ–**ç”¨æƒé‡çš„ç¼©æ”¾å¹³æ–¹å’Œæƒ©ç½š llf:ð‘â‚€+ð‘â‚+â‹¯+ð‘áµ£ã€‚
*   **å¼¹æ€§ç½‘æ­£åˆ™åŒ–**æ˜¯ L1 å’Œ L2 æ­£åˆ™åŒ–çš„çº¿æ€§ç»„åˆã€‚

æ­£åˆ™åŒ–å¯ä»¥æ˜¾è‘—æé«˜å¯¹ä¸å¯è§æ•°æ®çš„å»ºæ¨¡æ€§èƒ½ã€‚

## Python ä¸­çš„é€»è¾‘å›žå½’

çŽ°åœ¨æ‚¨å·²ç»ç†è§£äº†åŸºæœ¬åŽŸç†ï¼Œæ‚¨å·²ç»å‡†å¤‡å¥½åº”ç”¨é€‚å½“çš„[åŒ…](https://realpython.com/python-modules-packages/)ä»¥åŠå®ƒä»¬çš„å‡½æ•°å’Œç±»æ¥æ‰§è¡Œ Python ä¸­çš„é€»è¾‘å›žå½’ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæ‚¨å°†çœ‹åˆ°ä»¥ä¸‹å†…å®¹:

*   **ç”¨äºŽé€»è¾‘å›žå½’çš„ Python åŒ…**æ¦‚è¿°(NumPyã€scikit-learnã€StatsModels å’Œ Matplotlib)
*   **ç”¨ scikit-learn æ±‚è§£é€»è¾‘å›žå½’çš„ä¸¤ä¸ªç¤ºä¾‹**
*   **ç”¨ StatsModels è§£å†³çš„ä¸€ä¸ªæ¦‚å¿µç¤ºä¾‹**
*   **ä¸€ä¸ªæ‰‹å†™æ•°å­—åˆ†ç±»çš„çœŸå®žä¾‹å­**

è®©æˆ‘ä»¬å¼€å§‹ç”¨ Python å®žçŽ°é€»è¾‘å›žå½’å§ï¼

[*Remove ads*](/account/join/)

### é€»è¾‘å›žå½’ Python åŒ…

Python ä¸­çš„é€»è¾‘å›žå½’éœ€è¦å‡ ä¸ªåŒ…ã€‚å®ƒä»¬éƒ½æ˜¯å…è´¹å’Œå¼€æºçš„ï¼Œæœ‰å¾ˆå¤šå¯ç”¨çš„èµ„æºã€‚é¦–å…ˆï¼Œæ‚¨éœ€è¦ **NumPy** ï¼Œè¿™æ˜¯ Python ä¸­ç§‘å­¦å’Œæ•°å€¼è®¡ç®—çš„åŸºç¡€åŒ…ã€‚NumPy å¾ˆæœ‰ç”¨ï¼Œä¹Ÿå¾ˆå—æ¬¢è¿Žï¼Œå› ä¸ºå®ƒæ”¯æŒåœ¨ä¸€ç»´æˆ–å¤šç»´æ•°ç»„ä¸Šè¿›è¡Œé«˜æ€§èƒ½æ“ä½œã€‚

NumPy æœ‰è®¸å¤šæœ‰ç”¨çš„æ•°ç»„ä¾‹ç¨‹ã€‚å®ƒå…è®¸æ‚¨ç¼–å†™ä¼˜é›…è€Œç®€æ´çš„ä»£ç ï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå¥½åœ°ä¸Žè®¸å¤š Python åŒ…ä¸€èµ·å·¥ä½œã€‚å¦‚æžœä½ æƒ³å­¦ä¹  NumPyï¼Œé‚£ä¹ˆä½ å¯ä»¥ä»Žå®˜æ–¹çš„[ç”¨æˆ·æŒ‡å—](https://docs.scipy.org/doc/numpy/user/index.html)å¼€å§‹ã€‚ [NumPy å‚è€ƒæ–‡çŒ®](https://docs.scipy.org/doc/numpy/reference/)ä¹Ÿæä¾›äº†å…³äºŽå…¶å‡½æ•°ã€ç±»å’Œæ–¹æ³•çš„å…¨é¢æ–‡æ¡£ã€‚

**æ³¨æ„:**è¦äº†è§£æ›´å¤šå…³äºŽ NumPy æ€§èƒ½åŠå…¶æä¾›çš„å…¶ä»–å¥½å¤„ï¼Œè¯·æŸ¥çœ‹[Pure Python vs NumPy vs tensor flow æ€§èƒ½æ¯”è¾ƒ](https://realpython.com/numpy-tensorflow-performance/)å’Œ [Look Maï¼ŒNo For-Loops:Array Programming With NumPy](https://realpython.com/numpy-array-programming/)ã€‚

æ‚¨å°†ä½¿ç”¨çš„å¦ä¸€ä¸ª Python åŒ…æ˜¯ **scikit-learn** ã€‚è¿™æ˜¯æœ€å—æ¬¢è¿Žçš„[æ•°æ®ç§‘å­¦](https://realpython.com/tutorials/data-science/)å’Œ[æœºå™¨å­¦ä¹ ](https://realpython.com/tutorials/machine-learning/)åº“ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ scikit-learn æ‰§è¡Œå„ç§åŠŸèƒ½:

*   **é¢„å¤„ç†**æ•°æ®
*   **é™ä½Ž**é—®é¢˜çš„ç»´åº¦
*   **éªŒè¯**æ¨¡åž‹
*   **é€‰æ‹©**æœ€åˆé€‚çš„åž‹å·
*   **è§£å†³**å›žå½’å’Œåˆ†ç±»é—®é¢˜
*   **å®žçŽ°**èšç±»åˆ†æž

ä½ å¯ä»¥åœ¨ scikit-learn å®˜æ–¹ç½‘ç«™ä¸Šæ‰¾åˆ°æœ‰ç”¨çš„ä¿¡æ¯ï¼Œåœ¨é‚£é‡Œä½ å¯èƒ½æƒ³è¦é˜…è¯»å…³äºŽ[å¹¿ä¹‰çº¿æ€§æ¨¡åž‹](https://scikit-learn.org/stable/modules/linear_model.html)å’Œ[é€»è¾‘å›žå½’å®žçŽ°](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)çš„å†…å®¹ã€‚å¦‚æžœæ‚¨éœ€è¦ scikit-learn æ— æ³•æä¾›çš„åŠŸèƒ½ï¼Œé‚£ä¹ˆæ‚¨å¯èƒ½ä¼šå‘çŽ° **StatsModels** å¾ˆæœ‰ç”¨ã€‚è¿™æ˜¯ä¸€ä¸ªç”¨äºŽç»Ÿè®¡åˆ†æžçš„å¼ºå¤§ Python åº“ã€‚ä½ å¯ä»¥åœ¨å®˜æ–¹[ç½‘ç«™](https://www.statsmodels.org/stable/index.html)æ‰¾åˆ°æ›´å¤šä¿¡æ¯ã€‚

æœ€åŽï¼Œæ‚¨å°†ä½¿ç”¨ **Matplotlib** æ¥å¯è§†åŒ–æ‚¨çš„åˆ†ç±»ç»“æžœã€‚è¿™æ˜¯ä¸€ä¸ªå…¨é¢çš„ Python åº“ï¼Œå¹¿æ³›ç”¨äºŽé«˜è´¨é‡çš„ç»˜å›¾ã€‚æ›´å¤šä¿¡æ¯ï¼Œå¯ä»¥æŸ¥çœ‹å®˜æ–¹[ç½‘ç«™](https://matplotlib.org/)å’Œ[ç”¨æˆ·æŒ‡å—](https://matplotlib.org/users/index.html)ã€‚æœ‰å‡ ä¸ªå­¦ä¹  Matplotlib çš„èµ„æºå¯èƒ½å¯¹ä½ æœ‰ç”¨ï¼Œæ¯”å¦‚å®˜æ–¹çš„[æ•™ç¨‹](https://matplotlib.org/tutorials/index.html)ï¼ŒMatplotlib çš„[å‰–æž](https://github.com/matplotlib/AnatomyOfMatplotlib)ï¼Œä»¥åŠ [Python ä½¿ç”¨ Matplotlib ç»˜å›¾(æŒ‡å—)](https://realpython.com/python-matplotlib-guide/)ã€‚

### ç”¨ scikit-learn å®žçŽ° Python ä¸­çš„é€»è¾‘å›žå½’:ç¤ºä¾‹ 1

ç¬¬ä¸€ä¸ªä¾‹å­ä¸Žå•å˜é‡äºŒå…ƒåˆ†ç±»é—®é¢˜æœ‰å…³ã€‚è¿™æ˜¯æœ€ç®€å•çš„åˆ†ç±»é—®é¢˜ã€‚åœ¨å‡†å¤‡åˆ†ç±»æ¨¡åž‹æ—¶ï¼Œæ‚¨å°†é‡‡å–å‡ ä¸ªå¸¸è§„æ­¥éª¤:

1.  **å¯¼å…¥**åŒ…ã€å‡½æ•°å’Œç±»
2.  **èŽ·å–**è¦å¤„ç†çš„æ•°æ®ï¼Œå¦‚æžœåˆé€‚çš„è¯ï¼Œå¯¹å…¶è¿›è¡Œè½¬æ¢
3.  **åˆ›å»º**ä¸€ä¸ªåˆ†ç±»æ¨¡åž‹ï¼Œå¹¶ç”¨çŽ°æœ‰æ•°æ®è®­ç»ƒ(æˆ–æ‹Ÿåˆ)å®ƒ
4.  è¯„ä¼°ä½ çš„æ¨¡åž‹ï¼Œçœ‹çœ‹å®ƒçš„æ€§èƒ½æ˜¯å¦ä»¤äººæ»¡æ„

æ‚¨å®šä¹‰çš„è¶³å¤Ÿå¥½çš„æ¨¡åž‹å¯ç”¨äºŽå¯¹æ–°çš„ã€æœªçŸ¥çš„æ•°æ®è¿›è¡Œè¿›ä¸€æ­¥çš„é¢„æµ‹ã€‚ä¸Šè¿°è¿‡ç¨‹å¯¹äºŽåˆ†ç±»å’Œå›žå½’æ˜¯ç›¸åŒçš„ã€‚

#### æ­¥éª¤ 1:å¯¼å…¥åŒ…ã€å‡½æ•°å’Œç±»

é¦–å…ˆï¼Œä½ å¿…é¡»[ä¸ºå¯è§†åŒ–å¯¼å…¥](https://realpython.com/absolute-vs-relative-python-imports/) Matplotlibï¼Œä¸ºæ•°ç»„æ“ä½œå¯¼å…¥ NumPyã€‚æ‚¨è¿˜éœ€è¦ scikit-learn ä¸­çš„`LogisticRegression`ã€`classification_report()`å’Œ`confusion_matrix()`:

```py
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
```

çŽ°åœ¨æ‚¨å·²ç»ç”¨ scikit åœ¨ Python ä¸­å¯¼å…¥äº†é€»è¾‘å›žå½’æ‰€éœ€çš„æ‰€æœ‰ä¸œè¥¿â€”â€”å­¦ä¹ ï¼

#### ç¬¬äºŒæ­¥:èŽ·å–æ•°æ®

åœ¨å®žè·µä¸­ï¼Œæ‚¨é€šå¸¸ä¼šæœ‰ä¸€äº›æ•°æ®è¦å¤„ç†ã€‚å‡ºäºŽæœ¬ä¾‹çš„ç›®çš„ï¼Œè®©æˆ‘ä»¬åªä¸ºè¾“å…¥(ð‘¥)å’Œè¾“å‡º(ð‘¦)å€¼åˆ›å»ºæ•°ç»„:

```py
x = np.arange(10).reshape(-1, 1)
y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])
```

è¾“å…¥å’Œè¾“å‡ºåº”è¯¥æ˜¯ NumPy æ•°ç»„(ç±»`numpy.ndarray`çš„å®žä¾‹)æˆ–ç±»ä¼¼çš„å¯¹è±¡ã€‚`numpy.arange()`åœ¨ç»™å®šèŒƒå›´å†…åˆ›å»ºä¸€ä¸ªè¿žç»­çš„ç­‰è·å€¼æ•°ç»„ã€‚å…³äºŽè¿™ä¸ªå‡½æ•°çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹å®˜æ–¹[æ–‡æ¡£](https://docs.scipy.org/doc/numpy/reference/generated/numpy.arange.html)æˆ– [NumPy arange():å¦‚ä½•ä½¿ç”¨ np.arange()](https://realpython.com/how-to-use-numpy-arange/) ã€‚

è¦æ±‚æ•°ç»„`x`ä¸º**äºŒç»´**ã€‚æ¯ä¸ªè¾“å…¥åº”è¯¥æœ‰ä¸€åˆ—ï¼Œè¡Œæ•°åº”è¯¥ç­‰äºŽè§‚å¯Ÿæ•°ã€‚ä¸ºäº†ä½¿`x`äºŒç»´åŒ–ï¼Œæ‚¨å¯ä»¥åº”ç”¨å¸¦æœ‰å‚æ•°`-1`çš„`.reshape()`æ¥èŽ·å¾—æ‰€éœ€çš„å¤šè¡Œï¼Œåº”ç”¨`1`æ¥èŽ·å¾—ä¸€åˆ—ã€‚æ›´å¤šå…³äºŽ`.reshape()`çš„ä¿¡æ¯ï¼Œå¯ä»¥æŸ¥çœ‹å®˜æ–¹[æ–‡æ¡£](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.reshape.html)ã€‚ä¸‹é¢æ˜¯`x`å’Œ`y`çŽ°åœ¨çš„æ ·å­:

>>>

```py
>>> x
array([[0],
 [1],
 [2],
 [3],
 [4],
 [5],
 [6],
 [7],
 [8],
 [9]])
>>> y
array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])
```

`x`æœ‰ä¸¤ä¸ªç»´åº¦:

1.  **ä¸€åˆ—**ç”¨äºŽå•æ¬¡è¾“å…¥
2.  **åè¡Œ**ï¼Œæ¯ä¸€è¡Œå¯¹åº”ä¸€æ¬¡è§‚æµ‹

`y`æ˜¯æœ‰åä¸ªé¡¹ç›®çš„ä¸€ç»´ã€‚åŒæ ·ï¼Œæ¯ä¸ªé¡¹ç›®å¯¹åº”ä¸€ä¸ªè§‚å¯Ÿã€‚å®ƒåªåŒ…å« 0 å’Œ 1ï¼Œå› ä¸ºè¿™æ˜¯ä¸€ä¸ªäºŒè¿›åˆ¶åˆ†ç±»é—®é¢˜ã€‚

#### ç¬¬ä¸‰æ­¥:åˆ›å»ºä¸€ä¸ªæ¨¡åž‹å¹¶è®­ç»ƒå®ƒ

ä¸€æ—¦æ‚¨å‡†å¤‡å¥½äº†è¾“å…¥å’Œè¾“å‡ºï¼Œæ‚¨å°±å¯ä»¥åˆ›å»ºå’Œå®šä¹‰æ‚¨çš„åˆ†ç±»æ¨¡åž‹ã€‚æ‚¨å°†ä½¿ç”¨ç±»`LogisticRegression`çš„å®žä¾‹æ¥è¡¨ç¤ºå®ƒ:

```py
model = LogisticRegression(solver='liblinear', random_state=0)
```

ä¸Šé¢çš„è¯­å¥åˆ›å»ºäº†ä¸€ä¸ª`LogisticRegression`çš„å®žä¾‹ï¼Œå¹¶å°†å…¶å¼•ç”¨ç»‘å®šåˆ°å˜é‡`model`ã€‚`LogisticRegression`æœ‰å‡ ä¸ªå¯é€‰å‚æ•°å®šä¹‰æ¨¡åž‹å’Œæ–¹æ³•çš„è¡Œä¸º:

*   **`penalty`** æ˜¯ä¸€ä¸ª[å­—ç¬¦ä¸²](https://realpython.com/python-strings/)(é»˜è®¤ä¸º`'l2'`)å†³å®šæ˜¯å¦æœ‰æ­£åˆ™åŒ–ä»¥åŠä½¿ç”¨å“ªç§æ–¹æ³•ã€‚å…¶ä»–é€‰é¡¹æœ‰`'l1'`ã€`'elasticnet'`å’Œ`'none'`ã€‚

*   **`dual`** æ˜¯ä¸€ä¸ª[å¸ƒå°”](https://realpython.com/python-boolean/)(é»˜è®¤ä¸º`False`)å†³å®šæ˜¯ä½¿ç”¨ primal(å½“`False`)è¿˜æ˜¯å¯¹å¶å…¬å¼åŒ–(å½“`True`)ã€‚

*   **`tol`** æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°(é»˜è®¤ä¸º`0.0001`)ï¼Œå®šä¹‰äº†åœæ­¢ç¨‹åºçš„å…¬å·®ã€‚

*   **`C`** æ˜¯ä¸€ä¸ªæ­£æµ®ç‚¹æ•°(é»˜è®¤ä¸º`1.0`ï¼Œå®šä¹‰æ­£åˆ™åŒ–çš„ç›¸å¯¹å¼ºåº¦ã€‚è¾ƒå°çš„å€¼è¡¨ç¤ºè¾ƒå¼ºçš„æ­£åˆ™åŒ–ã€‚

*   **`fit_intercept`** æ˜¯ä¸€ä¸ªå¸ƒå°”å€¼(é»˜è®¤ä¸º`True`)ï¼Œå†³å®šæ˜¯è®¡ç®—æˆªè·ð‘â‚€(å½“`True`æ—¶)è¿˜æ˜¯å°†å…¶è§†ä¸ºç­‰äºŽé›¶(å½“`False`æ—¶)ã€‚

*   **`intercept_scaling`** æ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°(é»˜è®¤ä¸º`1.0`)ï¼Œå®šä¹‰äº†æˆªè·ð‘â‚€.çš„ç¼©æ”¾æ¯”ä¾‹

*   **`class_weight`** æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œ`'balanced'`æˆ–`None`(é»˜è®¤)å®šä¹‰äº†ä¸Žæ¯ä¸ªç±»ç›¸å…³çš„æƒé‡ã€‚å½“`None`æ—¶ï¼Œæ‰€æœ‰ç±»çš„æƒé‡éƒ½æ˜¯ 1ã€‚

*   **`random_state`** æ˜¯ä¸€ä¸ªæ•´æ•°ï¼Œ`numpy.RandomState`çš„ä¸€ä¸ªå®žä¾‹ï¼Œæˆ–è€…`None`(é»˜è®¤)å®šä¹‰ä½¿ç”¨ä»€ä¹ˆä¼ªéšæœºæ•°å‘ç”Ÿå™¨ã€‚

*   **`solver`** æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²(é»˜è®¤ä¸º`'liblinear'`)ï¼Œå†³å®šä½¿ç”¨ä»€ä¹ˆè§£ç®—å™¨æ¥æ‹Ÿåˆæ¨¡åž‹ã€‚å…¶ä»–é€‰é¡¹æœ‰`'newton-cg'`ã€`'lbfgs'`ã€`'sag'`å’Œ`'saga'`ã€‚

*   **`max_iter`** æ˜¯ä¸€ä¸ªæ•´æ•°(é»˜è®¤ä¸º`100`)ï¼Œç”¨äºŽå®šä¹‰æ¨¡åž‹æ‹Ÿåˆè¿‡ç¨‹ä¸­æ±‚è§£å™¨çš„æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚

*   **`multi_class`** æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²(é»˜è®¤ä¸º`'ovr'`)ï¼Œå†³å®šäº†å¤„ç†å¤šä¸ªç±»çš„æ–¹æ³•ã€‚å…¶ä»–é€‰é¡¹æœ‰`'multinomial'`å’Œ`'auto'`ã€‚

*   **`verbose`** æ˜¯ä¸€ä¸ªéžè´Ÿæ•´æ•°(é»˜è®¤ä¸º`0`)ï¼Œå®šä¹‰äº†`'liblinear'`å’Œ`'lbfgs'`è§£ç®—å™¨çš„è¯¦ç»†ç¨‹åº¦ã€‚

*   **`warm_start`** æ˜¯ä¸€ä¸ªå¸ƒå°”åž‹(`False`é»˜è®¤)ï¼Œå†³å®šæ˜¯å¦é‡ç”¨ä¹‹å‰å¾—åˆ°çš„è§£ã€‚

*   **`n_jobs`** æ˜¯ä¸€ä¸ªæ•´æ•°æˆ–`None`(é»˜è®¤å€¼)ï¼Œå®šä¹‰äº†è¦ä½¿ç”¨çš„å¹¶è¡Œè¿›ç¨‹çš„æ•°é‡ã€‚`None`é€šå¸¸æ˜¯æŒ‡ä½¿ç”¨ä¸€ä¸ªå†…æ ¸ï¼Œè€Œ`-1`æ˜¯æŒ‡ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„å†…æ ¸ã€‚

*   **`l1_ratio`** è¦ä¹ˆæ˜¯ 0 åˆ° 1 ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼Œè¦ä¹ˆæ˜¯`None`(é»˜è®¤)ã€‚å®ƒå®šä¹‰äº†å¼¹æ€§ç½‘æ­£åˆ™åŒ–ä¸­ L1 éƒ¨åˆ†çš„ç›¸å¯¹é‡è¦æ€§ã€‚

å‡ºäºŽä»¥ä¸‹å‡ ä¸ªåŽŸå› ï¼Œæ‚¨åº”è¯¥ä»”ç»†åŒ¹é…æ±‚è§£å™¨å’Œæ­£åˆ™åŒ–æ–¹æ³•:

*   æ²¡æœ‰æ­£åˆ™åŒ–ï¼Œè§„åˆ’æ±‚è§£æ— æ³•å·¥ä½œã€‚
*   `'newton-cg'`ã€`'sag'`ã€`'saga'`ã€`'lbfgs'`ä¸æ”¯æŒ L1 æ­£åˆ™åŒ–ã€‚
*   `'saga'`æ˜¯å”¯ä¸€æ”¯æŒå¼¹æ€§ç½‘æ­£åˆ™åŒ–çš„æ±‚è§£å™¨ã€‚

ä¸€æ—¦åˆ›å»ºäº†æ¨¡åž‹ï¼Œæ‚¨éœ€è¦æ‹Ÿåˆ(æˆ–è®­ç»ƒ)å®ƒã€‚æ¨¡åž‹æ‹Ÿåˆæ˜¯ç¡®å®šå¯¹åº”äºŽæˆæœ¬å‡½æ•°æœ€ä½³å€¼çš„ç³»æ•°ð‘â‚€ã€ð‘â‚ã€â€¦ã€ð‘áµ£çš„è¿‡ç¨‹ã€‚ä½ ç”¨`.fit()`æ‹Ÿåˆæ¨¡åž‹:

```py
model.fit(x, y)
```

`.fit()`å–`x`ã€`y`ï¼Œå¯èƒ½è¿˜æœ‰ä¸Žè§‚å¯Ÿç›¸å…³çš„æƒé‡ã€‚ç„¶åŽï¼Œå®ƒæ‹Ÿåˆæ¨¡åž‹å¹¶è¿”å›žæ¨¡åž‹å®žä¾‹æœ¬èº«:

```py
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
```

è¿™æ˜¯èŽ·å¾—çš„æ‹Ÿåˆæ¨¡åž‹çš„å­—ç¬¦ä¸²è¡¨ç¤ºã€‚

æ‚¨å¯ä»¥åˆ©ç”¨`.fit()`è¿”å›žæ¨¡åž‹å®žä¾‹çš„äº‹å®žï¼Œå¹¶å°†æœ€åŽä¸¤æ¡è¯­å¥é“¾æŽ¥èµ·æ¥ã€‚å®ƒä»¬ç›¸å½“äºŽä¸‹é¢ä¸€è¡Œä»£ç :

```py
model = LogisticRegression(solver='liblinear', random_state=0).fit(x, y)
```

è‡³æ­¤ï¼Œæ‚¨å·²ç»å®šä¹‰äº†åˆ†ç±»æ¨¡åž‹ã€‚

ä½ å¯ä»¥å¿«é€Ÿå¾—åˆ°ä½ çš„æ¨¡åž‹çš„å±žæ€§ã€‚ä¾‹å¦‚ï¼Œå±žæ€§`.classes_`è¡¨ç¤º`y`é‡‡ç”¨çš„ä¸åŒå€¼çš„æ•°ç»„:

>>>

```py
>>> model.classes_
array([0, 1])
```

è¿™æ˜¯äºŒå…ƒåˆ†ç±»çš„ä¾‹å­ï¼Œ`y`å¯ä»¥æ˜¯`0`ä¹Ÿå¯ä»¥æ˜¯`1`ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚

æ‚¨è¿˜å¯ä»¥èŽ·å¾—çº¿æ€§å‡½æ•°ð‘“çš„æ–œçŽ‡ð‘â‚å’Œæˆªè·ð‘â‚€çš„å€¼ï¼Œå¦‚ä¸‹æ‰€ç¤º:

>>>

```py
>>> model.intercept_
array([-1.04608067])
>>> model.coef_
array([[0.51491375]])
```

å¦‚ä½ æ‰€è§ï¼Œð‘â‚€åœ¨ä¸€ç»´æ•°ç»„ä¸­ï¼Œè€Œð‘â‚åœ¨äºŒç»´æ•°ç»„ä¸­ã€‚æ‚¨ä½¿ç”¨å±žæ€§`.intercept_`å’Œ`.coef_`æ¥èŽ·å¾—è¿™äº›ç»“æžœã€‚

#### æ­¥éª¤ 4:è¯„ä¼°æ¨¡åž‹

ä¸€æ—¦å®šä¹‰äº†ä¸€ä¸ªæ¨¡åž‹ï¼Œæ‚¨å¯ä»¥ç”¨`.predict_proba()`æ¥æ£€æŸ¥å®ƒçš„æ€§èƒ½ï¼Œå®ƒä¼šè¿”å›žé¢„æµ‹è¾“å‡ºç­‰äºŽé›¶æˆ–ä¸€çš„æ¦‚çŽ‡çŸ©é˜µ:

>>>

```py
>>> model.predict_proba(x)
array([[0.74002157, 0.25997843],
 [0.62975524, 0.37024476],
 [0.5040632 , 0.4959368 ],
 [0.37785549, 0.62214451],
 [0.26628093, 0.73371907],
 [0.17821501, 0.82178499],
 [0.11472079, 0.88527921],
 [0.07186982, 0.92813018],
 [0.04422513, 0.95577487],
 [0.02690569, 0.97309431]])
```

åœ¨ä¸Šé¢çš„çŸ©é˜µä¸­ï¼Œæ¯è¡Œå¯¹åº”ä¸€ä¸ªè§‚å¯Ÿå€¼ã€‚ç¬¬ä¸€åˆ—æ˜¯é¢„æµ‹è¾“å‡ºä¸ºé›¶çš„æ¦‚çŽ‡ï¼Œå³ 1 - ð‘(ð‘¥).ç¬¬äºŒåˆ—æ˜¯è¾“å‡ºä¸º 1 æˆ–ð‘(ð‘¥).çš„æ¦‚çŽ‡

ä½ å¯ä»¥å¾—åˆ°å®žé™…çš„é¢„æµ‹ï¼ŒåŸºäºŽæ¦‚çŽ‡çŸ©é˜µå’Œð‘(ð‘¥çš„å€¼)ï¼Œç”¨`.predict()`:

>>>

```py
>>> model.predict(x)
array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])
```

è¯¥å‡½æ•°ä»¥ä¸€ç»´æ•°ç»„çš„å½¢å¼è¿”å›žé¢„æµ‹çš„è¾“å‡ºå€¼ã€‚

ä¸‹å›¾è¯´æ˜Žäº†è¾“å…¥ã€è¾“å‡ºå’Œåˆ†ç±»ç»“æžœ:

[![Result of Logistic Regression](img/2626158bde5c6d1e355e9300b120483e.png)](https://files.realpython.com/media/log-reg-5.1e0f3f7e733a.png)

ç»¿è‰²åœ†åœˆä»£è¡¨å®žé™…å“åº”å’Œæ­£ç¡®é¢„æµ‹ã€‚çº¢è‰²Ã—è¡¨ç¤ºä¸æ­£ç¡®çš„é¢„æµ‹ã€‚é»‘è‰²å®žçº¿æ˜¯ä¼°è®¡çš„é€»è¾‘å›žå½’ç›´çº¿ð‘(ð‘¥).ç°è‰²æ–¹å—æ˜¯è¿™æ¡çº¿ä¸Šå¯¹åº”äºŽð‘¥å’Œæ¦‚çŽ‡çŸ©é˜µç¬¬äºŒåˆ—ä¸­çš„å€¼çš„ç‚¹ã€‚é»‘è‰²è™šçº¿æ˜¯ç½—å‰ç‰¹ð‘“(ð‘¥).

ç•¥é«˜äºŽ 2 çš„ð‘¥å€¼å¯¹åº”äºŽé˜ˆå€¼ð‘(ð‘¥)=0.5ï¼Œå³ð‘“(ð‘¥)=0.ð‘¥çš„è¿™ä¸ªå€¼æ˜¯è¢«åˆ†ç±»ä¸º 0 çš„ç‚¹å’Œè¢«é¢„æµ‹ä¸º 1 çš„ç‚¹ä¹‹é—´çš„è¾¹ç•Œã€‚

ä¾‹å¦‚ï¼Œç¬¬ä¸€ä¸ªç‚¹å…·æœ‰è¾“å…¥ð‘¥=0ã€å®žé™…è¾“å‡ºð‘¦=0ã€æ¦‚çŽ‡ð‘=0.26 å’Œé¢„æµ‹å€¼ 0ã€‚ç¬¬äºŒç‚¹æœ‰ð‘¥=1ã€ð‘¦=0ã€ð‘=0.37ï¼Œé¢„æµ‹å€¼ä¸º 0ã€‚åªæœ‰ç¬¬å››ä¸ªç‚¹æœ‰å®žé™…è¾“å‡ºð‘¦=0ï¼Œæ¦‚çŽ‡å¤§äºŽ 0.5(åœ¨ð‘=0.62)ï¼Œæ‰€ä»¥è¢«é”™è¯¯å½’ç±»ä¸º 1ã€‚æ‰€æœ‰å…¶ä»–å€¼éƒ½é¢„æµ‹æ­£ç¡®ã€‚

å½“åä¸ªè§‚å¯Ÿå€¼ä¸­æœ‰ä¹ä¸ªè¢«æ­£ç¡®åˆ†ç±»æ—¶ï¼Œæ‚¨çš„æ¨¡åž‹çš„ç²¾åº¦ç­‰äºŽ 9/10=0.9ï¼Œè¿™å¯ä»¥é€šè¿‡`.score()`èŽ·å¾—:

>>>

```py
>>> model.score(x, y)
0.9
```

`.score()`å°†è¾“å…¥å’Œè¾“å‡ºä½œä¸ºå‚æ•°ï¼Œå¹¶è¿”å›žæ­£ç¡®é¢„æµ‹æ•°ä¸Žè§‚å¯Ÿæ•°ä¹‹æ¯”ã€‚

ä½ å¯ä»¥ç”¨ä¸€ä¸ª**æ··æ·†çŸ©é˜µ**èŽ·å¾—æ›´å¤šå…³äºŽæ¨¡åž‹å‡†ç¡®æ€§çš„ä¿¡æ¯ã€‚åœ¨äºŒè¿›åˆ¶åˆ†ç±»çš„æƒ…å†µä¸‹ï¼Œæ··æ·†çŸ©é˜µæ˜¾ç¤ºä¸‹åˆ—æ•°å­—:

*   å·¦ä¸Šè§’ä½ç½®çš„**çœŸåº•ç‰‡**
*   **å·¦ä¸‹ä½ç½®çš„å‡é˜´æ€§**
*   å³ä¸Šè§’ä½ç½®çš„**è¯¯æŠ¥**
*   **å³ä¸‹ä½ç½®çš„çœŸé˜³æ€§**

è¦åˆ›å»ºæ··æ·†çŸ©é˜µï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`confusion_matrix()`å¹¶æä¾›å®žé™…å’Œé¢„æµ‹è¾“å‡ºä½œä¸ºå‚æ•°:

>>>

```py
>>> confusion_matrix(y, model.predict(x))
array([[3, 1],
 [0, 6]])
```

èŽ·å¾—çš„çŸ©é˜µæ˜¾ç¤ºäº†ä»¥ä¸‹å†…å®¹:

*   **ä¸‰ä¸ªçœŸå¦å®šé¢„æµ‹:**å‰ä¸‰ä¸ªè§‚æµ‹å€¼æ˜¯æ­£ç¡®é¢„æµ‹çš„é›¶ã€‚
*   **æ— å‡é˜´æ€§é¢„æµ‹:**è¿™äº›æ˜¯è¢«é”™è¯¯é¢„æµ‹ä¸ºé›¶çš„ã€‚
*   **ä¸€æ¬¡è¯¯æŠ¥é¢„æµ‹:**ç¬¬å››æ¬¡è§‚æµ‹æ˜¯ä¸€ä¸ªè¢«è¯¯é¢„æµ‹ä¸ºä¸€çš„é›¶ã€‚
*   **å…­ä¸ªçœŸæ­£é¢„æµ‹:**æœ€åŽå…­ä¸ªè§‚æµ‹å€¼æ˜¯é¢„æµ‹æ­£ç¡®çš„ã€‚

å¯è§†åŒ–æ··ä¹±çŸ©é˜µé€šå¸¸æ˜¯æœ‰ç”¨çš„ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ Matplotlib ä¸­çš„`.imshow()`æ¥å®žçŽ°ï¼Œå®ƒæŽ¥å—æ··æ·†çŸ©é˜µä½œä¸ºå‚æ•°:

```py
cm = confusion_matrix(y, model.predict(x))

fig, ax = plt.subplots(figsize=(8, 8))
ax.imshow(cm)
ax.grid(False)
ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))
ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))
ax.set_ylim(1.5, -0.5)
for i in range(2):
    for j in range(2):
        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')
plt.show()
```

ä¸Šé¢çš„ä»£ç åˆ›å»ºäº†ä¸€ä¸ªä»£è¡¨æ··æ·†çŸ©é˜µçš„**çƒ­å›¾**:

[![Classification Confusion Matrix](img/8e546962149edfb3ea9c25b669c1767a.png)](https://files.realpython.com/media/log-reg-6.e2d5854f3bee.png)

åœ¨è¿™ä¸ªå›¾ä¸­ï¼Œä¸åŒçš„é¢œè‰²ä»£è¡¨ä¸åŒçš„æ•°å­—ï¼Œç›¸ä¼¼çš„é¢œè‰²ä»£è¡¨ç›¸ä¼¼çš„æ•°å­—ã€‚çƒ­å›¾æ˜¯è¡¨ç¤ºçŸ©é˜µçš„ä¸€ç§æ—¢å¥½åˆæ–¹ä¾¿çš„æ–¹å¼ã€‚è¦äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ Matplotlib æ–‡æ¡£ä¸­å…³äºŽ[åˆ›å»ºå¸¦æ³¨é‡Šçš„çƒ­å›¾](https://matplotlib.org/3.1.0/gallery/images_contours_and_fields/image_annotated_heatmap.html)å’Œ [`.imshow()`](https://matplotlib.org/3.1.0/api/_as_gen/matplotlib.axes.Axes.imshow.html#matplotlib.axes.Axes.imshow) çš„å†…å®¹ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨`classification_report()`èŽ·å¾—æ›´å…¨é¢çš„åˆ†ç±»æŠ¥å‘Š:

>>>

```py
>>> print(classification_report(y, model.predict(x)))
 precision    recall  f1-score   support

 0       1.00      0.75      0.86         4
 1       0.86      1.00      0.92         6

 accuracy                           0.90        10
 macro avg       0.93      0.88      0.89        10
weighted avg       0.91      0.90      0.90        10
```

è¯¥å‡½æ•°ä¹Ÿå°†å®žé™…å’Œé¢„æµ‹è¾“å‡ºä½œä¸ºå‚æ•°ã€‚å¦‚æžœæ‚¨æä¾›äº†`output_dict=True`æˆ–è€…ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå®ƒå°†è¿”å›žä¸€ä¸ªå…³äºŽåˆ†ç±»çš„æŠ¥å‘Šï¼Œä½œä¸ºä¸€ä¸ª[å­—å…¸](https://realpython.com/courses/dictionaries-python/)ã€‚

**æ³¨æ„:**é€šå¸¸ç”¨ä½ **æ²¡æœ‰ç”¨**è®­ç»ƒçš„æ•°æ®æ¥è¯„ä¼°ä½ çš„æ¨¡åž‹æ›´å¥½ã€‚è¿™å°±æ˜¯é¿å…åå·®å’Œæ£€æµ‹è¿‡åº¦æ‹Ÿåˆçš„æ–¹æ³•ã€‚åœ¨æœ¬æ•™ç¨‹çš„åŽé¢ï¼Œæ‚¨å°†çœ‹åˆ°ä¸€ä¸ªç¤ºä¾‹ã€‚

æ›´å¤šå…³äºŽ`LogisticRegression`çš„ä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹å®˜æ–¹[æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)ã€‚å¦å¤–ï¼Œscikit-learn æä¾›äº†ä¸€ä¸ªç±»ä¼¼çš„ç±» [LogisticRegressionCV](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html) ï¼Œæ›´é€‚åˆ[äº¤å‰éªŒè¯](https://scikit-learn.org/stable/modules/cross_validation.html)ã€‚ä½ ä¹Ÿå¯ä»¥æŸ¥é˜…å®˜æ–¹æ–‡æ¡£æ¥äº†è§£æ›´å¤šå…³äºŽ[åˆ†ç±»æŠ¥å‘Š](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)å’Œ[æ··æ·†çŸ©é˜µ](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)çš„ä¿¡æ¯ã€‚

#### æ”¹è¿›æ¨¡åž‹

æ‚¨å¯ä»¥é€šè¿‡è®¾ç½®ä¸åŒçš„å‚æ•°æ¥æ”¹è¿›æ‚¨çš„æ¨¡åž‹ã€‚ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä½¿ç”¨ç­‰äºŽ`10.0`çš„æ­£åˆ™åŒ–å¼ºåº¦`C`ï¼Œè€Œä¸æ˜¯é»˜è®¤å€¼`1.0`:

```py
model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)
model.fit(x, y)
```

çŽ°åœ¨ä½ æœ‰äº†å¦ä¸€ä¸ªä¸åŒå‚æ•°çš„æ¨¡åž‹ã€‚å®ƒè¿˜ä¼šæœ‰ä¸€ä¸ªä¸åŒçš„æ¦‚çŽ‡çŸ©é˜µï¼Œä¸€ç»„ä¸åŒçš„ç³»æ•°å’Œé¢„æµ‹:

>>>

```py
>>> model.intercept_
array([-3.51335372])
>>> model.coef_
array([[1.12066084]])
>>> model.predict_proba(x)
array([[0.97106534, 0.02893466],
 [0.9162684 , 0.0837316 ],
 [0.7810904 , 0.2189096 ],
 [0.53777071, 0.46222929],
 [0.27502212, 0.72497788],
 [0.11007743, 0.88992257],
 [0.03876835, 0.96123165],
 [0.01298011, 0.98701989],
 [0.0042697 , 0.9957303 ],
 [0.00139621, 0.99860379]])
>>> model.predict(x)
array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])
```

å¦‚ä½ æ‰€è§ï¼Œæˆªè·ð‘â‚€å’Œç³»æ•°ð‘â‚çš„ç»å¯¹å€¼[æ›´å¤§ã€‚è¿™æ˜¯å› ä¸ºè¾ƒå¤§çš„`C`å€¼æ„å‘³ç€è¾ƒå¼±çš„æ­£åˆ™åŒ–ï¼Œæˆ–è€…ä¸Žð‘â‚€å’Œð‘â‚.çš„é«˜å€¼ç›¸å…³çš„è¾ƒå¼±çš„æƒ©ç½š](https://realpython.com/python-absolute-value)

ð‘â‚€å’Œð‘â‚çš„ä¸åŒå€¼æ„å‘³ç€é€»è¾‘ð‘“(ð‘¥çš„å˜åŒ–ï¼Œæ¦‚çŽ‡ð‘(ð‘¥çš„ä¸åŒå€¼ï¼Œå›žå½’çº¿çš„ä¸åŒå½¢çŠ¶ï¼Œä»¥åŠå…¶ä»–é¢„æµ‹è¾“å‡ºå’Œåˆ†ç±»æ€§èƒ½çš„å¯èƒ½å˜åŒ–ã€‚çŽ°åœ¨ð‘(ð‘¥)=0.5 å’Œð‘“(ð‘¥)=0 çš„ð‘¥è¾¹ç•Œå€¼æ¯”è¾ƒé«˜ã€‚3 ä»¥ä¸Šã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å°†èŽ·å¾—æ‰€æœ‰çœŸå®žé¢„æµ‹ï¼Œå¦‚å‡†ç¡®æ€§ã€æ··æ·†çŸ©é˜µå’Œåˆ†ç±»æŠ¥å‘Šæ‰€ç¤º:

>>>

```py
>>> model.score(x, y)
1.0
>>> confusion_matrix(y, model.predict(x))
array([[4, 0],
 [0, 6]])
>>> print(classification_report(y, model.predict(x)))
 precision    recall  f1-score   support

 0       1.00      1.00      1.00         4
 1       1.00      1.00      1.00         6

 accuracy                           1.00        10
 macro avg       1.00      1.00      1.00        10
weighted avg       1.00      1.00      1.00        10
```

æ··æ·†çŸ©é˜µå·¦ä¸‹å’Œå³ä¸Šå­—æ®µä¸­çš„åˆ†æ•°(æˆ–å‡†ç¡®åº¦)1 å’Œé›¶è¡¨ç¤ºå®žé™…è¾“å‡ºå’Œé¢„æµ‹è¾“å‡ºæ˜¯ç›¸åŒçš„ã€‚ä¸‹å›¾ä¹Ÿæ˜¾ç¤ºäº†è¿™ä¸€ç‚¹:

[![Result of Logistic Regression](img/6f20c75f665e1994ccf0ea030f296b8f.png)](https://files.realpython.com/media/log-reg-7.9141027bd736.png)

è¯¥å›¾è¯´æ˜Žäº†ä¼°è®¡çš„å›žå½’çº¿çŽ°åœ¨å…·æœ‰ä¸åŒçš„å½¢çŠ¶ï¼Œå¹¶ä¸”ç¬¬å››ä¸ªç‚¹è¢«æ­£ç¡®åˆ†ç±»ä¸º 0ã€‚æ²¡æœ‰çº¢Ã—ï¼Œæ‰€ä»¥æ²¡æœ‰é¢„æµ‹é”™ã€‚

[*Remove ads*](/account/join/)

### ä½¿ç”¨ scikit-learn åœ¨ Python ä¸­è¿›è¡Œé€»è¾‘å›žå½’:ç¤ºä¾‹ 2

è®©æˆ‘ä»¬è§£å†³å¦ä¸€ä¸ªåˆ†ç±»é—®é¢˜ã€‚å®ƒä¸Žå‰ä¸€ä¸ªç±»ä¼¼ï¼Œåªæ˜¯ç¬¬äºŒä¸ªå€¼çš„è¾“å‡ºä¸åŒã€‚ä»£ç ç±»ä¼¼äºŽå‰ä¸€ç§æƒ…å†µ:

```py
# Step 1: Import packages, functions, and classes
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

# Step 2: Get data
x = np.arange(10).reshape(-1, 1)
y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])

# Step 3: Create a model and train it
model = LogisticRegression(solver='liblinear', C=10.0, random_state=0)
model.fit(x, y)

# Step 4: Evaluate the model
p_pred = model.predict_proba(x)
y_pred = model.predict(x)
score_ = model.score(x, y)
conf_m = confusion_matrix(y, y_pred)
report = classification_report(y, y_pred)
```

æ­¤åˆ†ç±»ä»£ç ç¤ºä¾‹ç”Ÿæˆä»¥ä¸‹ç»“æžœ:

>>>

```py
>>> print('x:', x, sep='\n')
x:
[[0]
 [1]
 [2]
 [3]
 [4]
 [5]
 [6]
 [7]
 [8]
 [9]]
>>> print('y:', y, sep='\n', end='\n\n')
y:
[0 1 0 0 1 1 1 1 1 1]

>>> print('intercept:', model.intercept_)
intercept: [-1.51632619]
>>> print('coef:', model.coef_, end='\n\n')
coef: [[0.703457]]

>>> print('p_pred:', p_pred, sep='\n', end='\n\n')
p_pred:
[[0.81999686 0.18000314]
 [0.69272057 0.30727943]
 [0.52732579 0.47267421]
 [0.35570732 0.64429268]
 [0.21458576 0.78541424]
 [0.11910229 0.88089771]
 [0.06271329 0.93728671]
 [0.03205032 0.96794968]
 [0.0161218  0.9838782 ]
 [0.00804372 0.99195628]]

>>> print('y_pred:', y_pred, end='\n\n')
y_pred: [0 0 0 1 1 1 1 1 1 1]

>>> print('score_:', score_, end='\n\n')
score_: 0.8

>>> print('conf_m:', conf_m, sep='\n', end='\n\n')
conf_m:
[[2 1]
 [1 6]]

>>> print('report:', report, sep='\n')
report:
 precision    recall  f1-score   support

 0       0.67      0.67      0.67         3
 1       0.86      0.86      0.86         7

 accuracy                           0.80        10
 macro avg       0.76      0.76      0.76        10
weighted avg       0.80      0.80      0.80        10
```

åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåˆ†æ•°(æˆ–å‡†ç¡®åº¦)æ˜¯ 0.8ã€‚æœ‰ä¸¤ä¸ªè§‚å¯Ÿåˆ†ç±»ä¸æ­£ç¡®ã€‚å…¶ä¸­ä¸€ä¸ªæ˜¯å‡é˜´æ€§ï¼Œè€Œå¦ä¸€ä¸ªæ˜¯å‡é˜³æ€§ã€‚

ä¸‹å›¾æ˜¾ç¤ºäº†è¿™ä¸ªæœ‰å…«ä¸ªæ­£ç¡®é¢„æµ‹å’Œä¸¤ä¸ªé”™è¯¯é¢„æµ‹çš„ç¤ºä¾‹:

[![Result of Logistic Regression](img/66514e017450aee8b558db2b48281053.png)](https://files.realpython.com/media/log-reg-8.3d1dab72e105.png)

è¯¥å›¾æ­ç¤ºäº†è¿™ä¸ªä¾‹å­çš„ä¸€ä¸ªé‡è¦ç‰¹å¾ã€‚å’Œä¸Šä¸€ä¸ªä¸åŒï¼Œè¿™ä¸ªé—®é¢˜æ˜¯**ä¸çº¿æ€§å¯åˆ†**ã€‚è¿™æ„å‘³ç€ä½ ä¸èƒ½æ‰¾åˆ°ä¸€ä¸ªð‘¥çš„å€¼ï¼Œç„¶åŽç”»ä¸€æ¡ç›´çº¿æ¥åŒºåˆ†ð‘¦=0 å’Œð‘¦=1.çš„è§‚æµ‹å€¼æ²¡æœ‰è¿™æ¡çº¿ã€‚è¯·è®°ä½ï¼Œé€»è¾‘å›žå½’æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ï¼Œæ‰€ä»¥åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç†è®ºä¸Šæ‚¨æ— æ³•åˆ¶ä½œç²¾åº¦ä¸º 1 çš„é€»è¾‘å›žå½’æ¨¡åž‹ã€‚

### å¸¦ StatsModels çš„ Python ä¸­çš„é€»è¾‘å›žå½’:ç¤ºä¾‹

æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ StatsModels åŒ…åœ¨ Python ä¸­å®žçŽ°é€»è¾‘å›žå½’ã€‚é€šå¸¸ï¼Œå½“æ‚¨éœ€è¦ä¸Žæ¨¡åž‹å’Œç»“æžœç›¸å…³çš„æ›´å¤šç»Ÿè®¡ç»†èŠ‚æ—¶ï¼Œæ‚¨ä¼šå¸Œæœ›è¿™æ ·ã€‚è¯¥è¿‡ç¨‹ç±»ä¼¼äºŽ scikit-learn çš„è¿‡ç¨‹ã€‚

#### ç¬¬ä¸€æ­¥:å¯¼å…¥åŒ…

ä½ åªéœ€è¦[å¯¼å…¥](https://realpython.com/python-import/)NumPy å’Œ`statsmodels.api`:

```py
import numpy as np
import statsmodels.api as sm
```

çŽ°åœ¨æ‚¨å·²ç»æœ‰äº†æ‚¨éœ€è¦çš„åŒ…ã€‚

#### ç¬¬äºŒæ­¥:èŽ·å–æ•°æ®

æ‚¨å¯ä»¥åƒä½¿ç”¨ scikit-learn ä¸€æ ·èŽ·å¾—è¾“å…¥å’Œè¾“å‡ºã€‚ç„¶è€Œï¼ŒStatsModels æ²¡æœ‰è€ƒè™‘æˆªè·ð‘â‚€ï¼Œæ‚¨éœ€è¦åœ¨`x`ä¸­åŒ…å«é¢å¤–çš„ 1 åˆ—ã€‚ä½ ç”¨`add_constant()`æ¥åš:

```py
x = np.arange(10).reshape(-1, 1)
y = np.array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])
x = sm.add_constant(x)
```

`add_constant()`å°†æ•°ç»„`x`ä½œä¸ºå‚æ•°ï¼Œå¹¶è¿”å›žä¸€ä¸ªæ–°çš„æ•°ç»„ï¼Œå…¶ä¸­åŒ…å«ä¸€åˆ— 1ã€‚è¿™æ˜¯`x`å’Œ`y`çš„æ ·å­:

>>>

```py
>>> x
array([[1., 0.],
 [1., 1.],
 [1., 2.],
 [1., 3.],
 [1., 4.],
 [1., 5.],
 [1., 6.],
 [1., 7.],
 [1., 8.],
 [1., 9.]])
>>> y
array([0, 1, 0, 0, 1, 1, 1, 1, 1, 1])
```

è¿™æ˜¯ä½ çš„æ•°æ®ã€‚`x`çš„ç¬¬ä¸€åˆ—å¯¹åº”äºŽæˆªè·ð‘â‚€.ç¬¬äºŒåˆ—åŒ…å«`x`çš„åŽŸå§‹å€¼ã€‚

#### ç¬¬ä¸‰æ­¥:åˆ›å»ºä¸€ä¸ªæ¨¡åž‹å¹¶è®­ç»ƒå®ƒ

æ‚¨çš„é€»è¾‘å›žå½’æ¨¡åž‹å°†æ˜¯ç±»`statsmodels.discrete.discrete_model.Logit`çš„ä¸€ä¸ªå®žä¾‹ã€‚æ‚¨å¯ä»¥è¿™æ ·åˆ›å»ºä¸€ä¸ª:

>>>

```py
>>> model = sm.Logit(y, x)
```

æ³¨æ„è¿™é‡Œç¬¬ä¸€ä¸ªå‚æ•°æ˜¯`y`ï¼ŒåŽé¢æ˜¯`x`ã€‚

çŽ°åœ¨ï¼Œæ‚¨å·²ç»åˆ›å»ºäº†æ¨¡åž‹ï¼Œåº”è¯¥ç”¨çŽ°æœ‰æ•°æ®æ¥æ‹Ÿåˆå®ƒã€‚ä½ å¯ä»¥ç”¨`.fit()`æ¥åšï¼Œæˆ–è€…ï¼Œå¦‚æžœä½ æƒ³åº”ç”¨ L1 æ­£åˆ™åŒ–ï¼Œç”¨`.fit_regularized()`:

>>>

```py
>>> result = model.fit(method='newton')
Optimization terminated successfully.
 Current function value: 0.350471
 Iterations 7
```

æ¨¡åž‹çŽ°åœ¨å·²ç»å‡†å¤‡å¥½äº†ï¼Œå˜é‡`result`ä¿å­˜äº†æœ‰ç”¨çš„æ•°æ®ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥ç”¨`.params`èŽ·å¾—ð‘â‚€å’Œð‘â‚çš„å€¼:

>>>

```py
>>> result.params
array([-1.972805  ,  0.82240094])
```

èŽ·å¾—çš„æ•°ç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æˆªè·ð‘â‚€ï¼Œè€Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯æ–œçŽ‡ð‘â‚.æ›´å¤šä¿¡æ¯ï¼Œå¯ä»¥çœ‹çœ‹å®˜æ–¹å…³äºŽ [`Logit`](https://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.Logit.html) çš„æ–‡æ¡£ï¼Œè¿˜æœ‰[`.fit()`](https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.Logit.fit.html)[`.fit_regularized()`](https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.Logit.fit.html)ã€‚

#### æ­¥éª¤ 4:è¯„ä¼°æ¨¡åž‹

æ‚¨å¯ä»¥ä½¿ç”¨`results`èŽ·å¾—é¢„æµ‹è¾“å‡ºç­‰äºŽ 1 çš„æ¦‚çŽ‡:

>>>

```py
>>> result.predict(x)
array([0.12208792, 0.24041529, 0.41872657, 0.62114189, 0.78864861,
 0.89465521, 0.95080891, 0.97777369, 0.99011108, 0.99563083])
```

è¿™äº›æ¦‚çŽ‡æ˜¯ç”¨`.predict()`è®¡ç®—å‡ºæ¥çš„ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å®ƒä»¬çš„å€¼æ¥èŽ·å¾—å®žé™…çš„é¢„æµ‹è¾“å‡º:

>>>

```py
>>> (result.predict(x) >= 0.5).astype(int)
array([0, 0, 0, 1, 1, 1, 1, 1, 1, 1])
```

èŽ·å¾—çš„æ•°ç»„åŒ…å«é¢„æµ‹çš„è¾“å‡ºå€¼ã€‚å¦‚æ‚¨æ‰€è§ï¼Œð‘â‚€ã€ð‘â‚ä»¥åŠé€šè¿‡ scikit-learn å’Œ StatsModels èŽ·å¾—çš„æ¦‚çŽ‡æ˜¯ä¸åŒçš„ã€‚è¿™æ˜¯åº”ç”¨ä¸åŒçš„è¿­ä»£å’Œè¿‘ä¼¼ç¨‹åºå’Œå‚æ•°çš„ç»“æžœã€‚ç„¶è€Œï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å°†èŽ·å¾—ä¸Žä½¿ç”¨ scikit-learn æ—¶ç›¸åŒçš„é¢„æµ‹è¾“å‡ºã€‚

æ‚¨å¯ä»¥ç”¨`.pred_table()`èŽ·å¾—æ··æ·†çŸ©é˜µ:

>>>

```py
>>> result.pred_table()
array([[2., 1.],
 [1., 6.]])
```

è¿™ä¸ªä¾‹å­ä¸Žæ‚¨ä½¿ç”¨ scikit-learn æ—¶çš„ä¾‹å­ç›¸åŒï¼Œå› ä¸ºé¢„æµ‹çš„è¾“å‡ºæ˜¯ç›¸ç­‰çš„ã€‚ä½¿ç”¨ StatsModels å’Œ scikit-learn èŽ·å¾—çš„æ··æ·†çŸ©é˜µçš„å…ƒç´ ç±»åž‹ä¸åŒ(æµ®ç‚¹æ•°å’Œæ•´æ•°)ã€‚

`.summary()`å’Œ`.summary2()`èŽ·å–åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½æœ‰ç”¨çš„è¾“å‡ºæ•°æ®:

>>>

```py
>>> result.summary()
<class 'statsmodels.iolib.summary.Summary'>
"""
 Logit Regression Results 
==============================================================================
Dep. Variable:                      y   No. Observations:                   10
Model:                          Logit   Df Residuals:                        8
Method:                           MLE   Df Model:                            1
Date:                Sun, 23 Jun 2019   Pseudo R-squ.:                  0.4263
Time:                        21:43:49   Log-Likelihood:                -3.5047
converged:                       True   LL-Null:                       -6.1086
 LLR p-value:                   0.02248
==============================================================================
 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
const         -1.9728      1.737     -1.136      0.256      -5.377       1.431
x1             0.8224      0.528      1.557      0.119      -0.213       1.858
==============================================================================
"""
>>> result.summary2()
<class 'statsmodels.iolib.summary2.Summary'>
"""
 Results: Logit
===============================================================
Model:              Logit            Pseudo R-squared: 0.426 
Dependent Variable: y                AIC:              11.0094
Date:               2019-06-23 21:43 BIC:              11.6146
No. Observations:   10               Log-Likelihood:   -3.5047
Df Model:           1                LL-Null:          -6.1086
Df Residuals:       8                LLR p-value:      0.022485
Converged:          1.0000           Scale:            1.0000 
No. Iterations:     7.0000 
-----------------------------------------------------------------
 Coef.    Std.Err.      z      P>|z|     [0.025   0.975]
-----------------------------------------------------------------
const    -1.9728     1.7366   -1.1360   0.2560   -5.3765   1.4309
x1        0.8224     0.5281    1.5572   0.1194   -0.2127   1.8575
===============================================================

"""
```

è¿™äº›æ˜¯å¸¦æœ‰å€¼çš„è¯¦ç»†æŠ¥å‘Šï¼Œæ‚¨å¯ä»¥é€šè¿‡é€‚å½“çš„æ–¹æ³•å’Œå±žæ€§èŽ·å¾—è¿™äº›å€¼ã€‚æ¬²äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹ä¸Ž [`LogitResults`](https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.LogitResults.html) ç›¸å…³çš„å®˜æ–¹æ–‡æ¡£ã€‚

[*Remove ads*](/account/join/)

### Python ä¸­çš„é€»è¾‘å›žå½’:æ‰‹å†™è¯†åˆ«

å‰é¢çš„ä¾‹å­è¯´æ˜Žäº†é€»è¾‘å›žå½’åœ¨ Python ä¸­çš„å®žçŽ°ï¼Œä»¥åŠä¸Žè¯¥æ–¹æ³•ç›¸å…³çš„ä¸€äº›ç»†èŠ‚ã€‚ä¸‹ä¸€ä¸ªä¾‹å­å°†å‘æ‚¨å±•ç¤ºå¦‚ä½•ä½¿ç”¨é€»è¾‘å›žå½’æ¥è§£å†³çŽ°å®žä¸–ç•Œä¸­çš„åˆ†ç±»é—®é¢˜ã€‚è¿™ç§æ–¹æ³•ä¸Žæ‚¨å·²ç»çœ‹åˆ°çš„éžå¸¸ç›¸ä¼¼ï¼Œä½†æ˜¯æœ‰ä¸€ä¸ªæ›´å¤§çš„æ•°æ®é›†å’Œå‡ ä¸ªé¢å¤–çš„é—®é¢˜ã€‚

è¿™ä¸ªä¾‹å­æ˜¯å…³äºŽ**å›¾åƒè¯†åˆ«**çš„ã€‚æ›´å‡†ç¡®åœ°è¯´ï¼Œæ‚¨å°†è‡´åŠ›äºŽæ‰‹å†™æ•°å­—çš„è¯†åˆ«ã€‚æ‚¨å°†ä½¿ç”¨åŒ…å« 1797 ä¸ªè§‚å¯Ÿå€¼çš„æ•°æ®é›†ï¼Œæ¯ä¸ªè§‚å¯Ÿå€¼éƒ½æ˜¯ä¸€ä¸ªæ‰‹å†™æ•°å­—çš„å›¾åƒã€‚æ¯å¼ å›¾ç‰‡ 64 pxï¼Œå®½ 8 pxï¼Œé«˜ 8 pxã€‚

**æ³¨æ„:**è¦äº†è§£å…³äºŽè¿™ä¸ªæ•°æ®é›†çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·æŸ¥çœ‹å®˜æ–¹çš„[æ–‡æ¡£](https://scikit-learn.org/stable/datasets/index.html#digits-dataset)ã€‚

**è¾“å…¥(ð±)** æ˜¯å…·æœ‰ 64 ä¸ªç»´åº¦æˆ–å€¼çš„å‘é‡ã€‚æ¯ä¸ªè¾“å…¥å‘é‡æè¿°ä¸€å¹…å›¾åƒã€‚64 ä¸ªå€¼ä¸­çš„æ¯ä¸€ä¸ªä»£è¡¨å›¾åƒçš„ä¸€ä¸ªåƒç´ ã€‚è¾“å…¥å€¼æ˜¯ 0 åˆ° 16 ä¹‹é—´çš„æ•´æ•°ï¼Œå–å†³äºŽç›¸åº”åƒç´ çš„ç°åº¦ã€‚æ¯æ¬¡è§‚å¯Ÿçš„**è¾“å‡º(ð‘¦)** ä¸º 0 åˆ° 9 ä¹‹é—´çš„æ•´æ•°ï¼Œä¸Žå›¾åƒä¸Šçš„æ•°å­—ä¸€è‡´ã€‚æ€»å…±æœ‰åä¸ªç±»ï¼Œæ¯ä¸ªç±»å¯¹åº”ä¸€ä¸ªå›¾åƒã€‚

#### ç¬¬ä¸€æ­¥:å¯¼å…¥åŒ…

æ‚¨éœ€è¦ä»Ž scikit-learn å¯¼å…¥ Matplotlibã€NumPy å’Œå‡ ä¸ªå‡½æ•°å’Œç±»:

```py
import matplotlib.pyplot as plt
import numpy as np
from sklearn.datasets import load_digits
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
```

å°±æ˜¯è¿™æ ·ï¼æ‚¨æ‹¥æœ‰æ‰§è¡Œåˆ†ç±»æ‰€éœ€çš„æ‰€æœ‰åŠŸèƒ½ã€‚

#### æ­¥éª¤ 2a:èŽ·å–æ•°æ®

æ‚¨å¯ä»¥ä½¿ç”¨`load_digits()`ç›´æŽ¥ä»Ž scikit-learn èŽ·å–æ•°æ®é›†ã€‚å®ƒè¿”å›žè¾“å…¥å’Œè¾“å‡ºçš„å…ƒç»„:

```py
x, y = load_digits(return_X_y=True)
```

çŽ°åœ¨ä½ æœ‰äº†æ•°æ®ã€‚è¿™æ˜¯`x`å’Œ`y`çš„æ ·å­:

>>>

```py
>>> x
array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],
 [ 0.,  0.,  0., ..., 10.,  0.,  0.],
 [ 0.,  0.,  0., ..., 16.,  9.,  0.],
 ...,
 [ 0.,  0.,  1., ...,  6.,  0.,  0.],
 [ 0.,  0.,  2., ..., 12.,  0.,  0.],
 [ 0.,  0., 10., ..., 12.,  1.,  0.]])
>>> y
array([0, 1, 2, ..., 8, 9, 8])
```

è¿™å°±æ˜¯ä½ è¦å¤„ç†çš„æ•°æ®ã€‚`x`æ˜¯ä¸€ä¸ª 1797 è¡Œ 64 åˆ—çš„å¤šç»´æ•°ç»„ã€‚å®ƒåŒ…å«ä»Ž 0 åˆ° 16 çš„æ•´æ•°ã€‚`y`æ˜¯ä¸€ä¸ªä¸€ç»´æ•°ç»„ï¼ŒåŒ…å« 1797 ä¸ª 0 åˆ° 9 ä¹‹é—´çš„æ•´æ•°ã€‚

#### æ­¥éª¤ 2b:åˆ†å‰²æ•°æ®

å°†æ‚¨æ­£åœ¨å¤„ç†çš„æ•°æ®é›†åˆ†æˆä¸¤ä¸ªå­é›†æ˜¯ä¸€ç§å¾ˆå¥½ä¸”è¢«å¹¿æ³›é‡‡ç”¨çš„åšæ³•ã€‚è¿™äº›æ˜¯**è®­ç»ƒé›†**å’Œ**æµ‹è¯•é›†**ã€‚è¿™ç§åˆ†å‰²é€šå¸¸æ˜¯éšæœºè¿›è¡Œçš„ã€‚æ‚¨åº”è¯¥ä½¿ç”¨è®­ç»ƒé›†æ¥é€‚åº”æ‚¨çš„æ¨¡åž‹ã€‚ä¸€æ—¦æ¨¡åž‹è¢«æ‹Ÿåˆï¼Œæ‚¨å°±å¯ä»¥ç”¨æµ‹è¯•é›†æ¥è¯„ä¼°å®ƒçš„æ€§èƒ½ã€‚é‡è¦çš„æ˜¯ä¸è¦åœ¨æ‹Ÿåˆæ¨¡åž‹çš„è¿‡ç¨‹ä¸­ä½¿ç”¨æµ‹è¯•é›†ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿå¯¹æ¨¡åž‹è¿›è¡Œå…¬æ­£çš„è¯„ä¼°ã€‚

å°†æ•°æ®é›†åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ä¸€ç§æ–¹æ³•æ˜¯[åº”ç”¨`train_test_split()`](https://realpython.com/train-test-split-python-data/) :

```py
x_train, x_test, y_train, y_test =\
    train_test_split(x, y, test_size=0.2, random_state=0)
```

[`train_test_split()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) æŽ¥å—`x`å’Œ`y`ã€‚å®ƒè¿˜éœ€è¦`test_size`æ¥ç¡®å®šæµ‹è¯•é›†çš„å¤§å°ï¼Œä»¥åŠ`random_state`æ¥å®šä¹‰ä¼ªéšæœºæ•°å‘ç”Ÿå™¨çš„çŠ¶æ€ï¼Œä»¥åŠå…¶ä»–å¯é€‰å‚æ•°ã€‚è¯¥å‡½æ•°è¿”å›žä¸€ä¸ªåŒ…å«å››ä¸ªæ•°ç»„çš„åˆ—è¡¨[:](https://realpython.com/courses/lists-tuples-python/)

1.  **`x_train`:**`x`ä¸­ç”¨äºŽæ‹Ÿåˆæ¨¡åž‹çš„éƒ¨åˆ†
2.  **`x_test`:**`x`ä¸­ç”¨äºŽè¯„ä¼°æ¨¡åž‹çš„éƒ¨åˆ†
3.  **`y_train`:**`y`ä¸­å¯¹åº”`x_train`çš„éƒ¨åˆ†
4.  **`y_test`:**`y`ä¸­å¯¹åº”`x_test`çš„éƒ¨åˆ†

ä¸€æ—¦ä½ çš„æ•°æ®è¢«åˆ†å‰²ï¼Œä½ å¯ä»¥å¿˜è®°`x_test`å’Œ`y_test`ç›´åˆ°ä½ å®šä¹‰ä½ çš„æ¨¡åž‹ã€‚

#### æ­¥éª¤ 2c:æ ‡åº¦æ•°æ®

**æ ‡å‡†åŒ–**æ˜¯ä»¥æŸç§æ–¹å¼è½¬æ¢æ•°æ®ï¼Œä½¿æ¯ä¸€åˆ—çš„å‡å€¼å˜å¾—ç­‰äºŽé›¶ï¼Œæ¯ä¸€åˆ—çš„æ ‡å‡†å·®ä¸ºä¸€çš„è¿‡ç¨‹ã€‚è¿™æ ·ï¼Œæ‰€æœ‰åˆ—çš„æ¯”ä¾‹éƒ½ç›¸åŒã€‚é‡‡å–ä»¥ä¸‹æ­¥éª¤æ¥æ ‡å‡†åŒ–æ‚¨çš„æ•°æ®:

1.  **è®¡ç®—**æ¯åˆ—çš„å¹³å‡å€¼å’Œæ ‡å‡†åå·®ã€‚
2.  **ä»Žæ¯ä¸ªå…ƒç´ ä¸­å‡åŽ»**å¯¹åº”çš„å¹³å‡å€¼ã€‚
3.  **å°†**å¾—åˆ°çš„å·®å€¼é™¤ä»¥å¯¹åº”çš„æ ‡å‡†å·®ã€‚

å°†ç”¨äºŽé€»è¾‘å›žå½’çš„è¾“å…¥æ•°æ®æ ‡å‡†åŒ–æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åšæ³•ï¼Œå°½ç®¡åœ¨è®¸å¤šæƒ…å†µä¸‹è¿™æ˜¯ä¸å¿…è¦çš„ã€‚æ ‡å‡†åŒ–å¯èƒ½ä¼šæé«˜ç®—æ³•çš„æ€§èƒ½ã€‚å¦‚æžœæ‚¨éœ€è¦æ¯”è¾ƒå’Œè§£é‡Šæƒé‡ï¼Œè¿™ä¼šå¾ˆæœ‰å¸®åŠ©ã€‚è¿™åœ¨åº”ç”¨æƒ©ç½šæ—¶å¾ˆé‡è¦ï¼Œå› ä¸ºç®—æ³•å®žé™…ä¸Šæ˜¯å¯¹å¤§çš„æƒé‡å€¼è¿›è¡Œæƒ©ç½šã€‚

æ‚¨å¯ä»¥é€šè¿‡åˆ›å»ºä¸€ä¸ª [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) çš„å®žä¾‹å¹¶åœ¨å…¶ä¸Šè°ƒç”¨`.fit_transform()`æ¥æ ‡å‡†åŒ–æ‚¨çš„è¾“å…¥:

```py
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
```

`.fit_transform()`ä½¿`StandardScaler`çš„å®žä¾‹é€‚åˆä½œä¸ºå‚æ•°ä¼ é€’çš„æ•°ç»„ï¼Œè½¬æ¢è¯¥æ•°ç»„ï¼Œå¹¶è¿”å›žæ–°çš„æ ‡å‡†åŒ–æ•°ç»„ã€‚çŽ°åœ¨ï¼Œ`x_train`æ˜¯ä¸€ä¸ªæ ‡å‡†åŒ–çš„è¾“å…¥æ•°ç»„ã€‚

#### ç¬¬ä¸‰æ­¥:åˆ›å»ºä¸€ä¸ªæ¨¡åž‹å¹¶è®­ç»ƒå®ƒ

è¿™ä¸€æ­¥ä¸Žå‰é¢çš„ä¾‹å­éžå¸¸ç›¸ä¼¼ã€‚å”¯ä¸€çš„åŒºåˆ«æ˜¯æ‚¨ä½¿ç”¨`x_train`å’Œ`y_train`å­é›†æ¥æ‹Ÿåˆæ¨¡åž‹ã€‚åŒæ ·ï¼Œæ‚¨åº”è¯¥åˆ›å»ºä¸€ä¸ª`LogisticRegression`çš„å®žä¾‹ï¼Œå¹¶åœ¨å…¶ä¸Šè°ƒç”¨`.fit()`:

```py
model = LogisticRegression(solver='liblinear', C=0.05, multi_class='ovr',
                           random_state=0)
model.fit(x_train, y_train)
```

å½“æ‚¨å¤„ç†ä¸¤ä¸ªä»¥ä¸Šç±»çš„é—®é¢˜æ—¶ï¼Œæ‚¨åº”è¯¥æŒ‡å®š`LogisticRegression`çš„`multi_class`å‚æ•°ã€‚å®ƒå†³å®šäº†å¦‚ä½•è§£å†³é—®é¢˜:

*   **`'ovr'`** è¯´è¦ä½¿äºŒè¿›åˆ¶é€‚åˆå„ä¸ªé˜¶å±‚ã€‚
*   **`'multinomial'`** è¡¨ç¤ºåº”ç”¨å¤šé¡¹æŸå¤±æ‹Ÿåˆã€‚

æœ€åŽä¸€æ¡è¯­å¥äº§ç”Ÿä»¥ä¸‹è¾“å‡ºï¼Œå› ä¸º`.fit()`è¿”å›žæ¨¡åž‹æœ¬èº«:

```py
LogisticRegression(C=0.05, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='ovr', n_jobs=None, penalty='l2', random_state=0,
                   solver='liblinear', tol=0.0001, verbose=0, warm_start=False)
```

è¿™äº›æ˜¯ä½ çš„æ¨¡åž‹çš„å‚æ•°ã€‚çŽ°åœ¨å·²ç»å®šä¹‰å¥½äº†ï¼Œå¯ä»¥å¼€å§‹ä¸‹ä¸€æ­¥äº†ã€‚

#### æ­¥éª¤ 4:è¯„ä¼°æ¨¡åž‹

æ‚¨åº”è¯¥åƒåœ¨å‰é¢çš„ä¾‹å­ä¸­é‚£æ ·è¯„ä¼°æ‚¨çš„æ¨¡åž‹ï¼ŒåŒºåˆ«åœ¨äºŽæ‚¨å°†ä¸»è¦ä½¿ç”¨`x_test`å’Œ`y_test`ï¼Œå®ƒä»¬æ˜¯ä¸ç”¨äºŽè®­ç»ƒçš„å­é›†ã€‚å¦‚æžœä½ å·²ç»å†³å®šæ ‡å‡†åŒ–`x_train`ï¼Œé‚£ä¹ˆèŽ·å¾—çš„æ¨¡åž‹ä¾èµ–äºŽç¼©æ”¾åŽçš„æ•°æ®ï¼Œæ‰€ä»¥`x_test`ä¹Ÿåº”è¯¥ç”¨`StandardScaler`çš„åŒä¸€ä¸ªå®žä¾‹è¿›è¡Œç¼©æ”¾:

```py
x_test = scaler.transform(x_test)
```

è¿™å°±æ˜¯ä½ å¦‚ä½•èŽ·å¾—ä¸€ä¸ªæ–°çš„ï¼Œé€‚å½“æ¯”ä¾‹çš„`x_test`ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨ä½¿ç”¨`.transform()`ï¼Œå®ƒåªè½¬æ¢å‚æ•°ï¼Œè€Œä¸å®‰è£…ç¼©æ”¾å™¨ã€‚

æ‚¨å¯ä»¥é€šè¿‡`.predict()`èŽ·å¾—é¢„æµ‹çš„è¾“å‡º:

```py
y_pred = model.predict(x_test)
```

å˜é‡`y_pred`çŽ°åœ¨è¢«ç»‘å®šåˆ°é¢„æµ‹è¾“å‡ºçš„æ•°ç»„ã€‚æ³¨æ„ï¼Œè¿™é‡Œä½¿ç”¨äº†`x_test`ä½œä¸ºå‚æ•°ã€‚

æ‚¨å¯ä»¥é€šè¿‡`.score()`èŽ·å¾—ç²¾åº¦:

>>>

```py
>>> model.score(x_train, y_train)
0.964509394572025
>>> model.score(x_test, y_test)
0.9416666666666667
```

å®žé™…ä¸Šï¼Œæ‚¨å¯ä»¥èŽ·å¾—ä¸¤ä¸ªç²¾åº¦å€¼ï¼Œä¸€ä¸ªæ˜¯é€šè¿‡è®­ç»ƒé›†èŽ·å¾—çš„ï¼Œå¦ä¸€ä¸ªæ˜¯é€šè¿‡æµ‹è¯•é›†èŽ·å¾—çš„ã€‚æ¯”è¾ƒè¿™ä¸¤è€…å¯èƒ½æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œå› ä¸ºè®­ç»ƒé›†å‡†ç¡®æ€§é«˜å¾—å¤šçš„æƒ…å†µå¯èƒ½è¡¨æ˜Žè¿‡åº¦æ‹Ÿåˆã€‚æµ‹è¯•é›†çš„å‡†ç¡®æ€§ä¸Žè¯„ä¼°æœªçŸ¥æ•°æ®çš„æ€§èƒ½æ›´ç›¸å…³ï¼Œå› ä¸ºå®ƒæ²¡æœ‰åè§ã€‚

ç”¨`confusion_matrix()`å¯ä»¥å¾—åˆ°æ··æ·†çŸ©é˜µ:

>>>

```py
>>> confusion_matrix(y_test, y_pred)
array([[27,  0,  0,  0,  0,  0,  0,  0,  0,  0],
 [ 0, 32,  0,  0,  0,  0,  1,  0,  1,  1],
 [ 1,  1, 33,  1,  0,  0,  0,  0,  0,  0],
 [ 0,  0,  1, 28,  0,  0,  0,  0,  0,  0],
 [ 0,  0,  0,  0, 29,  0,  0,  1,  0,  0],
 [ 0,  0,  0,  0,  0, 39,  0,  0,  0,  1],
 [ 0,  1,  0,  0,  0,  0, 43,  0,  0,  0],
 [ 0,  0,  0,  0,  0,  0,  0, 39,  0,  0],
 [ 0,  2,  1,  2,  0,  0,  0,  1, 33,  0],
 [ 0,  0,  0,  1,  0,  1,  0,  2,  1, 36]])
```

èŽ·å¾—çš„æ··æ·†çŸ©é˜µå¾ˆå¤§ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒæœ‰ 100 ä¸ªæ•°å­—ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå°†å®ƒå¯è§†åŒ–å¯èƒ½ä¼šéžå¸¸æœ‰ç”¨:

```py
cm = confusion_matrix(y_test, y_pred)

fig, ax = plt.subplots(figsize=(8, 8))
ax.imshow(cm)
ax.grid(False)
ax.set_xlabel('Predicted outputs', fontsize=font_size, color='black')
ax.set_ylabel('Actual outputs', fontsize=font_size, color='black')
ax.xaxis.set(ticks=range(10))
ax.yaxis.set(ticks=range(10))
ax.set_ylim(9.5, -0.5)
for i in range(10):
    for j in range(10):
        ax.text(j, i, cm[i, j], ha='center', va='center', color='white')
plt.show()
```

ä¸Šé¢çš„ä»£ç ç”Ÿæˆäº†ä¸‹å›¾çš„æ··æ·†çŸ©é˜µ:

[![Classification Confusion Matrix](img/64fe4a9fb8780d2dd3c3f709f6076de7.png)](https://files.realpython.com/media/log-reg-9.65eb08059e5b.png)

è¿™æ˜¯ä¸€å¼ çƒ­å›¾ï¼Œç”¨æ•°å­—å’Œé¢œè‰²è¯´æ˜Žäº†æ··æ·†çŸ©é˜µã€‚æ‚¨å¯ä»¥çœ‹åˆ°ç´«è‰²é˜´å½±ä»£è¡¨å°æ•°å­—(å¦‚ 0ã€1 æˆ– 2)ï¼Œè€Œç»¿è‰²å’Œé»„è‰²ä»£è¡¨å¤§å¾—å¤šçš„æ•°å­—(27 åŠä»¥ä¸Š)ã€‚

ä¸»å¯¹è§’çº¿ä¸Šçš„æ•°å­—(27ï¼Œ32ï¼Œâ€¦ï¼Œ36)æ˜¾ç¤ºäº†æµ‹è¯•é›†ä¸­æ­£ç¡®é¢„æµ‹çš„æ•°é‡ã€‚ä¾‹å¦‚ï¼Œæœ‰ 27 ä¸ªå›¾åƒçš„å€¼ä¸º 0ï¼Œ32 ä¸ªå›¾åƒçš„å€¼ä¸º 1ï¼Œä¾æ­¤ç±»æŽ¨ï¼Œè¿™äº›å›¾åƒè¢«æ­£ç¡®åˆ†ç±»ã€‚å…¶ä»–æ•°å­—å¯¹åº”ä¸æ­£ç¡®çš„é¢„æµ‹ã€‚ä¾‹å¦‚ï¼Œç¬¬ä¸‰è¡Œç¬¬ä¸€åˆ—ä¸­çš„æ•°å­— 1 æ˜¾ç¤ºæœ‰ä¸€ä¸ªæ•°å­— 2 è¢«é”™è¯¯åœ°åˆ†ç±»ä¸º 0 çš„å›¾åƒã€‚

æœ€åŽï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`classification_report()`èŽ·å¾—å­—ç¬¦ä¸²æˆ–å­—å…¸å½¢å¼çš„åˆ†ç±»æŠ¥å‘Š:

>>>

```py
>>> print(classification_report(y_test, y_pred))
 precision    recall  f1-score   support

 0       0.96      1.00      0.98        27
 1       0.89      0.91      0.90        35
 2       0.94      0.92      0.93        36
 3       0.88      0.97      0.92        29
 4       1.00      0.97      0.98        30
 5       0.97      0.97      0.97        40
 6       0.98      0.98      0.98        44
 7       0.91      1.00      0.95        39
 8       0.94      0.85      0.89        39
 9       0.95      0.88      0.91        41

 accuracy                           0.94       360
 macro avg       0.94      0.94      0.94       360
weighted avg       0.94      0.94      0.94       360
```

è¯¥æŠ¥å‘Šæ˜¾ç¤ºäº†é™„åŠ ä¿¡æ¯ï¼Œå¦‚å¯¹æ¯ä¸ªæ•°å­—è¿›è¡Œåˆ†ç±»çš„æ”¯æŒå’Œç²¾åº¦ã€‚

[*Remove ads*](/account/join/)

## è¶…è¶Š Python ä¸­çš„é€»è¾‘å›žå½’

é€»è¾‘å›žå½’æ˜¯ä¸€ç§åŸºæœ¬çš„åˆ†ç±»æŠ€æœ¯ã€‚è¿™æ˜¯ä¸€ä¸ªç›¸å¯¹ç®€å•çš„çº¿æ€§åˆ†ç±»å™¨ã€‚å°½ç®¡é€»è¾‘å›žå½’ç®€å•ä¸”å—æ¬¢è¿Žï¼Œä½†åœ¨æŸäº›æƒ…å†µä¸‹(å°¤å…¶æ˜¯é«˜åº¦å¤æ‚çš„æ¨¡åž‹),é€»è¾‘å›žå½’å¹¶ä¸å¥æ•ˆã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å…¶ä»–åˆ†ç±»æŠ€æœ¯:

*   k-æœ€è¿‘é‚»
*   æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
*   æ”¯æŒå‘é‡æœº
*   å†³ç­–æ ‘
*   éšæœºæ£®æž—
*   ç¥žç»ç½‘ç»œ

å¹¸è¿çš„æ˜¯ï¼Œæœ‰å‡ ä¸ªå…¨é¢çš„ç”¨äºŽæœºå™¨å­¦ä¹ çš„ Python åº“å®žçŽ°äº†è¿™äº›æŠ€æœ¯ã€‚ä¾‹å¦‚ï¼Œæ‚¨åœ¨è¿™é‡Œçœ‹åˆ°çš„è¿è¡Œä¸­çš„è½¯ä»¶åŒ… scikit-learn å®žçŽ°äº†ä¸Šè¿°æ‰€æœ‰æŠ€æœ¯ï¼Œä½†ç¥žç»ç½‘ç»œé™¤å¤–ã€‚

å¯¹äºŽæ‰€æœ‰è¿™äº›æŠ€æœ¯ï¼Œscikit-learn æä¾›äº†åˆé€‚çš„ç±»ï¼ŒåŒ…æ‹¬`model.fit()`ã€`model.predict_proba()`ã€`model.predict()`ã€`model.score()`ç­‰æ–¹æ³•ã€‚æ‚¨å¯ä»¥å°†å®ƒä»¬ä¸Ž`train_test_split()`ã€`confusion_matrix()`ã€`classification_report()`ç­‰ç»„åˆä½¿ç”¨ã€‚

ç¥žç»ç½‘ç»œ(åŒ…æ‹¬æ·±åº¦ç¥žç»ç½‘ç»œ)å¯¹äºŽåˆ†ç±»é—®é¢˜å·²ç»å˜å¾—éžå¸¸æµè¡Œã€‚åƒ [TensorFlowã€PyTorch](https://realpython.com/pytorch-vs-tensorflow/) æˆ– [Keras](https://keras.io/) è¿™æ ·çš„åº“ä¸ºè¿™äº›ç±»åž‹çš„æ¨¡åž‹æä¾›äº†åˆé€‚çš„ã€ [performant](https://realpython.com/numpy-tensorflow-performance/) å’Œå¼ºå¤§çš„æ”¯æŒã€‚

## ç»“è®º

ä½ çŽ°åœ¨çŸ¥é“ä»€ä¹ˆæ˜¯é€»è¾‘å›žå½’ï¼Œä»¥åŠå¦‚ä½•ç”¨ Python å®žçŽ° T2 åˆ†ç±»ã€‚æ‚¨å·²ç»ä½¿ç”¨äº†è®¸å¤šå¼€æºåŒ…ï¼ŒåŒ…æ‹¬ NumPyï¼Œæ¥å¤„ç†æ•°ç»„å’Œ Matplotlib ä»¥å¯è§†åŒ–ç»“æžœã€‚æ‚¨è¿˜ä½¿ç”¨äº† scikit-learn å’Œ StatsModels æ¥åˆ›å»ºã€æ‹Ÿåˆã€è¯„ä¼°å’Œåº”ç”¨æ¨¡åž‹ã€‚

é€šå¸¸ï¼ŒPython ä¸­çš„é€»è¾‘å›žå½’æœ‰ä¸€ä¸ªç®€å•ä¸”ç”¨æˆ·å‹å¥½çš„å®žçŽ°ã€‚å®ƒé€šå¸¸ç”±ä»¥ä¸‹æ­¥éª¤ç»„æˆ:

1.  **å¯¼å…¥**åŒ…ã€å‡½æ•°å’Œç±»
2.  **èŽ·å–**è¦å¤„ç†çš„æ•°æ®ï¼Œå¦‚æžœåˆé€‚çš„è¯ï¼Œå¯¹å…¶è¿›è¡Œè½¬æ¢
3.  **åˆ›å»º**åˆ†ç±»æ¨¡åž‹ï¼Œå¹¶ç”¨çŽ°æœ‰æ•°æ®å¯¹å…¶è¿›è¡Œè®­ç»ƒ(æˆ–æ‹Ÿåˆ)
4.  è¯„ä¼°ä½ çš„æ¨¡åž‹ï¼Œçœ‹çœ‹å®ƒçš„æ€§èƒ½æ˜¯å¦ä»¤äººæ»¡æ„
5.  åº”ç”¨ä½ çš„æ¨¡åž‹è¿›è¡Œé¢„æµ‹

åœ¨ç†è§£æœºå™¨å­¦ä¹ æœ€é‡è¦çš„é¢†åŸŸä¹‹ä¸€æ–¹é¢ï¼Œä½ å·²ç»èµ°äº†å¾ˆé•¿çš„è·¯ï¼å¦‚æžœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–æ„è§ï¼Œè¯·å†™åœ¨ä¸‹é¢çš„è¯„è®ºåŒºã€‚*********