<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Chapter 8 - Run a production-ready system</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Chapter 8 - Run a production-ready system</h1>
<blockquote>原文：<a href="https://www.thedigitalcatbooks.com/pycabook-chapter-08/">https://www.thedigitalcatbooks.com/pycabook-chapter-08/</a></blockquote>
    <blockquote><p>Vilos Cohaagen said troops would be used to ensure full production.</p><cite>Total Recall, 1990</cite></blockquote><p>Now that we developed a repository that connects with PostgreSQL we can discuss how to properly set up the application to run a production-ready system. This part is not strictly related to the clean architecture, but I think it's worth completing the example, showing how the system that we designed can end up being the core of a real web application.</p><p>Clearly, the definition "production-ready" refers to many different configuration that ultimately depend on the load and the business requirements of the system. As the goal is to show a complete example and not to cover real production requirements I will show a solution that uses real external systems like PostgreSQL and Nginx, without being too concerned about performances.</p><h2 id="build-a-web-stack">Build a web stack</h2><p>Now that we successfully containerised the tests we might try to devise a production-ready setup of the whole application, running both a web server and a database in Docker containers. Once again, I will follow the approach that I show in the series of posts I mentioned in one of the previous sections.</p><p>To run a production-ready infrastructure we need to put a WSGI server in front of the web framework and a Web server in front of it. We will also need to run a database container that we will initialise only once.</p><p>The steps towards a production-ready configuration are not complicated and the final setup won't be ultimately too different form what we already did for the tests. We need to</p><ol><li>Create a JSON configuration with environment variables suitable for production</li><li>Create a suitable configuration for Docker Compose and configure the containers</li><li>Add commands to <code>manage.py</code> that allow us to control the processes</li></ol><p>Let's create the file <code>config/production.json</code>, which is very similar to the one we created for the tests</p><div class="code code-json"><div class="title"><code>config/production.json</code></div><div class="content"><div class="highlight"><pre><span/><span class="p">[</span>
  <span class="p">{</span>
    <span class="nt">"name"</span><span class="p">:</span> <span class="s2">"FLASK_ENV"</span><span class="p">,</span>
    <span class="nt">"value"</span><span class="p">:</span> <span class="s2">"production"</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="nt">"name"</span><span class="p">:</span> <span class="s2">"FLASK_CONFIG"</span><span class="p">,</span>
    <span class="nt">"value"</span><span class="p">:</span> <span class="s2">"production"</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="nt">"name"</span><span class="p">:</span> <span class="s2">"POSTGRES_DB"</span><span class="p">,</span>
    <span class="nt">"value"</span><span class="p">:</span> <span class="s2">"postgres"</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="nt">"name"</span><span class="p">:</span> <span class="s2">"POSTGRES_USER"</span><span class="p">,</span>
    <span class="nt">"value"</span><span class="p">:</span> <span class="s2">"postgres"</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="nt">"name"</span><span class="p">:</span> <span class="s2">"POSTGRES_HOSTNAME"</span><span class="p">,</span>
    <span class="nt">"value"</span><span class="p">:</span> <span class="s2">"localhost"</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="nt">"name"</span><span class="p">:</span> <span class="s2">"POSTGRES_PORT"</span><span class="p">,</span>
    <span class="nt">"value"</span><span class="p">:</span> <span class="s2">"5432"</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="nt">"name"</span><span class="p">:</span> <span class="s2">"POSTGRES_PASSWORD"</span><span class="p">,</span>
    <span class="nt">"value"</span><span class="p">:</span> <span class="s2">"postgres"</span>
  <span class="p">},</span>
  <span class="p">{</span>
    <span class="nt">"name"</span><span class="p">:</span> <span class="s2">"APPLICATION_DB"</span><span class="p">,</span>
    <span class="nt">"value"</span><span class="p">:</span> <span class="s2">"application"</span>
  <span class="p">}</span>
<span class="p">]</span>
</pre></div>
</div></div><p>Please note that now both <code>FLASK_ENV</code> and <code>FLASK_CONFIG</code> are set to <code>production</code>. Please remember that the first is an internal Flask variable with two possible fixed values (<code>development</code> and <code>production</code>), while the second one is an arbitrary name that has the final effect of loading a specific configuration object (<code>ProductionConfig</code> in this case). I also changed <code>POSTGRES_PORT</code> back to the default <code>5432</code> and <code>APPLICATION_DB</code> to <code>application</code> (an arbitrary name).</p><p>Let's define which containers we want to run in our production environment, and how we want to connect them. We need a production-ready database and I will use Postgres, as I already did during the tests. Then we need to wrap Flask with a production HTTP server, and for this job I will use <code>gunicorn</code>. Last, we need a Web Server to act as load balancer.</p><p>The file <code>docker/production.yml</code> will contain the Docker Compose configuration, according to the convention we defined in <code>manage.py</code></p><div class="code code-yaml"><div class="title"><code>docker/production.yml</code></div><div class="content"><div class="highlight"><pre><span/><span class="nt">version</span><span class="p">:</span> <span class="s">'3.8'</span>

<span class="nt">services</span><span class="p">:</span>
  <span class="nt">db</span><span class="p">:</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">postgres</span>
    <span class="nt">environment</span><span class="p">:</span>
      <span class="nt">POSTGRES_DB</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${POSTGRES_DB}</span>
      <span class="nt">POSTGRES_USER</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${POSTGRES_USER}</span>
      <span class="nt">POSTGRES_PASSWORD</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${POSTGRES_PASSWORD}</span>
    <span class="nt">ports</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="s">"${POSTGRES_PORT}:5432"</span>
    <span class="nt">volumes</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">pgdata:/var/lib/postgresql/data</span>
  <span class="nt">web</span><span class="p">:</span>
    <span class="nt">build</span><span class="p">:</span>
      <span class="nt">context</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${PWD}</span>
      <span class="nt">dockerfile</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">docker/web/Dockerfile.production</span>
    <span class="nt">environment</span><span class="p">:</span>
      <span class="nt">FLASK_ENV</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${FLASK_ENV}</span>
      <span class="nt">FLASK_CONFIG</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${FLASK_CONFIG}</span>
      <span class="nt">APPLICATION_DB</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${APPLICATION_DB}</span>
      <span class="nt">POSTGRES_USER</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${POSTGRES_USER}</span>
      <span class="nt">POSTGRES_HOSTNAME</span><span class="p">:</span> <span class="s">"db"</span>
      <span class="nt">POSTGRES_PASSWORD</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${POSTGRES_PASSWORD}</span>
      <span class="nt">POSTGRES_PORT</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${POSTGRES_PORT}</span>
    <span class="nt">command</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">gunicorn -w 4 -b 0.0.0.0 wsgi:app</span>
    <span class="nt">volumes</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">${PWD}:/opt/code</span>
  <span class="nt">nginx</span><span class="p">:</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
    <span class="nt">volumes</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">./nginx/nginx.conf:/etc/nginx/nginx.conf:ro</span>
    <span class="nt">ports</span><span class="p">:</span>
      <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">8080:8080</span>

<span class="nt">volumes</span><span class="p">:</span>
  <span class="nt">pgdata</span><span class="p">:</span>
</pre></div>
</div></div><p>As you can see the Postgres configuration is not different from the one we used in the file <code>testing.yml</code>, but I added the option <code>volumes</code> (both in <code>db</code> and at the end of the file) that allows me to create a stable volume. If you don't do it, the database will be destroyed once you shut down the container.</p><p>The container <code>web</code> runs the Flask application through <code>gunicorn</code>. The environment variables come once again from the JSON configuration, and we need to define them because the application needs to know how to connect with the database and how to run the web framework. The command <code>gunicorn -w 4 -b 0.0.0.0 wsgi:app</code> loads the WSGI application we created in <code>wsgi.py</code> and runs it in 4 concurrent processes. This container is created using <code>docker/web/Dockerfile.production</code> which I still have to define.</p><p>The last container is <code>nginx</code>, which we will use as it is directly from the Docker Hub. The container runs Nginx with the configuration stored in <code>/etc/nginx/nginx.conf</code>, which is the file we overwrite with the local one <code>./nginx/nginx.conf</code>. Please note that I configured it to use port 8080 instead of the standard port 80 for HTTP to avoid clashing with other software that you might be running on your computer.</p><p>The Dockerfile for the web application is the following</p><div class="code code-docker"><div class="title"><code>docker/web/Dockerfile.production</code></div><div class="content"><div class="highlight"><pre><span/><span class="k">FROM</span> <span class="s">python:3</span>

<span class="k">ENV</span> PYTHONUNBUFFERED <span class="m">1</span>

<span class="k">RUN</span> mkdir /opt/code
<span class="k">RUN</span> mkdir /opt/requirements
<span class="k">WORKDIR</span><span class="s"> /opt/code</span>

<span class="k">ADD</span> requirements /opt/requirements
<span class="k">RUN</span> pip install -r /opt/requirements/prod.txt
</pre></div>
</div></div><p>This is a very simple container that uses the standard <code>python:3</code> image, where I added the production requirements contained in <code>requirements/prod.txt</code>. To make the Docker container work we need to add <code>gunicorn</code> to this last file</p><div class="code code-text"><div class="title"><code>requirements/prod.txt</code></div><div class="content"><div class="highlight"><pre><span/>Flask
SQLAlchemy
psycopg2
pymongo
gunicorn
</pre></div>
</div></div><p>The configuration for Nginx is</p><div class="code code-nginx"><div class="title"><code>docker/nginx/nginx.conf</code></div><div class="content"><div class="highlight"><pre><span/><span class="k">worker_processes</span> <span class="mi">1</span><span class="p">;</span>

<span class="k">events</span> <span class="p">{</span> <span class="kn">worker_connections</span> <span class="mi">1024</span><span class="p">;</span> <span class="p">}</span>

<span class="k">http</span> <span class="p">{</span>

    <span class="kn">sendfile</span> <span class="no">on</span><span class="p">;</span>

    <span class="kn">upstream</span> <span class="s">app</span> <span class="p">{</span>
        <span class="kn">server</span> <span class="n">web</span><span class="p">:</span><span class="mi">8000</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="kn">server</span> <span class="p">{</span>
        <span class="kn">listen</span> <span class="mi">8080</span><span class="p">;</span>

        <span class="kn">location</span> <span class="s">/</span> <span class="p">{</span>
            <span class="kn">proxy_pass</span>         <span class="s">http://app</span><span class="p">;</span>
            <span class="kn">proxy_redirect</span>     <span class="no">off</span><span class="p">;</span>
            <span class="kn">proxy_set_header</span>   <span class="s">Host</span> <span class="nv">$host</span><span class="p">;</span>
            <span class="kn">proxy_set_header</span>   <span class="s">X-Real-IP</span> <span class="nv">$remote_addr</span><span class="p">;</span>
            <span class="kn">proxy_set_header</span>   <span class="s">X-Forwarded-For</span> <span class="nv">$proxy_add_x_forwarded_for</span><span class="p">;</span>
            <span class="kn">proxy_set_header</span>   <span class="s">X-Forwarded-Host</span> <span class="nv">$server_name</span><span class="p">;</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div></div><p>As for the rest of the project, this configuration is very basic and lacks some important parts that are mandatory in a real production environment, such as HTTPS. In its essence, though, it is however not too different from the configuration of a production-ready Nginx container.</p><p>As we will use Docker Compose, the script <code>manage.py</code> needs a simple change, which is a command that wraps <code>docker-compose</code> itself. We need the script to just initialise environment variables according to the content of the JSON configuration file and then run Docker Compose. As we already have the function <code>docker_compose_cmdline</code> the job is pretty simple</p><div class="code code-python"><div class="title"><code>manage.py</code></div><div class="content"><div class="highlight"><pre><span/><span class="c1"># Ensure an environment variable exists and has a value</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">signal</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="o">...</span>

<span class="k">def</span> <span class="nf">setenv</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">default</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="n">variable</span><span class="p">]</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">default</span><span class="p">)</span>


<span class="n">setenv</span><span class="p">(</span><span class="s2">"APPLICATION_CONFIG"</span><span class="p">,</span> <span class="s2">"production"</span><span class="p">)</span>

<span class="n">APPLICATION_CONFIG_PATH</span> <span class="o">=</span> <span class="s2">"config"</span>
<span class="n">DOCKER_PATH</span> <span class="o">=</span> <span class="s2">"docker"</span>

<span class="o">...</span>

<span class="nd">@cli</span><span class="o">.</span><span class="n">command</span><span class="p">(</span><span class="n">context_settings</span><span class="o">=</span><span class="p">{</span><span class="s2">"ignore_unknown_options"</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
<span class="nd">@click</span><span class="o">.</span><span class="n">argument</span><span class="p">(</span><span class="s2">"subcommand"</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="n">click</span><span class="o">.</span><span class="n">Path</span><span class="p">())</span>
<span class="k">def</span> <span class="nf">compose</span><span class="p">(</span><span class="n">subcommand</span><span class="p">):</span>
    <span class="n">configure_app</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"APPLICATION_CONFIG"</span><span class="p">))</span>
    <span class="n">cmdline</span> <span class="o">=</span> <span class="n">docker_compose_cmdline</span><span class="p">()</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">subcommand</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">(</span><span class="n">cmdline</span><span class="p">)</span>
        <span class="n">p</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
    <span class="k">except</span> <span class="ne">KeyboardInterrupt</span><span class="p">:</span>
        <span class="n">p</span><span class="o">.</span><span class="n">send_signal</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">SIGINT</span><span class="p">)</span>
        <span class="n">p</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</pre></div>
</div></div><p>As you can see I forced the variable <code>APPLICATION_CONFIG</code> to be <code>production</code> if not specified. Usually, my default configuration is the development one, but in this simple case I haven't defined one, so this will do for now.</p><p>The new command is <code>compose</code>, that leverages Click's <code>argument</code> decorator to collect subcommands and attach them to the Docker Compose command line. I also use the <code>signal</code> library, which I added to the imports, to control keyboard interruptions.</p><div class="admonition note"><i class="fa fa-github"/><div class="content"><div class="title">Source code</div><div><p><a href="https://github.com/pycabook/rentomatic/tree/ed2-c08-s01">https://github.com/pycabook/rentomatic/tree/ed2-c08-s01</a></p></div></div></div><p>When all this changes are in place we can test the application Dockerfile building the container.</p><div class="code code-sh"><div class="content"><div class="highlight"><pre><span/>$ ./manage.py compose build web
</pre></div>
</div></div><p>This command runs the Click command <code>compose</code> that first reads environment variables from the file <code>config/production.json</code>, and then runs <code>docker-compose</code> passing it the subcommand <code>build web</code>.</p><p>You output should be the following (with different image IDs)</p><div class="code code-text"><div class="content"><div class="highlight"><pre><span/>Building web
Step 1/7 : FROM python:3
 ---&gt; 768307cdb962
Step 2/7 : ENV PYTHONUNBUFFERED 1
 ---&gt; Using cache
 ---&gt; 0f2bb60286d3
Step 3/7 : RUN mkdir /opt/code
 ---&gt; Using cache
 ---&gt; e1278ef74291
Step 4/7 : RUN mkdir /opt/requirements
 ---&gt; Using cache
 ---&gt; 6d23f8abf0eb
Step 5/7 : WORKDIR /opt/code
 ---&gt; Using cache
 ---&gt; 8a3b6ae6d21c
Step 6/7 : ADD requirements /opt/requirements
 ---&gt; Using cache
 ---&gt; 75133f765531
Step 7/7 : RUN pip install -r /opt/requirements/prod.txt
 ---&gt; Using cache
 ---&gt; db644df9ba04

Successfully built db644df9ba04
Successfully tagged production_web:latest
</pre></div>
</div></div><p>If this is successful you can run Docker Compose</p><div class="code code-text"><div class="content"><div class="highlight"><pre><span/>$ ./manage.py compose up -d
Creating production_web_1   ... done
Creating production_db_1    ... done
Creating production_nginx_1 ... done
</pre></div>
</div></div><p>and the output of <code>docker ps</code> should show three containers running</p><div class="code code-text"><div class="content"><div class="highlight"><pre><span/>$ docker ps
IMAGE          PORTS                            NAMES
nginx          80/tcp, 0.0.0.0:8080-&gt;8080/tcp   production_nginx_1
postgres       0.0.0.0:5432-&gt;5432/tcp           production_db_1
production_web                                  production_web_1
</pre></div>
</div></div><p>Note that I removed several columns to make the output readable.</p><p>At this point we can open <a href="http://localhost:8080/rooms">http://localhost:8080/rooms</a> with our browser and see the result of the HTTP request received by Nginx, passed to gunicorn, and processed by Flask using the use case <code>room_list_use_case</code>.</p><p>The application is not actually using the database yet, as the Flask endpoint <code>room_list</code> in <code>application/rest/room.py</code> initialises the class <code>MemRepo</code> and loads it with some static values, which are the ones we see in our browser.</p><h2 id="connect-to-a-production-ready-database">Connect to a production-ready database</h2><p>Before we start changing the code of the application remember to tear down the system running </p><div class="code code-text"><div class="content"><div class="highlight"><pre><span/>$ ./manage.py compose down
Stopping production_web_1   ... done
Stopping production_nginx_1 ... done
Stopping production_db_1    ... done
Removing production_web_1   ... done
Removing production_nginx_1 ... done
Removing production_db_1    ... done
Removing network production_default
</pre></div>
</div></div><p>Thanks to the common interface between repositories, moving from the memory-based <code>MemRepo</code> to <code>PostgresRepo</code> is very simple. Clearly, as the external database will not contain any data initially, the response of the use case will be empty.</p><p>First of all, let's move the application to the Postgres repository. The new version of the endpoint is</p><div class="code code-python"><div class="title"><code>application/rest/room.py</code></div><div class="content"><div class="highlight"><pre><span/><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Blueprint</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">Response</span>

<span class="kn">from</span> <span class="nn">rentomatic.repository.postgresrepo</span> <span class="kn">import</span> <span class="n">PostgresRepo</span>
<span class="kn">from</span> <span class="nn">rentomatic.use_cases.room_list</span> <span class="kn">import</span> <span class="n">room_list_use_case</span>
<span class="kn">from</span> <span class="nn">rentomatic.serializers.room</span> <span class="kn">import</span> <span class="n">RoomJsonEncoder</span>
<span class="kn">from</span> <span class="nn">rentomatic.requests.room_list</span> <span class="kn">import</span> <span class="n">build_room_list_request</span>
<span class="kn">from</span> <span class="nn">rentomatic.responses</span> <span class="kn">import</span> <span class="n">ResponseTypes</span>

<span class="n">blueprint</span> <span class="o">=</span> <span class="n">Blueprint</span><span class="p">(</span><span class="s2">"room"</span><span class="p">,</span> <span class="vm">__name__</span><span class="p">)</span>

<span class="n">STATUS_CODES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">ResponseTypes</span><span class="o">.</span><span class="n">SUCCESS</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
    <span class="n">ResponseTypes</span><span class="o">.</span><span class="n">RESOURCE_ERROR</span><span class="p">:</span> <span class="mi">404</span><span class="p">,</span>
    <span class="n">ResponseTypes</span><span class="o">.</span><span class="n">PARAMETERS_ERROR</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
    <span class="n">ResponseTypes</span><span class="o">.</span><span class="n">SYSTEM_ERROR</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">postgres_configuration</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"POSTGRES_USER"</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"POSTGRES_USER"</span><span class="p">],</span>
    <span class="s2">"POSTGRES_PASSWORD"</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"POSTGRES_PASSWORD"</span><span class="p">],</span>
    <span class="s2">"POSTGRES_HOSTNAME"</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"POSTGRES_HOSTNAME"</span><span class="p">],</span>
    <span class="s2">"POSTGRES_PORT"</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"POSTGRES_PORT"</span><span class="p">],</span>
    <span class="s2">"APPLICATION_DB"</span><span class="p">:</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"APPLICATION_DB"</span><span class="p">],</span>
<span class="p">}</span>


<span class="nd">@blueprint</span><span class="o">.</span><span class="n">route</span><span class="p">(</span><span class="s2">"/rooms"</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s2">"GET"</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">room_list</span><span class="p">():</span>
    <span class="n">qrystr_params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">"filters"</span><span class="p">:</span> <span class="p">{},</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="n">arg</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">request</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">arg</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">"filter_"</span><span class="p">):</span>
            <span class="n">qrystr_params</span><span class="p">[</span><span class="s2">"filters"</span><span class="p">][</span><span class="n">arg</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"filter_"</span><span class="p">,</span> <span class="s2">""</span><span class="p">)]</span> <span class="o">=</span> <span class="n">values</span>

    <span class="n">request_object</span> <span class="o">=</span> <span class="n">build_room_list_request</span><span class="p">(</span>
        <span class="n">filters</span><span class="o">=</span><span class="n">qrystr_params</span><span class="p">[</span><span class="s2">"filters"</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">repo</span> <span class="o">=</span> <span class="n">PostgresRepo</span><span class="p">(</span><span class="n">postgres_configuration</span><span class="p">)</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">room_list_use_case</span><span class="p">(</span><span class="n">repo</span><span class="p">,</span> <span class="n">request_object</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">Response</span><span class="p">(</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="bp">cls</span><span class="o">=</span><span class="n">RoomJsonEncoder</span><span class="p">),</span>
        <span class="n">mimetype</span><span class="o">=</span><span class="s2">"application/json"</span><span class="p">,</span>
        <span class="n">status</span><span class="o">=</span><span class="n">STATUS_CODES</span><span class="p">[</span><span class="n">response</span><span class="o">.</span><span class="n">type</span><span class="p">],</span>
    <span class="p">)</span>
</pre></div>
</div></div><p>As you can see the main change is that <code>repo = MemRepo(rooms)</code> becomes <code>repo = PostgresRepo(postgres_configuration)</code>. Such a simple change is made possible by the clean architecture and its strict layered approach. The only other notable change is that we replaced the initial data for the memory-based repository with a dictionary containing connection data, which comes from the environment variables set by the management script.</p><p>This is enough to make the application connect to the Postgres database that we are running in a container, but as I mentioned we also need to initialise the database. The bare minimum that we need is an empty database with the correct name. Remember that in this particular setup we use for the application a different database (<code>APPLICATION_DB</code>) from the one that the Postgres container creates automatically at startup (<code>POSTGRES_DB</code>). I added a specific command to the management script to perform this task</p><div class="code code-python"><div class="title"><code>manage.py</code></div><div class="content"><div class="highlight"><pre><span/><span class="nd">@cli</span><span class="o">.</span><span class="n">command</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">init_postgres</span><span class="p">():</span>
    <span class="n">configure_app</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"APPLICATION_CONFIG"</span><span class="p">))</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">run_sql</span><span class="p">([</span><span class="sa">f</span><span class="s2">"CREATE DATABASE </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">'APPLICATION_DB'</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">])</span>
    <span class="k">except</span> <span class="n">psycopg2</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">DuplicateDatabase</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="sa">f</span><span class="s2">"The database </span><span class="si">{</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s1">'APPLICATION_DB'</span><span class="p">)</span><span class="si">}</span><span class="s2"> already"</span><span class="p">,</span>
                <span class="s2">"exists and will not be recreated"</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
</pre></div>
</div></div><p>Now spin up your containers</p><div class="code code-bash"><div class="content"><div class="highlight"><pre><span/>$ ./manage.py compose up -d
Creating network <span class="s2">"production_default"</span> with the default driver
Creating volume <span class="s2">"production_pgdata"</span> with default driver
Creating production_web_1   ... <span class="k">done</span>
Creating production_nginx_1 ... <span class="k">done</span>
Creating production_db_1    ... <span class="k">done</span>
</pre></div>
</div></div><p>and run the new command that we created</p><div class="code code-bash"><div class="content"><div class="highlight"><pre><span/>$ ./manage.py init-postgres
</pre></div>
</div></div><p>Mind the change between the name of the function <code>init_postgres</code> and the name of the command <code>init-postgres</code>. You only need to run this command once, but repeated executions will not affect the database.</p><p>We can check what this command did connecting to the database. We can do it executing <code>psql</code> in the database container</p><div class="code code-sh"><div class="content"><div class="highlight"><pre><span/>$ ./manage.py compose <span class="nb">exec</span> db psql -U postgres
psql <span class="o">(</span><span class="m">13</span>.4 <span class="o">(</span>Debian <span class="m">13</span>.4-1.pgdg100+1<span class="o">))</span>
Type <span class="s2">"help"</span> <span class="k">for</span> help.

<span class="nv">postgres</span><span class="o">=</span><span class="c1">#</span>
</pre></div>
</div></div><p>Please note that we need to specify the user <code>-U postgres</code>. That is the user that we created through the variable <code>POSTGRES_USER</code> in <code>config/production.json</code>. Once logged in, we can use the command <code>\l</code> to see the available databases</p><div class="code code-text"><div class="content"><div class="highlight"><pre><span/>postgres=# \l
                                  List of databases
    Name     |  Owner   | Encoding |  Collate   |   Ctype    |   Access privileges
-------------+----------+----------+------------+------------+----------------------
 application | postgres | UTF8     | en_US.utf8 | en_US.utf8 | 
 postgres    | postgres | UTF8     | en_US.utf8 | en_US.utf8 | 
 template0   | postgres | UTF8     | en_US.utf8 | en_US.utf8 | =c/postgres          +
             |          |          |            |            | postgres=CTc/postgres
 template1   | postgres | UTF8     | en_US.utf8 | en_US.utf8 | =c/postgres          +
             |          |          |            |            | postgres=CTc/postgres
(4 rows)

postgres=# 
</pre></div>
</div></div><p>Please note that the two databases <code>template0</code> and <code>template1</code> are system databases created by Postgres (see <a href="https://www.postgresql.org/docs/current/manage-ag-templatedbs.html">the documentation</a>), <code>postgres</code> is the default database created by the Docker container (the name is <code>postgres</code> by default, but in this case it comes from the environment variable <code>POSTGRES_DB</code> in <code>config/production.json</code>) and <code>application</code> is the database created by <code>./manage.py init-postgres</code> (from <code>APPLICATION_DB</code>).</p><p>We can connect to a database with the command <code>\c</code></p><div class="code code-text"><div class="content"><div class="highlight"><pre><span/>postgres=# \c application 
You are now connected to database "application" as user "postgres".
application=# 
</pre></div>
</div></div><p>Please note that the prompt changes with the name of the current database. Finally, we can list the available tables with <code>\dt</code></p><div class="code code-text"><div class="content"><div class="highlight"><pre><span/>application=# \dt
Did not find any relations.
</pre></div>
</div></div><p>As you can see there are no tables yet. This is no surprise as we didn't do anything to make Postres aware of the models that we created. Please remember that everything we are doing here is done in an external system and it is not directly connected with entities.</p><p>As you remember, we mapped entities to storage objects, and since we are using Postgres we leveraged SQLAlchemy classes, so now we need to create the database tables that correspond to them.</p><h3 id="migrations">Migrations</h3><p>We need a way to create the tables that correspond to the objects that we defined in <code>rentomatic/repository/postgres_objects.py</code>. The best strategy, when we use an ORM like SQLAlchemy, is to create and run migrations, and for this we can use <a href="https://alembic.sqlalchemy.org/">Alembic</a>.</p><p>If you are still connected with <code>psql</code> please exit with <code>\q</code>, then edit <code>requirements/prod.txt</code> and add <code>alembic</code></p><div class="code code-text"><div class="content"><div class="highlight"><pre><span/>Flask
SQLAlchemy
psycopg2
pymongo
gunicorn
<span class="hll">alembic
</span></pre></div>
</div></div><p>As usual, remember to run <code>pip install -r requirements/dev.txt</code> to update the virtual environment.</p><p>Alembic is capable of connecting to the database and run Python scripts (called "migrations") to alter the tables according to the SQLAlchemy models. To do this, however, we need to give Alembic access to the database providing username, password, hostname, and the database name. We also need to give Alembic access to the Python classes that represent the models.</p><p>First of all let's initialise Alembic. In the project's main directory (where <code>manage.py</code> is stored) run</p><div class="code code-bash"><div class="content"><div class="highlight"><pre><span/>$ alembic init migrations
</pre></div>
</div></div><p>which creates a directory called <code>migrations</code> that contains Alembic's configuration files, together with the migrations that will be created in <code>migrations/versions</code>. it will also create the file <code>alembic.ini</code> which contains the configuration values. The name <code>migrations</code> is completely arbitrary, so feel free to use a different one if you prefer.</p><p>The specific file we need to adjust to make Alembic aware of our models and our database is <code>migrations/env.py</code>. Add the highlighted lines</p><div class="code code-python"><div class="title">migrations/env.py</div><div class="content"><div class="highlight"><pre><span/><span class="hll"><span class="kn">import</span> <span class="nn">os</span>
</span>
<span class="kn">from</span> <span class="nn">logging.config</span> <span class="kn">import</span> <span class="n">fileConfig</span>

<span class="kn">from</span> <span class="nn">sqlalchemy</span> <span class="kn">import</span> <span class="n">engine_from_config</span>
<span class="kn">from</span> <span class="nn">sqlalchemy</span> <span class="kn">import</span> <span class="n">pool</span>

<span class="kn">from</span> <span class="nn">alembic</span> <span class="kn">import</span> <span class="n">context</span>

<span class="c1"># this is the Alembic Config object, which provides</span>
<span class="c1"># access to the values within the .ini file in use.</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">config</span>

<span class="hll"><span class="n">section</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">config_ini_section</span>
</span><span class="hll"><span class="n">config</span><span class="o">.</span><span class="n">set_section_option</span><span class="p">(</span>
</span><span class="hll">    <span class="n">section</span><span class="p">,</span> <span class="s2">"POSTGRES_USER"</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"POSTGRES_USER"</span><span class="p">)</span>
</span><span class="hll"><span class="p">)</span>
</span><span class="hll"><span class="n">config</span><span class="o">.</span><span class="n">set_section_option</span><span class="p">(</span>
</span><span class="hll">    <span class="n">section</span><span class="p">,</span> <span class="s2">"POSTGRES_PASSWORD"</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"POSTGRES_PASSWORD"</span><span class="p">)</span>
</span><span class="hll"><span class="p">)</span>
</span><span class="hll"><span class="n">config</span><span class="o">.</span><span class="n">set_section_option</span><span class="p">(</span>
</span><span class="hll">    <span class="n">section</span><span class="p">,</span> <span class="s2">"POSTGRES_HOSTNAME"</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"POSTGRES_HOSTNAME"</span><span class="p">)</span>
</span><span class="hll"><span class="p">)</span>
</span><span class="hll"><span class="n">config</span><span class="o">.</span><span class="n">set_section_option</span><span class="p">(</span>
</span><span class="hll">    <span class="n">section</span><span class="p">,</span> <span class="s2">"APPLICATION_DB"</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"APPLICATION_DB"</span><span class="p">)</span>
</span><span class="hll"><span class="p">)</span>
</span>
<span class="c1"># Interpret the config file for Python logging.</span>
<span class="c1"># This line sets up loggers basically.</span>
<span class="n">fileConfig</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">config_file_name</span><span class="p">)</span>

<span class="c1"># add your model's MetaData object here</span>
<span class="c1"># for 'autogenerate' support</span>
<span class="c1"># from myapp import mymodel</span>
<span class="c1"># target_metadata = mymodel.Base.metadata</span>
<span class="hll"><span class="c1"># target_metadata = None</span>
</span><span class="hll"><span class="kn">from</span> <span class="nn">rentomatic.repository.postgres_objects</span> <span class="kn">import</span> <span class="n">Base</span>
</span>
<span class="hll"><span class="n">target_metadata</span> <span class="o">=</span> <span class="n">Base</span><span class="o">.</span><span class="n">metadata</span>
</span>
<span class="c1"># other values from the config, defined by the needs of env.py,</span>
<span class="c1"># can be acquired:</span>
<span class="c1"># my_important_option = config.get_main_option("my_important_option")</span>
<span class="c1"># ... etc.</span>
</pre></div>
</div></div><p>Through <code>config.set_section_option</code> we are adding relevant configuration values to the main Alembic INI file section (<code>config.config_ini_section</code>), extracting them from the environment variables. We are also importing the file that contains the SQLAlchemy objects. You can find documentation on this procedure at <a href="https://alembic.sqlalchemy.org/en/latest/api/config.html">https://alembic.sqlalchemy.org/en/latest/api/config.html</a>.</p><p>Once this is done we need to change the INI file to use the new variables</p><div class="code code-python"><div class="title">alembic.ini</div><div class="content"><div class="highlight"><pre><span/><span class="c1"># the output encoding used when revision files</span>
<span class="c1"># are written from script.py.mako</span>
<span class="c1"># output_encoding = utf-8</span>

<span class="hll"><span class="n">sqlalchemy</span><span class="o">.</span><span class="n">url</span> <span class="o">=</span> <span class="n">postgresql</span><span class="p">:</span><span class="o">//%</span><span class="p">(</span><span class="n">POSTGRES_USER</span><span class="p">)</span><span class="n">s</span><span class="p">:</span><span class="o">%</span><span class="p">(</span><span class="n">POSTGRES_PASSWORD</span><span class="p">)</span><span class="n">s</span><span class="o">@%</span><span class="p">(</span><span class="n">POSTGRES_HOSTNAME</span><span class="p">)</span><span class="n">s</span><span class="o">/%</span><span class="p">(</span><span class="n">APPLICATION_DB</span><span class="p">)</span><span class="n">s</span>
</span>
<span class="p">[</span><span class="n">post_write_hooks</span><span class="p">]</span>
<span class="c1"># post_write_hooks defines scripts or Python functions that are run</span>
<span class="c1"># on newly generated revision scripts.  See the documentation for further</span>
<span class="c1"># detail and examples</span>
</pre></div>
</div></div><p>The syntax <code>%(VARNAME)s</code> is the basic variable interpolation used by <code>ConfigParser</code> (see <a href="https://docs.python.org/3.8/library/configparser.html#configparser.BasicInterpolation">the documentation</a>).</p><p>At this point we can run Alembic to migrate our database. In many cases, you can rely on Alembic's autogeneration functionality to generate the migrations, and this is what we can do to create the initial models. The Alembic command is <code>revision</code> with the <code>--autogenerate</code> flag, but we need to pass the environment variables on the command line. This is clearly a job for <code>migrate.py</code> but let's first run it to see what happens to the database. Later we will create a better setup to avoid passing variables manually</p><div class="code code-bash"><div class="content"><div class="highlight"><pre><span/>$ <span class="nv">POSTGRES_USER</span><span class="o">=</span>postgres<span class="se">\</span>
  <span class="nv">POSTGRES_PASSWORD</span><span class="o">=</span>postgres<span class="se">\</span>
  <span class="nv">POSTGRES_HOSTNAME</span><span class="o">=</span>localhost<span class="se">\</span>
  <span class="nv">APPLICATION_DB</span><span class="o">=</span>application<span class="se">\</span>
  alembic revision --autogenerate -m <span class="s2">"Initial"</span>
</pre></div>
</div></div><p>This will generate the file <code>migrations/versions/4d4c19952a36_initial.py</code>. Pay attention that the initial hash will be different for you. If you want you can open that file and see how Alembic generates the table and creates the columns.</p><p>So far we created the migration but we still need to apply it to the database. Make sure you are running the Docker containers (run <code>./manage.py compose up -d</code> otherwise) as Alembic is going to connect to the database, and run</p><div class="code code-bash"><div class="content"><div class="highlight"><pre><span/>$ <span class="nv">POSTGRES_USER</span><span class="o">=</span>postgres<span class="se">\</span>
  <span class="nv">POSTGRES_PASSWORD</span><span class="o">=</span>postgres<span class="se">\</span>
  <span class="nv">POSTGRES_HOSTNAME</span><span class="o">=</span>localhost<span class="se">\</span>
  <span class="nv">APPLICATION_DB</span><span class="o">=</span>application<span class="se">\</span>
  alembic upgrade head
</pre></div>
</div></div><p>At this point we can connect to the database and check the existing tables</p><div class="code code-bash"><div class="content"><div class="highlight"><pre><span/>$ ./manage.py compose <span class="nb">exec</span> db psql -U postgres -d application
psql <span class="o">(</span><span class="m">13</span>.4 <span class="o">(</span>Debian <span class="m">13</span>.4-1.pgdg100+1<span class="o">))</span>
Type <span class="s2">"help"</span> <span class="k">for</span> help.

<span class="nv">application</span><span class="o">=</span><span class="c1"># \dt</span>
              List of relations
 Schema <span class="p">|</span>      Name       <span class="p">|</span> Type  <span class="p">|</span>  Owner   
--------+-----------------+-------+----------
 public <span class="p">|</span> alembic_version <span class="p">|</span> table <span class="p">|</span> postgres
 public <span class="p">|</span> room            <span class="p">|</span> table <span class="p">|</span> postgres
<span class="o">(</span><span class="m">2</span> rows<span class="o">)</span>

<span class="nv">application</span><span class="o">=</span><span class="c1"># </span>
</pre></div>
</div></div><p>Please note that I used the option <code>-d</code> of <code>psql</code> to connect directly to the database <code>application</code>. As you can see, now we have two tables. The first, <code>alembic_version</code> is a simple one that Alembic uses to keep track of the state of the db, while <code>room</code> is the one that will contain our <code>Room</code> entities.</p><p>We can double-check the Alembic version</p><div class="code code-text"><div class="content"><div class="highlight"><pre><span/>application=# select * from alembic_version;
 version_num  
--------------
 4d4c19952a36
(1 row)
</pre></div>
</div></div><p>As I mentioned before, the hash given to the migration will be different in your case, but that value that you see in this table should be consistent with the name of the migration script.</p><p>We can also see the structure of the table <code>room</code></p><div class="code code-text"><div class="content"><div class="highlight"><pre><span/>application=# \d room
                                     Table "public.room"
  Column   |         Type          | Collation | Nullable |             Default              
-----------+-----------------------+-----------+----------+----------------------------------
 id        | integer               |           | not null | nextval('room_id_seq'::regclass)
 code      | character varying(36) |           | not null | 
 size      | integer               |           |          | 
 price     | integer               |           |          | 
 longitude | double precision      |           |          | 
 latitude  | double precision      |           |          | 
Indexes:
    "room_pkey" PRIMARY KEY, btree (id)
</pre></div>
</div></div><p>Clearly, there are still no rows contained in that table</p><div class="code code-text"><div class="content"><div class="highlight"><pre><span/>application=# select * from room;
 id | code | size | price | longitude | latitude 
----+------+------+-------+-----------+----------
(0 rows)
</pre></div>
</div></div><p>And indeed, if you open <a href="http://localhost:8080/rooms">http://localhost:8080/rooms</a> with your browser you will see a successful response, but no data.</p><p>To see some data we need to write something into the database. This is normally done through a form in the web application and a specific endpoint, but for the sake of simplicity in this case we can just add data manually to the database.</p><div class="code code-sql"><div class="content"><div class="highlight"><pre><span/><span class="n">application</span><span class="o">=#</span> <span class="k">INSERT</span> <span class="k">INTO</span> <span class="n">room</span><span class="p">(</span><span class="n">code</span><span class="p">,</span> <span class="k">size</span><span class="p">,</span> <span class="n">price</span><span class="p">,</span> <span class="n">longitude</span><span class="p">,</span> <span class="n">latitude</span><span class="p">)</span> <span class="k">VALUES</span> <span class="p">(</span><span class="s1">'f853578c-fc0f-4e65-81b8-566c5dffa35a'</span><span class="p">,</span> <span class="mi">215</span><span class="p">,</span> <span class="mi">39</span><span class="p">,</span> <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">09998975</span><span class="p">,</span> <span class="mi">51</span><span class="p">.</span><span class="mi">75436293</span><span class="p">);</span>
<span class="k">INSERT</span> <span class="mi">0</span> <span class="mi">1</span>
</pre></div>
</div></div><p>You can verify that the table contains the new room with a <code>SELECT</code></p><div class="code code-sql"><div class="content"><div class="highlight"><pre><span/><span class="n">application</span><span class="o">=#</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">room</span><span class="p">;</span>
 <span class="n">id</span> <span class="o">|</span>                 <span class="n">code</span>                 <span class="o">|</span> <span class="k">size</span> <span class="o">|</span> <span class="n">price</span> <span class="o">|</span>  <span class="n">longitude</span>  <span class="o">|</span>  <span class="n">latitude</span>   
<span class="c1">----+--------------------------------------+------+-------+-------------+-------------</span>
  <span class="mi">1</span> <span class="o">|</span> <span class="n">f853578c</span><span class="o">-</span><span class="n">fc0f</span><span class="o">-</span><span class="mi">4</span><span class="n">e65</span><span class="o">-</span><span class="mi">81</span><span class="n">b8</span><span class="o">-</span><span class="mi">566</span><span class="n">c5dffa35a</span> <span class="o">|</span>  <span class="mi">215</span> <span class="o">|</span>    <span class="mi">39</span> <span class="o">|</span> <span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">09998975</span> <span class="o">|</span> <span class="mi">51</span><span class="p">.</span><span class="mi">75436293</span>
<span class="p">(</span><span class="mi">1</span> <span class="k">row</span><span class="p">)</span>
</pre></div>
</div></div><p>and open or refresh <a href="http://localhost:8080/rooms">http://localhost:8080/rooms</a> with the browser to see the value returned by our use case.</p><div class="admonition note"><i class="fa fa-github"/><div class="content"><div class="title">Source code</div><div><p><a href="https://github.com/pycabook/rentomatic/tree/ed2-c08-s02">https://github.com/pycabook/rentomatic/tree/ed2-c08-s02</a></p></div></div></div><hr/><p>This chapter concludes the overview of the clean architecture example. Starting from scratch, we created domain models, serializers, use cases, an in-memory storage system, a command-line interface and an HTTP endpoint. We then improved the whole system with a very generic request/response management code, that provides robust support for errors. Last, we implemented two new storage systems, using both a relational and a NoSQL database.</p><p>This is by no means a little achievement. Our architecture covers a very small use case, but is robust and fully tested. Whatever error we might find in the way we dealt with data, databases, requests, and so on, can be isolated and tamed much faster than in a system which doesn't have tests. Moreover, the decoupling philosophy not only allows us to provide support for multiple storage systems, but also to quickly implement new access protocols, or new serialisations for our objects.</p><div id="_footnotes"/>
      
</body>
</html>