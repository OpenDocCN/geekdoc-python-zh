["```py\n[\n  {\n    \"name\": \"FLASK_ENV\",\n    \"value\": \"production\"\n  },\n  {\n    \"name\": \"FLASK_CONFIG\",\n    \"value\": \"production\"\n  },\n  {\n    \"name\": \"POSTGRES_DB\",\n    \"value\": \"postgres\"\n  },\n  {\n    \"name\": \"POSTGRES_USER\",\n    \"value\": \"postgres\"\n  },\n  {\n    \"name\": \"POSTGRES_HOSTNAME\",\n    \"value\": \"localhost\"\n  },\n  {\n    \"name\": \"POSTGRES_PORT\",\n    \"value\": \"5432\"\n  },\n  {\n    \"name\": \"POSTGRES_PASSWORD\",\n    \"value\": \"postgres\"\n  },\n  {\n    \"name\": \"APPLICATION_DB\",\n    \"value\": \"application\"\n  }\n] \n```", "```py\nversion: '3.8'\n\nservices:\n  db:\n    image: postgres\n    environment:\n      POSTGRES_DB: ${POSTGRES_DB}\n      POSTGRES_USER: ${POSTGRES_USER}\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n    ports:\n      - \"${POSTGRES_PORT}:5432\"\n    volumes:\n      - pgdata:/var/lib/postgresql/data\n  web:\n    build:\n      context: ${PWD}\n      dockerfile: docker/web/Dockerfile.production\n    environment:\n      FLASK_ENV: ${FLASK_ENV}\n      FLASK_CONFIG: ${FLASK_CONFIG}\n      APPLICATION_DB: ${APPLICATION_DB}\n      POSTGRES_USER: ${POSTGRES_USER}\n      POSTGRES_HOSTNAME: \"db\"\n      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n      POSTGRES_PORT: ${POSTGRES_PORT}\n    command: gunicorn -w 4 -b 0.0.0.0 wsgi:app\n    volumes:\n      - ${PWD}:/opt/code\n  nginx:\n    image: nginx\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n    ports:\n      - 8080:8080\n\nvolumes:\n  pgdata: \n```", "```py\nFROM python:3\n\nENV PYTHONUNBUFFERED 1\n\nRUN mkdir /opt/code\nRUN mkdir /opt/requirements\nWORKDIR /opt/code\n\nADD requirements /opt/requirements\nRUN pip install -r /opt/requirements/prod.txt \n```", "```py\nFlask\nSQLAlchemy\npsycopg2\npymongo\ngunicorn \n```", "```py\nworker_processes 1;\n\nevents { worker_connections 1024; }\n\nhttp {\n\n    sendfile on;\n\n    upstream app {\n        server web:8000;\n    }\n\n    server {\n        listen 8080;\n\n        location / {\n            proxy_pass         http://app;\n            proxy_redirect     off;\n            proxy_set_header   Host $host;\n            proxy_set_header   X-Real-IP $remote_addr;\n            proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header   X-Forwarded-Host $server_name;\n        }\n    }\n} \n```", "```py\n# Ensure an environment variable exists and has a value\nimport os\nimport json\nimport signal\nimport subprocess\nimport time\n\n...\n\ndef setenv(variable, default):\n    os.environ[variable] = os.getenv(variable, default)\n\nsetenv(\"APPLICATION_CONFIG\", \"production\")\n\nAPPLICATION_CONFIG_PATH = \"config\"\nDOCKER_PATH = \"docker\"\n\n...\n\n@cli.command(context_settings={\"ignore_unknown_options\": True})\n@click.argument(\"subcommand\", nargs=-1, type=click.Path())\ndef compose(subcommand):\n    configure_app(os.getenv(\"APPLICATION_CONFIG\"))\n    cmdline = docker_compose_cmdline() + list(subcommand)\n\n    try:\n        p = subprocess.Popen(cmdline)\n        p.wait()\n    except KeyboardInterrupt:\n        p.send_signal(signal.SIGINT)\n        p.wait() \n```", "```py\n*$ ./manage.py compose build web* \n```", "```py\n*Building web\nStep 1/7 : FROM python:3\n ---> 768307cdb962\nStep 2/7 : ENV PYTHONUNBUFFERED 1\n ---> Using cache\n ---> 0f2bb60286d3\nStep 3/7 : RUN mkdir /opt/code\n ---> Using cache\n ---> e1278ef74291\nStep 4/7 : RUN mkdir /opt/requirements\n ---> Using cache\n ---> 6d23f8abf0eb\nStep 5/7 : WORKDIR /opt/code\n ---> Using cache\n ---> 8a3b6ae6d21c\nStep 6/7 : ADD requirements /opt/requirements\n ---> Using cache\n ---> 75133f765531\nStep 7/7 : RUN pip install -r /opt/requirements/prod.txt\n ---> Using cache\n ---> db644df9ba04\n\nSuccessfully built db644df9ba04\nSuccessfully tagged production_web:latest* \n```", "```py\n*$ ./manage.py compose up -d\nCreating production_web_1   ... done\nCreating production_db_1    ... done\nCreating production_nginx_1 ... done* \n```", "```py\n*$ docker ps\nIMAGE          PORTS                            NAMES\nnginx          80/tcp, 0.0.0.0:8080->8080/tcp   production_nginx_1\npostgres       0.0.0.0:5432->5432/tcp           production_db_1\nproduction_web                                  production_web_1* \n```", "```py\n*$ ./manage.py compose down\nStopping production_web_1   ... done\nStopping production_nginx_1 ... done\nStopping production_db_1    ... done\nRemoving production_web_1   ... done\nRemoving production_nginx_1 ... done\nRemoving production_db_1    ... done\nRemoving network production_default* \n```", "```py\n*import os\nimport json\n\nfrom flask import Blueprint, request, Response\n\nfrom rentomatic.repository.postgresrepo import PostgresRepo\nfrom rentomatic.use_cases.room_list import room_list_use_case\nfrom rentomatic.serializers.room import RoomJsonEncoder\nfrom rentomatic.requests.room_list import build_room_list_request\nfrom rentomatic.responses import ResponseTypes\n\nblueprint = Blueprint(\"room\", __name__)\n\nSTATUS_CODES = {\n    ResponseTypes.SUCCESS: 200,\n    ResponseTypes.RESOURCE_ERROR: 404,\n    ResponseTypes.PARAMETERS_ERROR: 400,\n    ResponseTypes.SYSTEM_ERROR: 500,\n}\n\npostgres_configuration = {\n    \"POSTGRES_USER\": os.environ[\"POSTGRES_USER\"],\n    \"POSTGRES_PASSWORD\": os.environ[\"POSTGRES_PASSWORD\"],\n    \"POSTGRES_HOSTNAME\": os.environ[\"POSTGRES_HOSTNAME\"],\n    \"POSTGRES_PORT\": os.environ[\"POSTGRES_PORT\"],\n    \"APPLICATION_DB\": os.environ[\"APPLICATION_DB\"],\n}\n\n@blueprint.route(\"/rooms\", methods=[\"GET\"])\ndef room_list():\n    qrystr_params = {\n        \"filters\": {},\n    }\n\n    for arg, values in request.args.items():\n        if arg.startswith(\"filter_\"):\n            qrystr_params[\"filters\"][arg.replace(\"filter_\", \"\")] = values\n\n    request_object = build_room_list_request(\n        filters=qrystr_params[\"filters\"]\n    )\n\n    repo = PostgresRepo(postgres_configuration)\n    response = room_list_use_case(repo, request_object)\n\n    return Response(\n        json.dumps(response.value, cls=RoomJsonEncoder),\n        mimetype=\"application/json\",\n        status=STATUS_CODES[response.type],\n    )* \n```", "```py\n*@cli.command()\ndef init_postgres():\n    configure_app(os.getenv(\"APPLICATION_CONFIG\"))\n\n    try:\n        run_sql([f\"CREATE DATABASE {os.getenv('APPLICATION_DB')}\"])\n    except psycopg2.errors.DuplicateDatabase:\n        print(\n            (\n                f\"The database {os.getenv('APPLICATION_DB')} already\",\n                \"exists and will not be recreated\",\n            )\n        )* \n```", "```py\n*$ ./manage.py compose up -d\nCreating network \"production_default\" with the default driver\nCreating volume \"production_pgdata\" with default driver\nCreating production_web_1   ... done\nCreating production_nginx_1 ... done\nCreating production_db_1    ... done* \n```", "```py\n*$ ./manage.py init-postgres* \n```", "```py\n*$ ./manage.py compose exec db psql -U postgres\npsql (13.4 (Debian 13.4-1.pgdg100+1))\nType \"help\" for help.\n\npostgres=#* \n```", "```py\n*postgres=# \\l\n                                  List of databases\n    Name     |  Owner   | Encoding |  Collate   |   Ctype    |   Access privileges\n-------------+----------+----------+------------+------------+----------------------\n application | postgres | UTF8     | en_US.utf8 | en_US.utf8 | \n postgres    | postgres | UTF8     | en_US.utf8 | en_US.utf8 | \n template0   | postgres | UTF8     | en_US.utf8 | en_US.utf8 | =c/postgres          +\n             |          |          |            |            | postgres=CTc/postgres\n template1   | postgres | UTF8     | en_US.utf8 | en_US.utf8 | =c/postgres          +\n             |          |          |            |            | postgres=CTc/postgres\n(4 rows)\n\npostgres=#* \n```", "```py\n*postgres=# \\c application \nYou are now connected to database \"application\" as user \"postgres\".\napplication=#* \n```", "```py\n*application=# \\dt\nDid not find any relations.* \n```", "```py\n*Flask\nSQLAlchemy\npsycopg2\npymongo\ngunicorn\nalembic* \n```", "```py\n*$ alembic init migrations* \n```", "```py\n*import os \nfrom logging.config import fileConfig\n\nfrom sqlalchemy import engine_from_config\nfrom sqlalchemy import pool\n\nfrom alembic import context\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\nsection = config.config_ini_section config.set_section_option(\n section, \"POSTGRES_USER\", os.environ.get(\"POSTGRES_USER\") ) config.set_section_option(\n section, \"POSTGRES_PASSWORD\", os.environ.get(\"POSTGRES_PASSWORD\") ) config.set_section_option(\n section, \"POSTGRES_HOSTNAME\", os.environ.get(\"POSTGRES_HOSTNAME\") ) config.set_section_option(\n section, \"APPLICATION_DB\", os.environ.get(\"APPLICATION_DB\") ) \n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nfileConfig(config.config_file_name)\n\n# add your model's MetaData object here\n# for 'autogenerate' support\n# from myapp import mymodel\n# target_metadata = mymodel.Base.metadata\n# target_metadata = None from rentomatic.repository.postgres_objects import Base \ntarget_metadata = Base.metadata \n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.* \n```", "```py\n*# the output encoding used when revision files\n# are written from script.py.mako\n# output_encoding = utf-8\n\nsqlalchemy.url = postgresql://%(POSTGRES_USER)s:%(POSTGRES_PASSWORD)s@%(POSTGRES_HOSTNAME)s/%(APPLICATION_DB)s \n[post_write_hooks]\n# post_write_hooks defines scripts or Python functions that are run\n# on newly generated revision scripts.  See the documentation for further\n# detail and examples* \n```", "```py\n*$ POSTGRES_USER=postgres\\\n  POSTGRES_PASSWORD=postgres\\\n  POSTGRES_HOSTNAME=localhost\\\n  APPLICATION_DB=application\\\n  alembic revision --autogenerate -m \"Initial\"* \n```", "```py\n*$ POSTGRES_USER=postgres\\\n  POSTGRES_PASSWORD=postgres\\\n  POSTGRES_HOSTNAME=localhost\\\n  APPLICATION_DB=application\\\n  alembic upgrade head* \n```", "```py\n*$ ./manage.py compose exec db psql -U postgres -d application\npsql (13.4 (Debian 13.4-1.pgdg100+1))\nType \"help\" for help.\n\napplication=# \\dt\n              List of relations\n Schema |      Name       | Type  |  Owner   \n--------+-----------------+-------+----------\n public | alembic_version | table | postgres\n public | room            | table | postgres\n(2 rows)\n\napplication=#* \n```", "```py\n*application=# select * from alembic_version;\n version_num  \n--------------\n 4d4c19952a36\n(1 row)* \n```", "```py\n*application=# \\d room\n                                     Table \"public.room\"\n  Column   |         Type          | Collation | Nullable |             Default              \n-----------+-----------------------+-----------+----------+----------------------------------\n id        | integer               |           | not null | nextval('room_id_seq'::regclass)\n code      | character varying(36) |           | not null | \n size      | integer               |           |          | \n price     | integer               |           |          | \n longitude | double precision      |           |          | \n latitude  | double precision      |           |          | \nIndexes:\n    \"room_pkey\" PRIMARY KEY, btree (id)* \n```", "```py\n*application=# select * from room;\n id | code | size | price | longitude | latitude \n----+------+------+-------+-----------+----------\n(0 rows)* \n```", "```py\n*application=# INSERT INTO room(code, size, price, longitude, latitude) VALUES ('f853578c-fc0f-4e65-81b8-566c5dffa35a', 215, 39, -0.09998975, 51.75436293);\nINSERT 0 1* \n```", "```py\n*application=# SELECT * FROM room;\n id |                 code                 | size | price |  longitude  |  latitude   \n----+--------------------------------------+------+-------+-------------+-------------\n  1 | f853578c-fc0f-4e65-81b8-566c5dffa35a |  215 |    39 | -0.09998975 | 51.75436293\n(1 row)* \n```"]